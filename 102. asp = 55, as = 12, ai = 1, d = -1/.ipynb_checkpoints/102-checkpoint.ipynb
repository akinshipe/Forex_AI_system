{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc1897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "all_currency_pairs = ['USDCHF10080',\n",
    "                 'GBPUSD10080', 'EURUSD10080', 'USDJPY10080', 'USDCAD10080', 'AUDUSD10080', 'NZDUSD10080',\n",
    "                 'GBPCHF10080', 'EURCHF10080', 'CHFJPY10080', 'CADCHF10080', 'AUDCHF10080', 'NZDCHF10080', 'EURGBP10080',\n",
    "                 'GBPJPY10080', 'GBPCAD10080', 'GBPAUD10080', 'EURJPY10080', 'EURCAD10080', 'EURAUD10080', 'EURNZD10080',\n",
    "                'CADJPY10080', 'AUDJPY10080', 'NZDJPY10080', 'AUDCAD10080', 'NZDCAD10080', 'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "headers = ['date', 'ignore', 'open', 'high', 'low', 'close', 'volume'  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d48f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015.01.04' '2015.01.11' '2015.01.18' '2015.01.25' '2015.02.01'\n",
      " '2015.02.08' '2015.02.15' '2015.02.22' '2015.03.01' '2015.03.08'\n",
      " '2015.03.15' '2015.03.22' '2015.03.29' '2015.04.05' '2015.04.12'\n",
      " '2015.04.19' '2015.04.26' '2015.05.03' '2015.05.10' '2015.05.17'\n",
      " '2015.05.24' '2015.05.31' '2015.06.07' '2015.06.14' '2015.06.21'\n",
      " '2015.06.28' '2015.07.05' '2015.07.12' '2015.07.19' '2015.07.26'\n",
      " '2015.08.02' '2015.08.09' '2015.08.16' '2015.08.23' '2015.08.30'\n",
      " '2015.09.06' '2015.09.13' '2015.09.20' '2015.09.27' '2015.10.04'\n",
      " '2015.10.11' '2015.10.18' '2015.10.25' '2015.11.01' '2015.11.08'\n",
      " '2015.11.15' '2015.11.22' '2015.11.29' '2015.12.06' '2015.12.13'\n",
      " '2015.12.20' '2015.12.27' '2016.01.03' '2016.01.10' '2016.01.17'\n",
      " '2016.01.24' '2016.01.31' '2016.02.07' '2016.02.14' '2016.02.21'\n",
      " '2016.02.28' '2016.03.06' '2016.03.13' '2016.03.20' '2016.03.27'\n",
      " '2016.04.03' '2016.04.10' '2016.04.17' '2016.04.24' '2016.05.01'\n",
      " '2016.05.08' '2016.05.15' '2016.05.22' '2016.05.29' '2016.06.05'\n",
      " '2016.06.12' '2016.06.19' '2016.06.26' '2016.07.03' '2016.07.10'\n",
      " '2016.07.17' '2016.07.24' '2016.07.31' '2016.08.07' '2016.08.14'\n",
      " '2016.08.21' '2016.08.28' '2016.09.04' '2016.09.11' '2016.09.18'\n",
      " '2016.09.25' '2016.10.02' '2016.10.09' '2016.10.16' '2016.10.23'\n",
      " '2016.10.30' '2016.11.06' '2016.11.13' '2016.11.20' '2016.11.27'\n",
      " '2016.12.04' '2016.12.11' '2016.12.18' '2016.12.25' '2017.01.01'\n",
      " '2017.01.08' '2017.01.15' '2017.01.22' '2017.01.29' '2017.02.05'\n",
      " '2017.02.12' '2017.02.19' '2017.02.26' '2017.03.05' '2017.03.19'\n",
      " '2017.03.26' '2017.04.02' '2017.04.09' '2017.04.16' '2017.04.23'\n",
      " '2017.04.30' '2017.05.07' '2017.05.14' '2017.05.21' '2017.05.28'\n",
      " '2017.06.04' '2017.06.11' '2017.06.18' '2017.06.25' '2017.07.02'\n",
      " '2017.07.09' '2017.07.16' '2017.07.23' '2017.07.30' '2017.08.06'\n",
      " '2017.08.13' '2017.08.20' '2017.08.27' '2017.09.03' '2017.09.10'\n",
      " '2017.09.17' '2017.09.24' '2017.10.01' '2017.10.08' '2017.10.15'\n",
      " '2017.10.22' '2017.10.29' '2017.11.05' '2017.11.12' '2017.11.19'\n",
      " '2017.11.26' '2017.12.03' '2017.12.10' '2017.12.17' '2017.12.24'\n",
      " '2017.12.31' '2018.01.07' '2018.01.14' '2018.01.21' '2018.01.28'\n",
      " '2018.02.04' '2018.02.11' '2018.02.18' '2018.02.25' '2018.03.04'\n",
      " '2018.03.11' '2018.03.18' '2018.03.25' '2018.04.01' '2018.04.08'\n",
      " '2018.04.15' '2018.04.22' '2018.04.29' '2018.05.06' '2018.05.13'\n",
      " '2018.05.20' '2018.05.27' '2018.06.03' '2018.06.10' '2018.06.17'\n",
      " '2018.06.24' '2018.07.01' '2018.07.08' '2018.07.15' '2018.07.22'\n",
      " '2018.07.29' '2018.08.05' '2018.08.12' '2018.08.19' '2018.08.26'\n",
      " '2018.09.02' '2018.09.09' '2018.09.16' '2018.09.23' '2018.09.30'\n",
      " '2018.10.07' '2018.10.14' '2018.10.21' '2018.10.28' '2018.11.04'\n",
      " '2018.11.11' '2018.11.18' '2018.11.25' '2018.12.02' '2018.12.09'\n",
      " '2018.12.16' '2018.12.23' '2018.12.30' '2019.01.06' '2019.01.13'\n",
      " '2019.01.20' '2019.01.27' '2019.02.03' '2019.02.10' '2019.02.17'\n",
      " '2019.02.24' '2019.03.03' '2019.03.10' '2019.03.17' '2019.03.24'\n",
      " '2019.03.31' '2019.04.07' '2019.04.14' '2019.04.21' '2019.04.28'\n",
      " '2019.05.05' '2019.05.12' '2019.05.19' '2019.05.26' '2019.06.02'\n",
      " '2019.06.09' '2019.06.16' '2019.06.23' '2019.06.30' '2019.07.07'\n",
      " '2019.07.14' '2019.07.21' '2019.07.28' '2019.08.04' '2019.08.11'\n",
      " '2019.08.18' '2019.08.25' '2019.09.01' '2019.09.08' '2019.09.15'\n",
      " '2019.09.22' '2019.09.29' '2019.10.06' '2019.10.13' '2019.10.20'\n",
      " '2019.10.27' '2019.11.03' '2019.11.10' '2019.11.17' '2019.11.24'\n",
      " '2019.12.01' '2019.12.08' '2019.12.15' '2019.12.22' '2019.12.29'\n",
      " '2020.01.05' '2020.01.12' '2020.01.19' '2020.01.26' '2020.02.02'\n",
      " '2020.02.09' '2020.02.16' '2020.02.23' '2020.03.01' '2020.03.08'\n",
      " '2020.03.15' '2020.03.22' '2020.03.29' '2020.04.05' '2020.04.12'\n",
      " '2020.04.19' '2020.04.26' '2020.05.03' '2020.05.10' '2020.05.17'\n",
      " '2020.05.24' '2020.05.31' '2020.06.07' '2020.06.14' '2020.06.21'\n",
      " '2020.06.28' '2020.07.05' '2020.07.12' '2020.07.19' '2020.07.26'\n",
      " '2020.08.02' '2020.08.09' '2020.08.16' '2020.08.23' '2020.08.30'\n",
      " '2020.09.06' '2020.09.13' '2020.09.20' '2020.09.27' '2020.10.04'\n",
      " '2020.10.11' '2020.10.18' '2020.10.25' '2020.11.01' '2020.11.08'\n",
      " '2020.11.15' '2020.11.22' '2020.11.29' '2020.12.06' '2020.12.13'\n",
      " '2020.12.20' '2020.12.27' '2021.01.03' '2021.01.10' '2021.01.17'\n",
      " '2021.01.24' '2021.01.31' '2021.02.07' '2021.02.14' '2021.02.21'\n",
      " '2021.02.28' '2021.03.07' '2021.03.14' '2021.03.21' '2021.03.28'\n",
      " '2021.04.04' '2021.04.11' '2021.04.18' '2021.04.25' '2021.05.02'\n",
      " '2021.05.09' '2021.05.16' '2021.05.23' '2021.05.30' '2021.06.06'\n",
      " '2021.06.13' '2021.06.20' '2021.06.27' '2021.07.04' '2021.07.11'\n",
      " '2021.07.18' '2021.07.25' '2021.08.01' '2021.08.08' '2021.08.15'\n",
      " '2021.08.22' '2021.08.29' '2021.09.05' '2021.09.12' '2021.09.19'\n",
      " '2021.09.26' '2021.10.03' '2021.10.10' '2021.10.17' '2021.10.24'\n",
      " '2021.10.31' '2021.11.07' '2021.11.14' '2021.11.21' '2021.11.28']\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"../raw_weekly_data/NZDCAD10080.csv\", names = headers )\n",
    "\n",
    "\n",
    "\n",
    "needed_weeks_df = raw_df.loc[(raw_df['date'] >= \"2015.01.01\")   ]   \n",
    "\n",
    "\n",
    "\n",
    "needed_weeks_df = needed_weeks_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "available_weeks = needed_weeks_df['date'].values\n",
    "\n",
    "\n",
    "\n",
    "#print(raw_df)\n",
    "print(available_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2b15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in available_weeks:\n",
    "    \n",
    "    current_date = datetime.strptime(y, '%Y.%m.%d').strftime('%A')\n",
    "    \n",
    "    if current_date != 'Sunday':\n",
    "        available_weeks = [x for x in available_weeks if x != y]\n",
    "        print('error-----------------------------', y, ' did is not a sunday')\n",
    "        \n",
    "        raise Exception('error-----------------------------', y, ' did is not a sunday')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7aad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in available_weeks:\n",
    "  \n",
    "  \n",
    "    path = \"./files/\" + a\n",
    "\n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "        control_file = pd.DataFrame()\n",
    "        \n",
    "        for  b in range(8):\n",
    "            control_file['control' + str(b)] = -1\n",
    "            \n",
    "            \n",
    "        control_file.to_csv(path + '/control.csv')\n",
    "        \n",
    "        \n",
    "\n",
    "    except OSError as error: \n",
    "         raise Exception(error)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_currency_pair_df = []\n",
    "\n",
    "for d in all_currency_pairs:\n",
    "    \n",
    "    current_currency_df = pd.read_csv(\"../raw_weekly_data/\" + d + \".csv\", names = headers ) \n",
    "    \n",
    "    \n",
    "    \n",
    "    current_currency_df = current_currency_df.iloc[::-1]\n",
    "    \n",
    "    \n",
    "    current_currency_df = current_currency_df.reset_index(drop=True)\n",
    "    \n",
    "   \n",
    "      \n",
    "    current_currency_df = {'name': d.replace('10080',''),'dataframe': current_currency_df }\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_currency_pair_df.append(current_currency_df)\n",
    "    \n",
    "\n",
    "print(all_currency_pair_df)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_signal_percent = 55\n",
    "\n",
    "analysis_span = 12\n",
    "\n",
    "analysis_interval = 1\n",
    "\n",
    "no_of_weeks_analysis = [c for c in range(0, analysis_span, analysis_interval)]\n",
    "\n",
    "all_time_next_week_trade =[]\n",
    "\n",
    "for e in available_weeks:\n",
    "    \n",
    "    next_week_trade = []\n",
    "\n",
    "    for f in all_currency_pair_df:\n",
    "        \n",
    "        \n",
    "        current_currency_df = f['dataframe'].copy(deep = True)\n",
    "        \n",
    "        \n",
    "\n",
    "        current_currency_df = current_currency_df.loc[(current_currency_df['date'] <= e )   ] \n",
    "        \n",
    "        \n",
    "        \n",
    "        current_currency_df = current_currency_df.reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "\n",
    "        current_currency_df = current_currency_df.head(analysis_span)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(f['name'], current_currency_df)\n",
    "\n",
    "        needed_value_list = []\n",
    "        \n",
    "        needed_direction_list = []\n",
    "        \n",
    "        for g in no_of_weeks_analysis:\n",
    "            \n",
    "            needed_value = current_currency_df.copy()['close'][g]\n",
    "            \n",
    "            \n",
    "            needed_value_list.append(needed_value)\n",
    "            \n",
    "          \n",
    "        \n",
    "        #print(f['name'], needed_value_list)\n",
    "       \n",
    "        \n",
    "        for index, h in enumerate(needed_value_list):\n",
    "            \n",
    "            if index == 0:\n",
    "                \n",
    "                continue\n",
    "                \n",
    "            if h - needed_value_list[index-1] > 0 :\n",
    "                \n",
    "                needed_direction_list.append('S')\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                needed_direction_list.append('B')\n",
    "                \n",
    "                \n",
    "        #print(f['name'],needed_direction_list)  \n",
    "        \n",
    "        if (100 * needed_direction_list.count('S') / len(needed_direction_list) ) > acceptable_signal_percent:\n",
    "            \n",
    "            next_week_trade.append({'name': f['name'], 'direction': 'B'})\n",
    "        \n",
    "        if ( 100 * needed_direction_list.count('B') / len(needed_direction_list) ) > acceptable_signal_percent:\n",
    "            \n",
    "            next_week_trade.append({'name': f['name'], 'direction': 'S'})\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(next_week_trade) > 0:\n",
    "        \n",
    "        all_time_next_week_trade.append( {'week': e, 'next_week_trades': next_week_trade} )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('--------------------------------------------------------------------------------------------', e )\n",
    "    #print(next_week_trade)\n",
    "    #print(len(next_week_trade))\n",
    "    \n",
    "    \n",
    "    \n",
    "if len(all_time_next_week_trade) == 0:\n",
    "             \n",
    "    raise Exception(\"no week passed the acceptable_signal_percent \")\n",
    "        \n",
    "        \n",
    "    \n",
    "print(len(all_time_next_week_trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a nextweek trades dataframe for each week and saving the dataframe in that week'd folder\n",
    "\n",
    "for i in all_time_next_week_trade:\n",
    "    \n",
    "    current_week_data = i['next_week_trades']\n",
    "    current_week_name = i['week']\n",
    "    \n",
    "    \n",
    "    \n",
    "    currency_name =[]\n",
    "    trade_direction = []\n",
    "    \n",
    "    for j in current_week_data:\n",
    "        \n",
    "        currency_name.append(j['name'])\n",
    "        trade_direction.append(j['direction'])       \n",
    "          \n",
    "    \n",
    "    next_week_trades_dataframe = pd.DataFrame()\n",
    "    next_week_trades_dataframe['name']= currency_name\n",
    "    next_week_trades_dataframe['direction'] = trade_direction\n",
    "    \n",
    "    \n",
    "    print(next_week_trades_dataframe)\n",
    "\n",
    "    next_week_trades_dataframe.to_csv(\"files/\" + current_week_name + '/next_week_trades.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1333ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading 30 minutes data for all currency in to memeory to spead up processing\n",
    "\n",
    "all_currency_thirty_minutes_data = {}\n",
    "\n",
    "for z in all_currency_pairs:\n",
    "    current_currency = z.replace('10080','')\n",
    "    current_currency_df = pd.read_csv('../raw_30_minutes_data/' + current_currency + '30.csv', names=headers ) \n",
    "    \n",
    "    all_currency_thirty_minutes_data[current_currency] = current_currency_df\n",
    "    \n",
    "    #print( current_currency, )\n",
    "    \n",
    "    \n",
    "print(len(all_currency_thirty_minutes_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualified_weeks =[]\n",
    "\n",
    "for k in all_time_next_week_trade:\n",
    "    \n",
    "    current_week_data = k['next_week_trades']\n",
    "    current_week_date = k['week']\n",
    "    \n",
    "    current_week_date = datetime.strptime(current_week_date, '%Y.%m.%d')\n",
    "\n",
    "    week_start_date  = current_week_date + timedelta(days=7)\n",
    "    week_end_date = current_week_date + timedelta(days=12)\n",
    "    \n",
    "    current_week_date = current_week_date.strftime(\"%Y.%m.%d\")\n",
    "    week_start_date = week_start_date.strftime(\"%Y.%m.%d\")\n",
    "    week_end_date = week_end_date.strftime(\"%Y.%m.%d\")      \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    #print(current_week_date, week_start_date, week_end_date)\n",
    "    \n",
    "    qualified_currencies = 0\n",
    "   \n",
    "    for l in current_week_data:\n",
    "        \n",
    "        \n",
    "        current_currency = l['name'] \n",
    "        \n",
    "        current_currency_df = all_currency_thirty_minutes_data[current_currency].copy()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        current_currency_df = current_currency_df.loc[  (current_currency_df['date'] >= week_start_date)\n",
    "                                                   \n",
    "                                                                                 & \n",
    "                                                              (current_currency_df['date'] <= week_end_date)\n",
    "                                                            ]  \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        current_currency_df = current_currency_df.reset_index(drop=True )\n",
    "        \n",
    "        #print( current_currency, week_start_date, week_end_date, current_currency_df)\n",
    "       \n",
    "        \n",
    "       \n",
    "        current_currency_dataframe_row_ammount = len(current_currency_df.index)\n",
    "        \n",
    "        if  current_currency_dataframe_row_ammount < 238:\n",
    "            \n",
    "            print(current_currency,len(current_currency_df),week_start_date,'less than 238, skipping ',current_week_date)\n",
    "            break\n",
    "            \n",
    "            \n",
    "            #raise Exception(\"lenght is lesss than 238\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        if  current_currency_dataframe_row_ammount != 240:\n",
    "            \n",
    "           \n",
    "            \n",
    "            if (current_currency_df['ignore'].tail(1).values == '22:30' ):\n",
    "                \n",
    "              \n",
    "                \n",
    "                last_row = current_currency_df.copy().tail(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                last_row.tail()['ignore'] = '23:00'\n",
    "                \n",
    "                \n",
    "                current_currency_df = current_currency_df.append(last_row, ignore_index = True)\n",
    "                \n",
    "               \n",
    "                \n",
    "                \n",
    "                last_row.tail()['ignore'] = '23:30'\n",
    "                \n",
    "                current_currency_df = current_currency_df.append(last_row, ignore_index = True)\n",
    "                \n",
    "              \n",
    "                \n",
    "                #print(current_currency, current_currency_df)\n",
    "                \n",
    "                if  len(current_currency_df.index) != 240:\n",
    "              \n",
    "                    print(current_currency, current_currency_df)\n",
    "                    raise Exception(\"number of rows is still wrong after repair\")\n",
    "        \n",
    "            else:\n",
    "                \n",
    "                print(current_currency,len(current_currency_df),week_start_date,\"irrepairable,skipping \",current_week_date)\n",
    "                break\n",
    "        \n",
    "        if current_currency_df['ignore'].iloc[-1] != '23:30' :\n",
    "        \n",
    "            print(current_currency, current_currency_df)\n",
    "            raise Exception(\"last row is not 23:30\")\n",
    "        \n",
    "        \n",
    "      \n",
    "        \n",
    "        \n",
    "       \n",
    "        current_currency_df.to_csv(\"files/\" + k['week'] + '/' + current_currency +\".csv\", index=None)\n",
    "        \n",
    "        qualified_currencies = qualified_currencies +1\n",
    "        \n",
    "        \n",
    "        \n",
    "    if qualified_currencies == len(current_week_data):\n",
    "            \n",
    "        qualified_weeks.append(k)\n",
    "        \n",
    "    \n",
    "   \n",
    "        \n",
    "        #print(current_currency_df)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #print('-----------------------------------------------------------------------------------------------', week_start_date)\n",
    "\n",
    "\n",
    "print(len(qualified_weeks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe25e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6dff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe = []\n",
    "trade_values = []\n",
    "unique_time_frames = []\n",
    "\n",
    "for m in qualified_weeks:\n",
    "\n",
    "    \n",
    "    \n",
    "    current_week = m['week']\n",
    "   \n",
    "    current_week_data = m['next_week_trades']\n",
    "    \n",
    "    current_week_drawdown_df = pd.DataFrame()\n",
    "    \n",
    "    current_week_profit = pd.DataFrame()\n",
    "  \n",
    "\n",
    "    \n",
    "    \n",
    "    for index, n in enumerate(current_week_data):\n",
    "        \n",
    "        \n",
    "        \n",
    "        current_currency = n['name']\n",
    "        current_currency_direction = n['direction']\n",
    "        current_currency_df =  pd.read_csv(\"files/\" + current_week + '/' + current_currency +\".csv\" ) \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        # adding timeframe to the maximal draw down and profit df\n",
    "        if index == 0:\n",
    "            \n",
    "            current_week_drawdown_df['date'] = current_currency_df['date']\n",
    "            current_week_profit['date'] = current_currency_df['date']\n",
    "           \n",
    "            #saving unique_timeframes in a week to use later in the script\n",
    "            if len(unique_time_frames) == 0:\n",
    "                \n",
    "                unique_time_frames = current_currency_df['ignore'].values\n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        #print(current_currency_df)\n",
    "        maximal_draw_down =[]\n",
    "        profit = []\n",
    "        pips_corrector = 100000\n",
    "            \n",
    "        if current_currency.endswith('JPY'):\n",
    "                \n",
    "            pips_corrector = 1000\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        for o in range(240):\n",
    "                   \n",
    "            if current_currency_direction == 'B':\n",
    "                \n",
    "                \n",
    "                dd = current_currency_df.loc[o,'low'] - current_currency_df.loc[0,'open']\n",
    "                p = current_currency_df.loc[o,'close'] - current_currency_df.loc[0,'open']\n",
    "              \n",
    "            if current_currency_direction == 'S':\n",
    "                \n",
    "                \n",
    "                dd = current_currency_df.loc[0,'open'] - current_currency_df.loc[o,'high']\n",
    "                p = current_currency_df.loc[0,'open'] - current_currency_df.loc[o,'close']\n",
    "            \n",
    "            \n",
    "            maximal_draw_down.append(dd*pips_corrector)\n",
    "            profit.append(p*pips_corrector)\n",
    "                \n",
    "        \n",
    "        current_week_drawdown_df[current_currency] = maximal_draw_down\n",
    "        current_week_profit[current_currency] = profit\n",
    "            \n",
    "    current_week_drawdown_df['empty'] = ['' for p in range(240)]      \n",
    "    current_week_drawdown_df[\"sum\"] = current_week_drawdown_df.drop([\"empty\", 'date'], axis=1, inplace=False).sum(axis=1)        \n",
    "    \n",
    "    current_week_drawdown_df.to_csv(\"files/\" + current_week + '/' + 'maximal_draw_down.csv', index= None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    current_week_profit['empty'] = ['' for p in range(240)]      \n",
    "    current_week_profit[\"sum\"] = current_week_profit.drop([\"empty\", 'date'], axis=1, inplace=False).sum(axis=1)        \n",
    "    \n",
    "    current_week_profit.to_csv(\"files/\" + current_week + '/' + 'profit.csv', index= None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(current_week_drawdown_df)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('--------------------------------------------------------------------------------------------------', m)   \n",
    "    \n",
    "    \n",
    "#print(current_week_drawdown_df)\n",
    "#print(current_week_profit)\n",
    "\n",
    "print(unique_time_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_time_frames = []\n",
    "\n",
    "for index, w in enumerate(unique_time_frames):\n",
    "    \n",
    "    if index >= 192: \n",
    "        day = 'FRI'  \n",
    "        day_time_frames.append(day + ' ' + w)\n",
    "        \n",
    "    elif index >= 144: \n",
    "        day = 'THUR'  \n",
    "        day_time_frames.append(day + ' ' + w)\n",
    "        \n",
    "    elif index >=96: \n",
    "        day = 'WED'  \n",
    "        day_time_frames.append(day + ' ' + w)\n",
    "        \n",
    "    elif index >=48: \n",
    "        day = 'TUE'  \n",
    "        day_time_frames.append(day + ' ' + w)\n",
    "        \n",
    "    else: \n",
    "        day = 'MON'  \n",
    "        day_time_frames.append(day + ' ' + w)\n",
    "    \n",
    "   \n",
    "    \n",
    "print(len(day_time_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all maximal drawdowns for all weeks\n",
    "combine_week_drawdown_df = pd.DataFrame()\n",
    "\n",
    "combine_week_drawdown_df['date'] = day_time_frames\n",
    "\n",
    "for index, q in enumerate(qualified_weeks):\n",
    "    \n",
    "    current_week = q['week']\n",
    "    current_week_dd_df = pd.read_csv(\"files/\" + current_week + '/' + 'maximal_draw_down' +\".csv\" ) \n",
    "    #print(current_week_dd_df)\n",
    "    \n",
    "   \n",
    "    combine_week_drawdown_df[current_week] = current_week_dd_df['sum']\n",
    "    \n",
    "\n",
    "combine_week_drawdown_df['empty'] = ['' for r in range(240)]      \n",
    "combine_week_drawdown_df[\"sum\"] = combine_week_drawdown_df.drop([\"empty\",'date' ], axis=1, inplace=False).sum(axis=1)        \n",
    "\n",
    "combine_week_drawdown_df.to_csv(\"files/\" + 'combine_week_drawdown_df.csv', index= None)\n",
    "\n",
    "print(combine_week_drawdown_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b832ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all profits drawdowns for all weeks\n",
    "combine_week_profit_df = pd.DataFrame()\n",
    "\n",
    "combine_week_profit_df['date'] = day_time_frames\n",
    "\n",
    "for index, q in enumerate(qualified_weeks):\n",
    "    \n",
    "    current_week = q['week']\n",
    "    current_week_profit_df = pd.read_csv(\"files/\" + current_week + '/' + 'profit' +\".csv\" ) \n",
    "    #print(current_week_dd_df)\n",
    "    \n",
    "   \n",
    "    combine_week_profit_df[current_week] = current_week_profit_df['sum']\n",
    "    \n",
    "\n",
    "combine_week_profit_df['empty'] = ['' for r in range(240)]      \n",
    "combine_week_profit_df[\"sum\"] = combine_week_profit_df.drop([\"empty\",'date' ], axis=1, inplace=False).sum(axis=1)        \n",
    "\n",
    "combine_week_profit_df.to_csv(\"files/\" + 'combine_week_profit_df.csv', index= None)\n",
    "\n",
    "print(combine_week_profit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c7f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all profit and drawdown dataframe to memory to speed up processing\n",
    "\n",
    "qualified_weeks_dfs=[]\n",
    "\n",
    "for v in qualified_weeks:\n",
    "    \n",
    "    current_week = v['week']\n",
    "\n",
    "    current_week_profit_df = pd.read_csv(\"files/\" + current_week + '/profit.csv')\n",
    "    current_week_drawdown_df = pd.read_csv(\"files/\" + current_week + '/maximal_draw_down.csv')\n",
    "    \n",
    "    qualified_weeks_dfs.append( \n",
    "                                { 'week': current_week,\n",
    "                                   'profit_df' : current_week_profit_df,\n",
    "                                   'drawdown_df': current_week_drawdown_df\n",
    "                                }\n",
    "                                )\n",
    "    \n",
    "\n",
    "print(qualified_weeks_dfs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bdfc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_df = pd.DataFrame()\n",
    "\n",
    "start_date_index_list =[]\n",
    "\n",
    "cut_off_date_index_list =[]\n",
    "\n",
    "draw_down_list = []\n",
    "\n",
    "total_spread_list = []\n",
    "\n",
    "profit_list=[]\n",
    "\n",
    "profit_ratio_list=[]\n",
    "\n",
    "\n",
    "#combine_week_drawdown_df = pd.read_csv(\"files/\" + 'combine_week_drawdown_df.csv')\n",
    "#combine_week_profit_df = pd.read_csv(\"files/\" + 'combine_week_profit_df.csv')\n",
    "\n",
    "\n",
    "#print(combine_week_drawdown_df)\n",
    "\n",
    "start_date_index = [f for f in range(0, 239)]\n",
    "\n",
    "\n",
    "draw_down = [f*-1 for f in range(100, 3000, 100)] \n",
    "\n",
    "\n",
    "total_spread = -200\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for t in start_date_index:\n",
    "    \n",
    "    cut_off_date_index =   [f+1 for f in range( 1,(240-t)  ) ]\n",
    "    \n",
    "    #print(cut_off_date_index)\n",
    "    \n",
    "    for g in cut_off_date_index:\n",
    "        \n",
    "        \n",
    "        for q in draw_down :\n",
    "            \n",
    "            \n",
    "            strategy_profit = []\n",
    "            \n",
    "            current_maximal_drawdown = q + total_spread\n",
    "            \n",
    "            \n",
    "            for s in qualified_weeks_dfs:\n",
    "                \n",
    "                current_week_calculated_profit = None\n",
    "                \n",
    "                current_drawdown_df = s['drawdown_df'].copy()\n",
    "                current_drawdown_df = current_drawdown_df.iloc[t:]\n",
    "              \n",
    "                current_drawdown_df = current_drawdown_df.reset_index(drop=True)   \n",
    "                current_drawdown_df = current_drawdown_df.iloc[:g]\n",
    "                current_week_drawdown_list = current_drawdown_df['sum'].values\n",
    "                \n",
    "               \n",
    "                \n",
    "                \n",
    "\n",
    "                current_profit_df = s['profit_df'].copy()\n",
    "                current_profit_df = current_profit_df.iloc[t:]\n",
    "                current_profit_df = current_profit_df.reset_index(drop=True)\n",
    "                current_profit_df = current_profit_df.iloc[:g]\n",
    "                current_week_profit_list = current_profit_df['sum'].values\n",
    "                \n",
    "                \n",
    "                \n",
    "                #print(current_week_profit_list)\n",
    "                \n",
    "            \n",
    "                for r in range(len(current_week_drawdown_list)):\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    current_drawdown = current_week_drawdown_list[r] - current_week_profit_list[0]\n",
    "                    \n",
    "                    current_profit = current_week_profit_list[r] - current_week_profit_list[0]\n",
    "                    \n",
    "                    \n",
    "                    if r == 0:\n",
    "                        #skipping the first row\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    if current_drawdown <= q:\n",
    "                        \n",
    "                        \n",
    "                        current_week_calculated_profit = current_maximal_drawdown\n",
    "                    \n",
    "                        break\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                if current_week_calculated_profit == None:\n",
    "                    \n",
    "                    current_week_calculated_profit = current_profit\n",
    "                    \n",
    "                \n",
    "                strategy_profit.append(current_week_calculated_profit)\n",
    "                \n",
    "            total_profit = sum(strategy_profit)\n",
    "            \n",
    "            profit_ratio = total_profit/(10*current_maximal_drawdown*-1)\n",
    "            \n",
    "            if profit_ratio > 1 :\n",
    "                \n",
    "                print( 'profit_ratio : ', profit_ratio)\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            #print( 'start:', t+1, '  end:', g, '  drawdown:',q , '  profit:', total_profit, 'profit_ratio:',profit_ratio )\n",
    "                \n",
    "            start_date_index_list.append(t+1)\n",
    "\n",
    "            cut_off_date_index_list.append(g)\n",
    "\n",
    "            draw_down_list.append(q)\n",
    "\n",
    "            total_spread_list.append(total_spread)\n",
    "\n",
    "            profit_list.append(total_profit)\n",
    "\n",
    "            profit_ratio_list.append(profit_ratio)\n",
    "            \n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_df['start_date_index'] = start_date_index_list\n",
    "\n",
    "\n",
    "statistic_df['cut_off_date_index'] = cut_off_date_index_list\n",
    "\n",
    "statistic_df['total_spread'] = total_spread_list\n",
    "\n",
    "statistic_df['draw_down'] = draw_down_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "statistic_df['profit'] = profit_list\n",
    "\n",
    "statistic_df['profit_ratio'] = profit_ratio_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(statistic_df)\n",
    "statistic_df.to_csv('files/statistic_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809a4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
