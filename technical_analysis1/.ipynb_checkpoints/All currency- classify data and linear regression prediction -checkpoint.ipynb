{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "37ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fde693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_list = ['USDCHF10080',\n",
    "                 #'GBPUSD10080', 'EURUSD10080', 'USDJPY10080', 'USDCAD10080', 'AUDUSD10080', 'NZDUSD10080',\n",
    "                 #'GBPCHF10080', 'EURCHF10080', 'CHFJPY10080', 'CADCHF10080', 'AUDCHF10080', 'NZDCHF10080', 'EURGBP10080',\n",
    "                 #'GBPJPY10080', 'GBPCAD10080', 'GBPAUD10080', 'EURJPY10080', 'EURCAD10080', 'EURAUD10080', 'EURNZD10080',\n",
    "                #'CADJPY10080', 'AUDJPY10080', 'NZDJPY10080', 'AUDCAD10080', 'NZDCAD10080', 'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "# for q in currency_list:\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     for x in range(5):\n",
    "\n",
    "#         currency = q.replace('10080','')\n",
    "\n",
    "#         data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "#         #data = data.head(695)\n",
    "\n",
    "\n",
    "#         X = data.drop(columns=['Unnamed: 0', \n",
    "#                                'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "#                               ])\n",
    "\n",
    "\n",
    "\n",
    "#         y = data['nextweek_class']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 )\n",
    "\n",
    "\n",
    "\n",
    "#         lnr= LinearRegression()\n",
    "#         lnr.fit(X_train, y_train)\n",
    "#         y_predict = lnr.predict(X_test)\n",
    "        \n",
    "        \n",
    "#         error = sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         errors.append(error)\n",
    "       \n",
    "        \n",
    "#     average_error = sum(errors)/len(errors)\n",
    "       \n",
    "#     print(q + \" Linear regression Average \" + str(average_error))\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1fcc8706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(691, 5, 27) (691,)\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_86 (LSTM)               (None, 5, 10)             1520      \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, 5, 10)             840       \n",
      "_________________________________________________________________\n",
      "lstm_88 (LSTM)               (None, 10)                840       \n",
      "=================================================================\n",
      "Total params: 3,200\n",
      "Trainable params: 3,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/250\n",
      "18/18 [==============================] - 5s 55ms/step - loss: 12.4946 - accuracy: 0.0254 - val_loss: 11.4668 - val_accuracy: 0.0504\n",
      "Epoch 2/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.4940 - accuracy: 0.0290 - val_loss: 11.4670 - val_accuracy: 0.0576\n",
      "Epoch 3/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.4935 - accuracy: 0.0290 - val_loss: 11.4669 - val_accuracy: 0.0576\n",
      "Epoch 4/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.4928 - accuracy: 0.0272 - val_loss: 11.4666 - val_accuracy: 0.0432\n",
      "Epoch 5/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.4916 - accuracy: 0.0217 - val_loss: 11.4661 - val_accuracy: 0.0432\n",
      "Epoch 6/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.4900 - accuracy: 0.0217 - val_loss: 11.4651 - val_accuracy: 0.0432\n",
      "Epoch 7/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.4872 - accuracy: 0.0217 - val_loss: 11.4635 - val_accuracy: 0.0360\n",
      "Epoch 8/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.4819 - accuracy: 0.0181 - val_loss: 11.4596 - val_accuracy: 0.0360\n",
      "Epoch 9/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.4709 - accuracy: 0.0181 - val_loss: 11.4519 - val_accuracy: 0.0360\n",
      "Epoch 10/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.4500 - accuracy: 0.0163 - val_loss: 11.4395 - val_accuracy: 0.0432\n",
      "Epoch 11/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.4151 - accuracy: 0.0254 - val_loss: 11.4332 - val_accuracy: 0.0360\n",
      "Epoch 12/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.3853 - accuracy: 0.0272 - val_loss: 11.4403 - val_accuracy: 0.0504\n",
      "Epoch 13/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.3518 - accuracy: 0.0236 - val_loss: 11.4527 - val_accuracy: 0.0360\n",
      "Epoch 14/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.3265 - accuracy: 0.0290 - val_loss: 11.4431 - val_accuracy: 0.0360\n",
      "Epoch 15/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.3009 - accuracy: 0.0254 - val_loss: 11.4493 - val_accuracy: 0.0360\n",
      "Epoch 16/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.2670 - accuracy: 0.0290 - val_loss: 11.4481 - val_accuracy: 0.0432\n",
      "Epoch 17/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.2577 - accuracy: 0.0399 - val_loss: 11.4715 - val_accuracy: 0.0432\n",
      "Epoch 18/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.2449 - accuracy: 0.0399 - val_loss: 11.4485 - val_accuracy: 0.0504\n",
      "Epoch 19/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.2115 - accuracy: 0.0435 - val_loss: 11.4776 - val_accuracy: 0.0576\n",
      "Epoch 20/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.1997 - accuracy: 0.0417 - val_loss: 11.4782 - val_accuracy: 0.0576\n",
      "Epoch 21/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.1743 - accuracy: 0.0453 - val_loss: 11.4731 - val_accuracy: 0.0576\n",
      "Epoch 22/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.1621 - accuracy: 0.0471 - val_loss: 11.4938 - val_accuracy: 0.0576\n",
      "Epoch 23/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.1283 - accuracy: 0.0453 - val_loss: 11.4865 - val_accuracy: 0.0576\n",
      "Epoch 24/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.1329 - accuracy: 0.0471 - val_loss: 11.5228 - val_accuracy: 0.0576\n",
      "Epoch 25/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0965 - accuracy: 0.0471 - val_loss: 11.5368 - val_accuracy: 0.0504\n",
      "Epoch 26/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0822 - accuracy: 0.0453 - val_loss: 11.5288 - val_accuracy: 0.0576\n",
      "Epoch 27/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0553 - accuracy: 0.0471 - val_loss: 11.5758 - val_accuracy: 0.0576\n",
      "Epoch 28/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0392 - accuracy: 0.0453 - val_loss: 11.5459 - val_accuracy: 0.0504\n",
      "Epoch 29/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0350 - accuracy: 0.0435 - val_loss: 11.5437 - val_accuracy: 0.0432\n",
      "Epoch 30/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0161 - accuracy: 0.0435 - val_loss: 11.5180 - val_accuracy: 0.0504\n",
      "Epoch 31/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9958 - accuracy: 0.0435 - val_loss: 11.5042 - val_accuracy: 0.0504\n",
      "Epoch 32/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9717 - accuracy: 0.0453 - val_loss: 11.4493 - val_accuracy: 0.0432\n",
      "Epoch 33/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9858 - accuracy: 0.0417 - val_loss: 11.4727 - val_accuracy: 0.0576\n",
      "Epoch 34/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9532 - accuracy: 0.0417 - val_loss: 11.4613 - val_accuracy: 0.0576\n",
      "Epoch 35/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9566 - accuracy: 0.0417 - val_loss: 11.4660 - val_accuracy: 0.0576\n",
      "Epoch 36/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9472 - accuracy: 0.0435 - val_loss: 11.4661 - val_accuracy: 0.0647\n",
      "Epoch 37/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9379 - accuracy: 0.0435 - val_loss: 11.4626 - val_accuracy: 0.0647\n",
      "Epoch 38/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9326 - accuracy: 0.0399 - val_loss: 11.4982 - val_accuracy: 0.0647\n",
      "Epoch 39/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9391 - accuracy: 0.0435 - val_loss: 11.5037 - val_accuracy: 0.0647\n",
      "Epoch 40/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9266 - accuracy: 0.0399 - val_loss: 11.4813 - val_accuracy: 0.0647\n",
      "Epoch 41/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9409 - accuracy: 0.0362 - val_loss: 11.4817 - val_accuracy: 0.0576\n",
      "Epoch 42/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9477 - accuracy: 0.0417 - val_loss: 11.4821 - val_accuracy: 0.0647\n",
      "Epoch 43/250\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.9479 - accuracy: 0.0435 - val_loss: 11.4498 - val_accuracy: 0.0719\n",
      "Epoch 44/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9391 - accuracy: 0.0417 - val_loss: 11.4602 - val_accuracy: 0.0719\n",
      "Epoch 45/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9292 - accuracy: 0.0417 - val_loss: 11.4591 - val_accuracy: 0.0719\n",
      "Epoch 46/250\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.9232 - accuracy: 0.0417 - val_loss: 11.4538 - val_accuracy: 0.0647\n",
      "Epoch 47/250\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 11.9240 - accuracy: 0.0435 - val_loss: 11.4283 - val_accuracy: 0.0719\n",
      "Epoch 48/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9179 - accuracy: 0.0417 - val_loss: 11.4401 - val_accuracy: 0.0719\n",
      "Epoch 49/250\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 11.9241 - accuracy: 0.0417 - val_loss: 11.4616 - val_accuracy: 0.0719\n",
      "Epoch 50/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9179 - accuracy: 0.0399 - val_loss: 11.4549 - val_accuracy: 0.0719\n",
      "Epoch 51/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9215 - accuracy: 0.0380 - val_loss: 11.4051 - val_accuracy: 0.0719\n",
      "Epoch 52/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9277 - accuracy: 0.0380 - val_loss: 11.4521 - val_accuracy: 0.0647\n",
      "Epoch 53/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9312 - accuracy: 0.0362 - val_loss: 11.4488 - val_accuracy: 0.0647\n",
      "Epoch 54/250\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 11.9136 - accuracy: 0.0362 - val_loss: 11.4253 - val_accuracy: 0.0719\n",
      "Epoch 55/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8973 - accuracy: 0.0380 - val_loss: 11.4265 - val_accuracy: 0.0719\n",
      "Epoch 56/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8905 - accuracy: 0.0362 - val_loss: 11.4337 - val_accuracy: 0.0719\n",
      "Epoch 57/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8891 - accuracy: 0.0380 - val_loss: 11.4413 - val_accuracy: 0.0719\n",
      "Epoch 58/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8875 - accuracy: 0.0380 - val_loss: 11.4413 - val_accuracy: 0.0647\n",
      "Epoch 59/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8858 - accuracy: 0.0380 - val_loss: 11.4474 - val_accuracy: 0.0719\n",
      "Epoch 60/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8838 - accuracy: 0.0362 - val_loss: 11.4563 - val_accuracy: 0.0719\n",
      "Epoch 61/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8823 - accuracy: 0.0362 - val_loss: 11.4636 - val_accuracy: 0.0647\n",
      "Epoch 62/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8799 - accuracy: 0.0362 - val_loss: 11.4510 - val_accuracy: 0.0719\n",
      "Epoch 63/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8753 - accuracy: 0.0344 - val_loss: 11.4565 - val_accuracy: 0.0647\n",
      "Epoch 64/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8733 - accuracy: 0.0344 - val_loss: 11.4609 - val_accuracy: 0.0647\n",
      "Epoch 65/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8722 - accuracy: 0.0344 - val_loss: 11.4668 - val_accuracy: 0.0576\n",
      "Epoch 66/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8719 - accuracy: 0.0344 - val_loss: 11.4684 - val_accuracy: 0.0647\n",
      "Epoch 67/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8710 - accuracy: 0.0362 - val_loss: 11.4676 - val_accuracy: 0.0647\n",
      "Epoch 68/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8673 - accuracy: 0.0344 - val_loss: 11.4680 - val_accuracy: 0.0576\n",
      "Epoch 69/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8670 - accuracy: 0.0344 - val_loss: 11.4689 - val_accuracy: 0.0576\n",
      "Epoch 70/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8662 - accuracy: 0.0344 - val_loss: 11.4802 - val_accuracy: 0.0576\n",
      "Epoch 71/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8760 - accuracy: 0.0380 - val_loss: 11.4802 - val_accuracy: 0.0576\n",
      "Epoch 72/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8826 - accuracy: 0.0380 - val_loss: 11.4866 - val_accuracy: 0.0647\n",
      "Epoch 73/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8852 - accuracy: 0.0417 - val_loss: 11.5025 - val_accuracy: 0.0576\n",
      "Epoch 74/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8940 - accuracy: 0.0380 - val_loss: 11.4955 - val_accuracy: 0.0504\n",
      "Epoch 75/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9006 - accuracy: 0.0399 - val_loss: 11.4888 - val_accuracy: 0.0576\n",
      "Epoch 76/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8903 - accuracy: 0.0380 - val_loss: 11.5080 - val_accuracy: 0.0504\n",
      "Epoch 77/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8897 - accuracy: 0.0399 - val_loss: 11.4974 - val_accuracy: 0.0647\n",
      "Epoch 78/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8808 - accuracy: 0.0399 - val_loss: 11.4629 - val_accuracy: 0.0576\n",
      "Epoch 79/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8859 - accuracy: 0.0399 - val_loss: 11.4515 - val_accuracy: 0.0504\n",
      "Epoch 80/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9305 - accuracy: 0.0417 - val_loss: 11.4244 - val_accuracy: 0.0576\n",
      "Epoch 81/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9383 - accuracy: 0.0435 - val_loss: 11.4170 - val_accuracy: 0.0719\n",
      "Epoch 82/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9424 - accuracy: 0.0435 - val_loss: 11.4138 - val_accuracy: 0.0647\n",
      "Epoch 83/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9808 - accuracy: 0.0362 - val_loss: 11.3756 - val_accuracy: 0.0647\n",
      "Epoch 84/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9822 - accuracy: 0.0417 - val_loss: 11.3727 - val_accuracy: 0.0432\n",
      "Epoch 85/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9423 - accuracy: 0.0399 - val_loss: 11.4090 - val_accuracy: 0.0576\n",
      "Epoch 86/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9298 - accuracy: 0.0399 - val_loss: 11.3870 - val_accuracy: 0.0576\n",
      "Epoch 87/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9272 - accuracy: 0.0399 - val_loss: 11.4240 - val_accuracy: 0.0576\n",
      "Epoch 88/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8985 - accuracy: 0.0399 - val_loss: 11.4075 - val_accuracy: 0.0576\n",
      "Epoch 89/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9610 - accuracy: 0.0326 - val_loss: 11.4289 - val_accuracy: 0.0504\n",
      "Epoch 90/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9764 - accuracy: 0.0344 - val_loss: 11.4182 - val_accuracy: 0.0432\n",
      "Epoch 91/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9493 - accuracy: 0.0362 - val_loss: 11.3844 - val_accuracy: 0.0576\n",
      "Epoch 92/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9349 - accuracy: 0.0344 - val_loss: 11.3940 - val_accuracy: 0.0432\n",
      "Epoch 93/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9179 - accuracy: 0.0344 - val_loss: 11.4072 - val_accuracy: 0.0432\n",
      "Epoch 94/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9137 - accuracy: 0.0344 - val_loss: 11.4063 - val_accuracy: 0.0504\n",
      "Epoch 95/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8951 - accuracy: 0.0399 - val_loss: 11.3941 - val_accuracy: 0.0432\n",
      "Epoch 96/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8828 - accuracy: 0.0399 - val_loss: 11.3900 - val_accuracy: 0.0360\n",
      "Epoch 97/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8737 - accuracy: 0.0417 - val_loss: 11.3849 - val_accuracy: 0.0432\n",
      "Epoch 98/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8722 - accuracy: 0.0435 - val_loss: 11.3815 - val_accuracy: 0.0432\n",
      "Epoch 99/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8706 - accuracy: 0.0417 - val_loss: 11.3817 - val_accuracy: 0.0432\n",
      "Epoch 100/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8697 - accuracy: 0.0417 - val_loss: 11.3741 - val_accuracy: 0.0432\n",
      "Epoch 101/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8686 - accuracy: 0.0435 - val_loss: 11.3720 - val_accuracy: 0.0432\n",
      "Epoch 102/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8679 - accuracy: 0.0417 - val_loss: 11.3719 - val_accuracy: 0.0504\n",
      "Epoch 103/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8674 - accuracy: 0.0435 - val_loss: 11.3732 - val_accuracy: 0.0504\n",
      "Epoch 104/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8670 - accuracy: 0.0435 - val_loss: 11.3758 - val_accuracy: 0.0504\n",
      "Epoch 105/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8669 - accuracy: 0.0417 - val_loss: 11.3746 - val_accuracy: 0.0504\n",
      "Epoch 106/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8664 - accuracy: 0.0417 - val_loss: 11.3818 - val_accuracy: 0.0504\n",
      "Epoch 107/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8661 - accuracy: 0.0417 - val_loss: 11.3849 - val_accuracy: 0.0504\n",
      "Epoch 108/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8656 - accuracy: 0.0399 - val_loss: 11.3892 - val_accuracy: 0.0504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8613 - accuracy: 0.0399 - val_loss: 11.3907 - val_accuracy: 0.0432\n",
      "Epoch 110/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8627 - accuracy: 0.0399 - val_loss: 11.3857 - val_accuracy: 0.0504\n",
      "Epoch 111/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8604 - accuracy: 0.0399 - val_loss: 11.3759 - val_accuracy: 0.0504\n",
      "Epoch 112/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8660 - accuracy: 0.0417 - val_loss: 11.3784 - val_accuracy: 0.0504\n",
      "Epoch 113/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8658 - accuracy: 0.0435 - val_loss: 11.3896 - val_accuracy: 0.0504\n",
      "Epoch 114/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8650 - accuracy: 0.0435 - val_loss: 11.3950 - val_accuracy: 0.0504\n",
      "Epoch 115/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8616 - accuracy: 0.0435 - val_loss: 11.3938 - val_accuracy: 0.0504\n",
      "Epoch 116/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8610 - accuracy: 0.0435 - val_loss: 11.3947 - val_accuracy: 0.0504\n",
      "Epoch 117/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8597 - accuracy: 0.0417 - val_loss: 11.3914 - val_accuracy: 0.0432\n",
      "Epoch 118/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8606 - accuracy: 0.0417 - val_loss: 11.3829 - val_accuracy: 0.0504\n",
      "Epoch 119/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8574 - accuracy: 0.0417 - val_loss: 11.3792 - val_accuracy: 0.0504\n",
      "Epoch 120/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8571 - accuracy: 0.0417 - val_loss: 11.3762 - val_accuracy: 0.0504\n",
      "Epoch 121/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8540 - accuracy: 0.0417 - val_loss: 11.3717 - val_accuracy: 0.0504\n",
      "Epoch 122/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8536 - accuracy: 0.0417 - val_loss: 11.3688 - val_accuracy: 0.0504\n",
      "Epoch 123/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8534 - accuracy: 0.0417 - val_loss: 11.3694 - val_accuracy: 0.0504\n",
      "Epoch 124/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8533 - accuracy: 0.0417 - val_loss: 11.3679 - val_accuracy: 0.0504\n",
      "Epoch 125/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8532 - accuracy: 0.0417 - val_loss: 11.3654 - val_accuracy: 0.0504\n",
      "Epoch 126/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8530 - accuracy: 0.0417 - val_loss: 11.3643 - val_accuracy: 0.0504\n",
      "Epoch 127/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8529 - accuracy: 0.0417 - val_loss: 11.3620 - val_accuracy: 0.0504\n",
      "Epoch 128/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8528 - accuracy: 0.0417 - val_loss: 11.3600 - val_accuracy: 0.0504\n",
      "Epoch 129/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8525 - accuracy: 0.0417 - val_loss: 11.3632 - val_accuracy: 0.0504\n",
      "Epoch 130/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8534 - accuracy: 0.0417 - val_loss: 11.3729 - val_accuracy: 0.0504\n",
      "Epoch 131/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8506 - accuracy: 0.0417 - val_loss: 11.3517 - val_accuracy: 0.0504\n",
      "Epoch 132/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8572 - accuracy: 0.0399 - val_loss: 11.3459 - val_accuracy: 0.0504\n",
      "Epoch 133/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8563 - accuracy: 0.0417 - val_loss: 11.3394 - val_accuracy: 0.0504\n",
      "Epoch 134/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8502 - accuracy: 0.0417 - val_loss: 11.3540 - val_accuracy: 0.0504\n",
      "Epoch 135/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8496 - accuracy: 0.0417 - val_loss: 11.3609 - val_accuracy: 0.0504\n",
      "Epoch 136/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8493 - accuracy: 0.0417 - val_loss: 11.3637 - val_accuracy: 0.0504\n",
      "Epoch 137/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8491 - accuracy: 0.0417 - val_loss: 11.3662 - val_accuracy: 0.0504\n",
      "Epoch 138/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8489 - accuracy: 0.0417 - val_loss: 11.3669 - val_accuracy: 0.0504\n",
      "Epoch 139/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8488 - accuracy: 0.0417 - val_loss: 11.3682 - val_accuracy: 0.0504\n",
      "Epoch 140/250\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.8486 - accuracy: 0.0417 - val_loss: 11.3678 - val_accuracy: 0.0504\n",
      "Epoch 141/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8485 - accuracy: 0.0417 - val_loss: 11.3686 - val_accuracy: 0.0504\n",
      "Epoch 142/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8484 - accuracy: 0.0417 - val_loss: 11.3680 - val_accuracy: 0.0504\n",
      "Epoch 143/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8483 - accuracy: 0.0417 - val_loss: 11.3688 - val_accuracy: 0.0504\n",
      "Epoch 144/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8482 - accuracy: 0.0417 - val_loss: 11.3729 - val_accuracy: 0.0504\n",
      "Epoch 145/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8479 - accuracy: 0.0417 - val_loss: 11.3760 - val_accuracy: 0.0432\n",
      "Epoch 146/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8449 - accuracy: 0.0417 - val_loss: 11.3884 - val_accuracy: 0.0432\n",
      "Epoch 147/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8446 - accuracy: 0.0417 - val_loss: 11.3910 - val_accuracy: 0.0432\n",
      "Epoch 148/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8445 - accuracy: 0.0417 - val_loss: 11.3928 - val_accuracy: 0.0432\n",
      "Epoch 149/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8445 - accuracy: 0.0417 - val_loss: 11.3974 - val_accuracy: 0.0432\n",
      "Epoch 150/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8444 - accuracy: 0.0417 - val_loss: 11.3970 - val_accuracy: 0.0432\n",
      "Epoch 151/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8442 - accuracy: 0.0417 - val_loss: 11.3978 - val_accuracy: 0.0432\n",
      "Epoch 152/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8440 - accuracy: 0.0417 - val_loss: 11.4040 - val_accuracy: 0.0432\n",
      "Epoch 153/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8401 - accuracy: 0.0417 - val_loss: 11.4012 - val_accuracy: 0.0432\n",
      "Epoch 154/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8410 - accuracy: 0.0417 - val_loss: 11.4027 - val_accuracy: 0.0432\n",
      "Epoch 155/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8336 - accuracy: 0.0417 - val_loss: 11.4033 - val_accuracy: 0.0432\n",
      "Epoch 156/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8333 - accuracy: 0.0417 - val_loss: 11.4004 - val_accuracy: 0.0432\n",
      "Epoch 157/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8332 - accuracy: 0.0417 - val_loss: 11.4004 - val_accuracy: 0.0432\n",
      "Epoch 158/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8439 - accuracy: 0.0417 - val_loss: 11.4077 - val_accuracy: 0.0432\n",
      "Epoch 159/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8335 - accuracy: 0.0417 - val_loss: 11.4134 - val_accuracy: 0.0432\n",
      "Epoch 160/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8334 - accuracy: 0.0417 - val_loss: 11.4124 - val_accuracy: 0.0432\n",
      "Epoch 161/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8332 - accuracy: 0.0417 - val_loss: 11.4114 - val_accuracy: 0.0432\n",
      "Epoch 162/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8331 - accuracy: 0.0417 - val_loss: 11.4101 - val_accuracy: 0.0432\n",
      "Epoch 163/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8327 - accuracy: 0.0417 - val_loss: 11.4136 - val_accuracy: 0.0432\n",
      "Epoch 164/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8295 - accuracy: 0.0417 - val_loss: 11.4163 - val_accuracy: 0.0432\n",
      "Epoch 165/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8294 - accuracy: 0.0417 - val_loss: 11.4068 - val_accuracy: 0.0432\n",
      "Epoch 166/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8292 - accuracy: 0.0417 - val_loss: 11.4009 - val_accuracy: 0.0432\n",
      "Epoch 167/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8292 - accuracy: 0.0417 - val_loss: 11.4002 - val_accuracy: 0.0432\n",
      "Epoch 168/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8291 - accuracy: 0.0417 - val_loss: 11.4006 - val_accuracy: 0.0432\n",
      "Epoch 169/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8290 - accuracy: 0.0417 - val_loss: 11.4007 - val_accuracy: 0.0432\n",
      "Epoch 170/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8289 - accuracy: 0.0417 - val_loss: 11.4014 - val_accuracy: 0.0432\n",
      "Epoch 171/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8288 - accuracy: 0.0417 - val_loss: 11.4024 - val_accuracy: 0.0432\n",
      "Epoch 172/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8286 - accuracy: 0.0417 - val_loss: 11.4019 - val_accuracy: 0.0432\n",
      "Epoch 173/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8263 - accuracy: 0.0417 - val_loss: 11.3928 - val_accuracy: 0.0360\n",
      "Epoch 174/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8293 - accuracy: 0.0417 - val_loss: 11.4008 - val_accuracy: 0.0360\n",
      "Epoch 175/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8330 - accuracy: 0.0435 - val_loss: 11.4169 - val_accuracy: 0.0432\n",
      "Epoch 176/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8404 - accuracy: 0.0435 - val_loss: 11.4253 - val_accuracy: 0.0504\n",
      "Epoch 177/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8518 - accuracy: 0.0435 - val_loss: 11.3930 - val_accuracy: 0.0432\n",
      "Epoch 178/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.8943 - accuracy: 0.0399 - val_loss: 11.3895 - val_accuracy: 0.0360\n",
      "Epoch 179/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9588 - accuracy: 0.0417 - val_loss: 11.3845 - val_accuracy: 0.0432\n",
      "Epoch 180/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9970 - accuracy: 0.0399 - val_loss: 11.3617 - val_accuracy: 0.0432\n",
      "Epoch 181/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0108 - accuracy: 0.0399 - val_loss: 11.3750 - val_accuracy: 0.0360\n",
      "Epoch 182/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0443 - accuracy: 0.0435 - val_loss: 11.4409 - val_accuracy: 0.0288\n",
      "Epoch 183/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.0537 - accuracy: 0.0380 - val_loss: 11.4529 - val_accuracy: 0.0432\n",
      "Epoch 184/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0528 - accuracy: 0.0399 - val_loss: 11.4619 - val_accuracy: 0.0360\n",
      "Epoch 185/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0226 - accuracy: 0.0362 - val_loss: 11.4272 - val_accuracy: 0.0432\n",
      "Epoch 186/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.0405 - accuracy: 0.0362 - val_loss: 11.4505 - val_accuracy: 0.0360\n",
      "Epoch 187/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0465 - accuracy: 0.0362 - val_loss: 11.4108 - val_accuracy: 0.0360\n",
      "Epoch 188/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0509 - accuracy: 0.0362 - val_loss: 11.4057 - val_accuracy: 0.0432\n",
      "Epoch 189/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0071 - accuracy: 0.0362 - val_loss: 11.3583 - val_accuracy: 0.0504\n",
      "Epoch 190/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9972 - accuracy: 0.0380 - val_loss: 11.3887 - val_accuracy: 0.0576\n",
      "Epoch 191/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9982 - accuracy: 0.0399 - val_loss: 11.3501 - val_accuracy: 0.0576\n",
      "Epoch 192/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0082 - accuracy: 0.0435 - val_loss: 11.3593 - val_accuracy: 0.0576\n",
      "Epoch 193/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0322 - accuracy: 0.0435 - val_loss: 11.3917 - val_accuracy: 0.0576\n",
      "Epoch 194/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0141 - accuracy: 0.0380 - val_loss: 11.4042 - val_accuracy: 0.0576\n",
      "Epoch 195/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0037 - accuracy: 0.0435 - val_loss: 11.3572 - val_accuracy: 0.0504\n",
      "Epoch 196/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9902 - accuracy: 0.0435 - val_loss: 11.3569 - val_accuracy: 0.0504\n",
      "Epoch 197/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9712 - accuracy: 0.0399 - val_loss: 11.3836 - val_accuracy: 0.0576\n",
      "Epoch 198/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9751 - accuracy: 0.0380 - val_loss: 11.3530 - val_accuracy: 0.0576\n",
      "Epoch 199/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9858 - accuracy: 0.0380 - val_loss: 11.4138 - val_accuracy: 0.0504\n",
      "Epoch 200/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9717 - accuracy: 0.0380 - val_loss: 11.4577 - val_accuracy: 0.0576\n",
      "Epoch 201/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9602 - accuracy: 0.0380 - val_loss: 11.4256 - val_accuracy: 0.0647\n",
      "Epoch 202/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9546 - accuracy: 0.0399 - val_loss: 11.4113 - val_accuracy: 0.0576\n",
      "Epoch 203/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9532 - accuracy: 0.0399 - val_loss: 11.3994 - val_accuracy: 0.0647\n",
      "Epoch 204/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9534 - accuracy: 0.0399 - val_loss: 11.3799 - val_accuracy: 0.0647\n",
      "Epoch 205/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9519 - accuracy: 0.0417 - val_loss: 11.3927 - val_accuracy: 0.0576\n",
      "Epoch 206/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9400 - accuracy: 0.0417 - val_loss: 11.4264 - val_accuracy: 0.0647\n",
      "Epoch 207/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9332 - accuracy: 0.0435 - val_loss: 11.4080 - val_accuracy: 0.0647\n",
      "Epoch 208/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9402 - accuracy: 0.0435 - val_loss: 11.4145 - val_accuracy: 0.0647\n",
      "Epoch 209/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9362 - accuracy: 0.0435 - val_loss: 11.3748 - val_accuracy: 0.0647\n",
      "Epoch 210/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9537 - accuracy: 0.0399 - val_loss: 11.3345 - val_accuracy: 0.0647\n",
      "Epoch 211/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0138 - accuracy: 0.0399 - val_loss: 11.3712 - val_accuracy: 0.0647\n",
      "Epoch 212/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0201 - accuracy: 0.0362 - val_loss: 11.3829 - val_accuracy: 0.0647\n",
      "Epoch 213/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0097 - accuracy: 0.0380 - val_loss: 11.4145 - val_accuracy: 0.0647\n",
      "Epoch 214/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.0017 - accuracy: 0.0380 - val_loss: 11.4180 - val_accuracy: 0.0647\n",
      "Epoch 215/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9987 - accuracy: 0.0380 - val_loss: 11.4087 - val_accuracy: 0.0647\n",
      "Epoch 216/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9930 - accuracy: 0.0380 - val_loss: 11.4135 - val_accuracy: 0.0647\n",
      "Epoch 217/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9837 - accuracy: 0.0380 - val_loss: 11.4147 - val_accuracy: 0.0719\n",
      "Epoch 218/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9742 - accuracy: 0.0435 - val_loss: 11.3881 - val_accuracy: 0.0576\n",
      "Epoch 219/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9861 - accuracy: 0.0435 - val_loss: 11.3641 - val_accuracy: 0.0360\n",
      "Epoch 220/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9666 - accuracy: 0.0417 - val_loss: 11.3930 - val_accuracy: 0.0432\n",
      "Epoch 221/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9918 - accuracy: 0.0453 - val_loss: 11.4057 - val_accuracy: 0.0504\n",
      "Epoch 222/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.0087 - accuracy: 0.0399 - val_loss: 11.3431 - val_accuracy: 0.0576\n",
      "Epoch 223/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0147 - accuracy: 0.0417 - val_loss: 11.3625 - val_accuracy: 0.0504\n",
      "Epoch 224/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0020 - accuracy: 0.0417 - val_loss: 11.3765 - val_accuracy: 0.0504\n",
      "Epoch 225/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9897 - accuracy: 0.0399 - val_loss: 11.3846 - val_accuracy: 0.0504\n",
      "Epoch 226/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9964 - accuracy: 0.0362 - val_loss: 11.3967 - val_accuracy: 0.0504\n",
      "Epoch 227/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.0194 - accuracy: 0.0380 - val_loss: 11.3771 - val_accuracy: 0.0576\n",
      "Epoch 228/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9975 - accuracy: 0.0399 - val_loss: 11.3287 - val_accuracy: 0.0288\n",
      "Epoch 229/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9874 - accuracy: 0.0399 - val_loss: 11.3785 - val_accuracy: 0.0432\n",
      "Epoch 230/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9850 - accuracy: 0.0399 - val_loss: 11.3956 - val_accuracy: 0.0360\n",
      "Epoch 231/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9675 - accuracy: 0.0399 - val_loss: 11.3860 - val_accuracy: 0.0360\n",
      "Epoch 232/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9664 - accuracy: 0.0417 - val_loss: 11.3882 - val_accuracy: 0.0360\n",
      "Epoch 233/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9587 - accuracy: 0.0417 - val_loss: 11.3677 - val_accuracy: 0.0288\n",
      "Epoch 234/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9464 - accuracy: 0.0435 - val_loss: 11.3654 - val_accuracy: 0.0432\n",
      "Epoch 235/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9523 - accuracy: 0.0417 - val_loss: 11.3906 - val_accuracy: 0.0432\n",
      "Epoch 236/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9470 - accuracy: 0.0435 - val_loss: 11.3790 - val_accuracy: 0.0360\n",
      "Epoch 237/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9488 - accuracy: 0.0453 - val_loss: 11.3992 - val_accuracy: 0.0504\n",
      "Epoch 238/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9495 - accuracy: 0.0435 - val_loss: 11.3973 - val_accuracy: 0.0360\n",
      "Epoch 239/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9316 - accuracy: 0.0453 - val_loss: 11.3850 - val_accuracy: 0.0360\n",
      "Epoch 240/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0150 - accuracy: 0.0380 - val_loss: 11.4220 - val_accuracy: 0.0432\n",
      "Epoch 241/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.0085 - accuracy: 0.0435 - val_loss: 11.4073 - val_accuracy: 0.0432\n",
      "Epoch 242/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9771 - accuracy: 0.0380 - val_loss: 11.4109 - val_accuracy: 0.0288\n",
      "Epoch 243/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.0508 - accuracy: 0.0362 - val_loss: 11.4584 - val_accuracy: 0.0360\n",
      "Epoch 244/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.0093 - accuracy: 0.0362 - val_loss: 11.4436 - val_accuracy: 0.0216\n",
      "Epoch 245/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9853 - accuracy: 0.0362 - val_loss: 11.3715 - val_accuracy: 0.0288\n",
      "Epoch 246/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9723 - accuracy: 0.0417 - val_loss: 11.4305 - val_accuracy: 0.0288\n",
      "Epoch 247/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9704 - accuracy: 0.0344 - val_loss: 11.4533 - val_accuracy: 0.0216\n",
      "Epoch 248/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9793 - accuracy: 0.0326 - val_loss: 11.4343 - val_accuracy: 0.0216\n",
      "Epoch 249/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.9722 - accuracy: 0.0308 - val_loss: 11.4565 - val_accuracy: 0.0144\n",
      "Epoch 250/250\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9664 - accuracy: 0.0344 - val_loss: 11.4446 - val_accuracy: 0.0216\n"
     ]
    }
   ],
   "source": [
    "for q in currency_list:\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for x in range(1):\n",
    "\n",
    "        currency = q.replace('10080','')\n",
    "\n",
    "        data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "        data = data.head(695)\n",
    "\n",
    "\n",
    "        X = data.drop(columns=['Unnamed: 0', \n",
    "                               'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "                              ])\n",
    "\n",
    "\n",
    "\n",
    "        y = data['nextweek_class']\n",
    "      \n",
    "    \n",
    "        \n",
    "\n",
    "        #print(X.shape)\n",
    "        \n",
    "        \n",
    "        # after scaling the df, resulted in \"scaled_dataset\"\n",
    "        sequences = 5\n",
    "        result = []\n",
    "        # for loop will walk for each of the 1500 rows\n",
    "        for i in range(0,len(X)):\n",
    "            # every group must have the same length, so if current loop position i + number \n",
    "            # of sequences is higher than df length, breaks\n",
    "            if i+sequences <= len(X):\n",
    "                # this will add into the list as [[R1a,R1b...R1t],[R2a,R2b...R2t],...[R5a,R5b...R5t]]\n",
    "                result.append(X[i:i+sequences].values)\n",
    "        # Converting to array + keras takes float32 better than 64\n",
    "        train_x = np.array(result)\n",
    "        #train_x  = train_x.astype('float32')\n",
    "        # making the y into same length as X\n",
    "        train_y = np.array(y.head(len(train_x)).values)\n",
    "\n",
    "        print(train_x.shape, train_y.shape)\n",
    "        #print(train_x[len(train_x)-10])\n",
    "        #print(train_y[len(train_x)-10])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.2 )\n",
    "\n",
    "       \n",
    "        \n",
    "       \n",
    "        #Initializing the classifier Network\n",
    "        classifier = Sequential()\n",
    "\n",
    "        #Adding the input LSTM network layer\n",
    "        #classifier.add(CuDNNLSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "        classifier.add(LSTM(10, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "        classifier.add(LSTM(10, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "        classifier.add(LSTM(10,  return_sequences=False))\n",
    "        #classifier.add(Dropout(0.2))\n",
    "        #Adding a second LSTM network layer\n",
    "        \n",
    "        #classifier.add(LSTM(128))\n",
    "        #Adding a dense hidden layer\n",
    "        #classifier.add(Dense(64, activation='relu'))\n",
    "        #classifier.add(Dropout(0.2))\n",
    "\n",
    "        #Adding the output layer\n",
    "        #classifier.add(Dense(35, activation='softmax'))\n",
    "      \n",
    "        #Compiling the network\n",
    "        classifier.compile( loss='mean_absolute_error',\n",
    "                      optimizer=Adam(learning_rate=0.001, decay=1e-6),\n",
    "                      metrics=['accuracy'] )\n",
    "        \n",
    "        print(classifier.summary())\n",
    "\n",
    "        #Fitting the data to the model\n",
    "        history = classifier.fit(X_train,\n",
    "                 y_train,\n",
    "                  epochs=250,\n",
    "                  validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "65668a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 11.8518 - accuracy: 0.0318\n",
      "Test Loss: 11.851827621459961\n",
      "Test Accuracy: 0.03183791786432266\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = classifier.evaluate(train_x, train_y)\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9f56b9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2139cd112b0>]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ea025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798afda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
