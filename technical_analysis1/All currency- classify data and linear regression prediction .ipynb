{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "37ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fde693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_list = [#'USDCHF10080',\n",
    "                 #'GBPUSD10080', 'EURUSD10080', \n",
    "    #'USDJPY10080', \n",
    "    #'USDCAD10080', \n",
    "    #'AUDUSD10080', \n",
    "    #'NZDUSD10080',\n",
    "                 #'GBPCHF10080',\n",
    "    #'EURCHF10080', \n",
    "    #'CHFJPY10080', \n",
    "    #'CADCHF10080',\n",
    "    #'AUDCHF10080', \n",
    "    #'NZDCHF10080', \n",
    "    'EURGBP10080',\n",
    "             #   'GBPCAD10080',\n",
    "     #'GBPAUD10080', \n",
    "    #'EURJPY10080',\n",
    "    #'EURCAD10080',\n",
    "    #'EURAUD10080',\n",
    "    #'EURNZD10080',\n",
    "    #'CADJPY10080', \n",
    "    #'AUDJPY10080',\n",
    "    #'NZDJPY10080',\n",
    "    #'AUDCAD10080', \n",
    "    #'NZDCAD10080', \n",
    "                #'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "# for q in currency_list:\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     for x in range(5):\n",
    "\n",
    "#         currency = q.replace('10080','')\n",
    "\n",
    "#         data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "#         #data = data.head(695)\n",
    "\n",
    "\n",
    "#         X = data.drop(columns=['Unnamed: 0', \n",
    "#                                'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "#                               ])\n",
    "\n",
    "\n",
    "\n",
    "#         y = data['nextweek_class']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 )\n",
    "\n",
    "\n",
    "\n",
    "#         lnr= LinearRegression()\n",
    "#         lnr.fit(X_train, y_train)\n",
    "#         y_predict = lnr.predict(X_test)\n",
    "        \n",
    "        \n",
    "#         error = sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         errors.append(error)\n",
    "       \n",
    "        \n",
    "#     average_error = sum(errors)/len(errors)\n",
    "       \n",
    "#     print(q + \" Linear regression Average \" + str(average_error))\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1fcc8706",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 97ms/step - loss: 153.8372 - val_loss: 182.8658\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 153.8313 - val_loss: 182.8644\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 153.8329 - val_loss: 182.8635\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 153.8220 - val_loss: 182.8593\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 153.8270 - val_loss: 182.8562\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 151.0392\n",
      "------------------------------------------------------------------------------------ 0\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 94ms/step - loss: 155.6854 - val_loss: 163.1778\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 155.6817 - val_loss: 163.1717\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 155.6811 - val_loss: 163.1749\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 155.6775 - val_loss: 163.1743\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 155.6748 - val_loss: 163.1452\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 158.9392\n",
      "------------------------------------------------------------------------------------ 1\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 90ms/step - loss: 156.2604 - val_loss: 176.1721\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 156.2061 - val_loss: 176.2402\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 156.1081 - val_loss: 176.3004\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 155.8810 - val_loss: 176.7131\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 155.6471 - val_loss: 177.0240\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 145.9185\n",
      "------------------------------------------------------------------------------------ 2\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 90ms/step - loss: 163.8073 - val_loss: 130.0495\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 163.7932 - val_loss: 130.0698\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 163.7790 - val_loss: 130.0867\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 163.7663 - val_loss: 130.1259\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 163.7721 - val_loss: 130.2736\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 147.7727\n",
      "------------------------------------------------------------------------------------ 3\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 97ms/step - loss: 157.9415 - val_loss: 150.9019\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 157.8990 - val_loss: 151.0354\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 157.7947 - val_loss: 151.5867\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 157.6697 - val_loss: 151.6927\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 157.5827 - val_loss: 152.3031\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 158.3392\n",
      "------------------------------------------------------------------------------------ 4\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 94ms/step - loss: 158.5537 - val_loss: 143.6440\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 158.5411 - val_loss: 143.6187\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.5275 - val_loss: 143.5926\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.4953 - val_loss: 143.5181\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.4081 - val_loss: 143.3419\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 161.9618\n",
      "------------------------------------------------------------------------------------ 5\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 95ms/step - loss: 151.2250 - val_loss: 176.6090\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 151.2222 - val_loss: 176.6228\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 151.2103 - val_loss: 176.6375\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 151.2045 - val_loss: 176.6344\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 151.1962 - val_loss: 176.6592\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 168.9814\n",
      "------------------------------------------------------------------------------------ 6\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 95ms/step - loss: 160.7392 - val_loss: 142.5498\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 160.7080 - val_loss: 142.6926\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 160.6310 - val_loss: 142.9017\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 160.4630 - val_loss: 143.5998\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 160.3221 - val_loss: 144.5709\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 152.4000\n",
      "------------------------------------------------------------------------------------ 7\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 111ms/step - loss: 158.8851 - val_loss: 150.2520\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 158.8813 - val_loss: 150.2678\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 158.8766 - val_loss: 150.2429\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 158.8728 - val_loss: 150.2176\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 158.8740 - val_loss: 150.2276\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 154.5531\n",
      "------------------------------------------------------------------------------------ 8\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 91ms/step - loss: 173.7132 - val_loss: 106.8497\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 173.6962 - val_loss: 106.8748\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 173.6730 - val_loss: 106.9322\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 173.6318 - val_loss: 107.0270\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 173.5228 - val_loss: 107.4578\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 119.8275\n",
      "------------------------------------------------------------------------------------ 9\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 120ms/step - loss: 153.7650 - val_loss: 164.1138\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 153.7567 - val_loss: 164.1214\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 153.7549 - val_loss: 164.1140\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 153.7495 - val_loss: 164.0920\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 153.7231 - val_loss: 164.0114\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 167.3977\n",
      "------------------------------------------------------------------------------------ 10\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 96ms/step - loss: 158.2450 - val_loss: 129.6005\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 158.2235 - val_loss: 129.6068\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 158.1937 - val_loss: 129.6089\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 158.1555 - val_loss: 129.6263\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 158.1625 - val_loss: 129.6113\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 175.1723\n",
      "------------------------------------------------------------------------------------ 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 93ms/step - loss: 158.3875 - val_loss: 133.7795\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.3755 - val_loss: 133.7757\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.3253 - val_loss: 133.7663\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 158.1921 - val_loss: 133.7347\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 158.0675 - val_loss: 133.7680\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 171.8141\n",
      "------------------------------------------------------------------------------------ 12\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 93ms/step - loss: 157.5005 - val_loss: 160.3374\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 157.4955 - val_loss: 160.3634\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 157.4929 - val_loss: 160.3852\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 157.4872 - val_loss: 160.3805\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 157.4882 - val_loss: 160.4831\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 152.7113\n",
      "------------------------------------------------------------------------------------ 13\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 95ms/step - loss: 156.8594 - val_loss: 126.1843\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 156.8543 - val_loss: 126.1842\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 156.8525 - val_loss: 126.1837\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 156.8530 - val_loss: 126.1889\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 156.8429 - val_loss: 126.1940\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 184.6950\n",
      "------------------------------------------------------------------------------------ 14\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 93ms/step - loss: 156.8552 - val_loss: 167.8326\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 156.8490 - val_loss: 167.8412\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 156.8489 - val_loss: 167.8221\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 156.8396 - val_loss: 167.8323\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 156.8383 - val_loss: 167.8063\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 149.3412\n",
      "------------------------------------------------------------------------------------ 15\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 93ms/step - loss: 153.6151 - val_loss: 170.4871\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 153.5957 - val_loss: 170.5228\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 153.5535 - val_loss: 170.6598\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 153.4412 - val_loss: 171.0104\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 153.2820 - val_loss: 171.3617\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 162.4533\n",
      "------------------------------------------------------------------------------------ 16\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 95ms/step - loss: 155.5239 - val_loss: 152.8163\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 155.5196 - val_loss: 152.8172\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 155.5182 - val_loss: 152.8158\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 155.5184 - val_loss: 152.8137\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 155.5172 - val_loss: 152.8147\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 168.5195\n",
      "------------------------------------------------------------------------------------ 17\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 93ms/step - loss: 158.9023 - val_loss: 150.4512\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.8688 - val_loss: 150.5399\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 158.7960 - val_loss: 150.7669\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 158.6867 - val_loss: 151.0358\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.5532 - val_loss: 151.4073\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 154.7853\n",
      "------------------------------------------------------------------------------------ 18\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 90ms/step - loss: 161.2037 - val_loss: 143.6819\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 161.1954 - val_loss: 143.6626\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 161.1879 - val_loss: 143.6403\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 161.1869 - val_loss: 143.6098\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 161.1779 - val_loss: 143.5741\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 148.9962\n",
      "------------------------------------------------------------------------------------ 19\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 119ms/step - loss: 157.5899 - val_loss: 150.6316\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 157.5836 - val_loss: 150.6304\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 157.5780 - val_loss: 150.6267\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 157.5681 - val_loss: 150.6334\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 157.5580 - val_loss: 150.6273\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 160.3702\n",
      "------------------------------------------------------------------------------------ 20\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 97ms/step - loss: 160.2680 - val_loss: 129.4621\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 160.2599 - val_loss: 129.4688\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 160.2590 - val_loss: 129.4737\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 160.2446 - val_loss: 129.4846\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 160.2350 - val_loss: 129.5700\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 165.6378\n",
      "------------------------------------------------------------------------------------ 21\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 92ms/step - loss: 156.5395 - val_loss: 149.4166\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 156.5028 - val_loss: 149.4622\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 156.4705 - val_loss: 149.5452\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 156.3899 - val_loss: 149.7943\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 156.2476 - val_loss: 149.8834\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 166.8528\n",
      "------------------------------------------------------------------------------------ 22\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 93ms/step - loss: 161.4514 - val_loss: 153.2452\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 161.4446 - val_loss: 153.2533\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 161.4223 - val_loss: 153.2924\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 161.4082 - val_loss: 153.4006\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 161.3166 - val_loss: 153.5012\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 139.3124\n",
      "------------------------------------------------------------------------------------ 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 93ms/step - loss: 154.1475 - val_loss: 172.6077\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 154.1326 - val_loss: 172.6590\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 154.1124 - val_loss: 172.7775\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 154.0966 - val_loss: 172.9788\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 153.9716 - val_loss: 173.2727\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 158.1058\n",
      "------------------------------------------------------------------------------------ 24\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 92ms/step - loss: 158.6264 - val_loss: 139.5003\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 158.6189 - val_loss: 139.4981\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 158.6145 - val_loss: 139.5090\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 158.5926 - val_loss: 139.5078\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 158.5792 - val_loss: 139.5142\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 164.9398\n",
      "------------------------------------------------------------------------------------ 25\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 96ms/step - loss: 153.4598 - val_loss: 139.0058\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 153.4377 - val_loss: 139.0390\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 153.4279 - val_loss: 139.0777\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 153.3545 - val_loss: 139.2033\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 153.2215 - val_loss: 139.5204\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 190.2041\n",
      "------------------------------------------------------------------------------------ 26\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 93ms/step - loss: 149.9452 - val_loss: 179.4300\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 149.9297 - val_loss: 179.4227\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 149.9156 - val_loss: 179.3299\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 149.8943 - val_loss: 179.1789\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 149.8439 - val_loss: 178.6299\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 173.1340\n",
      "------------------------------------------------------------------------------------ 27\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 92ms/step - loss: 158.4633 - val_loss: 179.3566\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.4471 - val_loss: 179.3736\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.4408 - val_loss: 179.4110\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 158.4207 - val_loss: 179.3966\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 158.3951 - val_loss: 179.4154\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 131.5972\n",
      "------------------------------------------------------------------------------------ 28\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 90ms/step - loss: 157.6632 - val_loss: 153.8875\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 157.6553 - val_loss: 153.8828\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 157.6582 - val_loss: 153.8580\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 157.6447 - val_loss: 153.8415\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 157.6384 - val_loss: 153.7944\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 157.3512\n",
      "------------------------------------------------------------------------------------ 29\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 89ms/step - loss: 160.1066 - val_loss: 151.6722\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 160.0998 - val_loss: 151.6755\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 160.0913 - val_loss: 151.6820\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 160.0879 - val_loss: 151.6841\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 160.0736 - val_loss: 151.7126\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 147.4061\n",
      "------------------------------------------------------------------------------------ 30\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 101ms/step - loss: 156.8501 - val_loss: 156.5109\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 156.8340 - val_loss: 156.5091\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 156.7966 - val_loss: 156.4904\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 156.8198 - val_loss: 156.4165\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 156.6944 - val_loss: 156.5439\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 159.0005\n",
      "------------------------------------------------------------------------------------ 31\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 92ms/step - loss: 163.4450 - val_loss: 153.0842\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 163.4429 - val_loss: 153.0817\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 163.4290 - val_loss: 153.0879\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 163.4112 - val_loss: 153.1111\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 163.3719 - val_loss: 153.1516\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 130.1720\n",
      "------------------------------------------------------------------------------------ 32\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 94ms/step - loss: 162.1241 - val_loss: 108.9047\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 162.0829 - val_loss: 108.9563\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 161.9647 - val_loss: 109.1199\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 161.8200 - val_loss: 109.4239\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 161.6203 - val_loss: 109.7503\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 175.1539\n",
      "------------------------------------------------------------------------------------ 33\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 98ms/step - loss: 164.4686 - val_loss: 155.7272\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 164.4596 - val_loss: 155.6982\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 164.4489 - val_loss: 155.6663\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 164.4256 - val_loss: 155.5588\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 164.4810 - val_loss: 155.3295\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 123.1689\n",
      "------------------------------------------------------------------------------------ 34\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 100ms/step - loss: 153.6085 - val_loss: 170.3657\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 153.5911 - val_loss: 170.3878\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 153.5582 - val_loss: 170.4551\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 153.4895 - val_loss: 170.5054\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 153.4355 - val_loss: 170.5665\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 162.9676\n",
      "------------------------------------------------------------------------------------ 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 92ms/step - loss: 157.0771 - val_loss: 153.0822\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 157.0633 - val_loss: 153.0745\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 157.0539 - val_loss: 153.0758\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 157.0310 - val_loss: 153.0744\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 157.0170 - val_loss: 153.0805\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 160.6817\n",
      "------------------------------------------------------------------------------------ 36\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 122ms/step - loss: 154.8745 - val_loss: 164.8380\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 154.8703 - val_loss: 164.8408\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 154.8704 - val_loss: 164.8177\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 154.8583 - val_loss: 164.7812\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 154.8530 - val_loss: 164.7442\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 161.4030\n",
      "------------------------------------------------------------------------------------ 37\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 97ms/step - loss: 164.9562 - val_loss: 150.5007\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 164.9514 - val_loss: 150.5235\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 164.9490 - val_loss: 150.5501\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 164.9494 - val_loss: 150.5555\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 164.9449 - val_loss: 150.6294\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 125.2888\n",
      "------------------------------------------------------------------------------------ 38\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 96ms/step - loss: 156.6763 - val_loss: 171.4168\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 156.6707 - val_loss: 171.4132\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 156.6633 - val_loss: 171.4000\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 156.6608 - val_loss: 171.4052\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 156.6484 - val_loss: 171.3852\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 147.1343\n",
      "------------------------------------------------------------------------------------ 39\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 119ms/step - loss: 163.2082 - val_loss: 129.1304\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 163.1586 - val_loss: 129.2296\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 163.0186 - val_loss: 129.7076\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 162.6994 - val_loss: 130.4503\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 162.4701 - val_loss: 130.8750\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 152.6876\n",
      "------------------------------------------------------------------------------------ 40\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 94ms/step - loss: 160.1723 - val_loss: 149.4046\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 160.1642 - val_loss: 149.4030\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 160.1470 - val_loss: 149.4020\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 160.1181 - val_loss: 149.4062\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 160.0761 - val_loss: 149.4536\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 148.7551\n",
      "------------------------------------------------------------------------------------ 41\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 93ms/step - loss: 158.2906 - val_loss: 156.5059\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.2884 - val_loss: 156.5087\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.2868 - val_loss: 156.5031\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 158.2827 - val_loss: 156.5001\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.2791 - val_loss: 156.4955\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 152.0622\n",
      "------------------------------------------------------------------------------------ 42\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 119ms/step - loss: 159.0665 - val_loss: 149.1730\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 159.0146 - val_loss: 149.1841\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.8954 - val_loss: 149.2311\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.6540 - val_loss: 149.3714\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 158.5463 - val_loss: 149.5102\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 155.3591\n",
      "------------------------------------------------------------------------------------ 43\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 94ms/step - loss: 166.0936 - val_loss: 134.6006\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 166.0828 - val_loss: 134.6031\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 166.0764 - val_loss: 134.6251\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 166.0575 - val_loss: 134.7105\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 166.0262 - val_loss: 134.6992\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 133.0512\n",
      "------------------------------------------------------------------------------------ 44\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 95ms/step - loss: 159.8182 - val_loss: 140.3551\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 159.7926 - val_loss: 140.3841\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 159.7503 - val_loss: 140.4053\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 159.6388 - val_loss: 140.5767\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 159.4368 - val_loss: 140.7878\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 158.7511\n",
      "------------------------------------------------------------------------------------ 45\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 94ms/step - loss: 159.2370 - val_loss: 143.6935\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 159.2303 - val_loss: 143.6801\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 159.2228 - val_loss: 143.6744\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 159.2122 - val_loss: 143.6420\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 159.1849 - val_loss: 143.6068\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 158.3960\n",
      "------------------------------------------------------------------------------------ 46\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 94ms/step - loss: 161.1409 - val_loss: 132.8066\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 161.1360 - val_loss: 132.8501\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 161.1038 - val_loss: 132.8781\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 161.0763 - val_loss: 132.9735\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 161.0223 - val_loss: 133.1627\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 157.9953\n",
      "------------------------------------------------------------------------------------ 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 94ms/step - loss: 158.3861 - val_loss: 157.7203\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 158.3867 - val_loss: 157.6796\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 158.3714 - val_loss: 157.5589\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 158.3680 - val_loss: 157.4868\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 158.3548 - val_loss: 157.5688\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 150.5521\n",
      "------------------------------------------------------------------------------------ 48\n",
      "(1112, 1, 4) (1112,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 93ms/step - loss: 161.4967 - val_loss: 148.9297\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 161.4900 - val_loss: 148.9259\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 161.4914 - val_loss: 148.9390\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 161.4874 - val_loss: 148.9414\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 161.4931 - val_loss: 148.9562\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 143.2100\n",
      "------------------------------------------------------------------------------------ 49\n",
      "[12.289800642366075, 12.607110067067872, 12.079671861852832, 12.156180962609232, 12.583290622125016, 12.726422819023211, 12.99928633858413, 12.345039242403582, 12.431938116285346, 10.946574430398485, 12.938225325002918, 13.23526851875971, 13.10778726231329, 12.357642128243015, 13.59025469161663, 12.220523793284254, 12.745716647041847, 12.981507279588145, 12.44127379246601, 12.20640185877438, 12.663735368422909, 12.870035047505638, 12.917151329217834, 11.803067109377823, 12.574011846892034, 12.842888647744298, 13.791450859909158, 13.158038310020562, 11.471581548659238, 12.543969907101717, 12.141091277645078, 12.609540784613376, 11.409292322223378, 13.234573885201275, 11.098149848227449, 12.765877206428447, 12.676029225232377, 12.704448635683438, 11.193249125645758, 12.129891893324936, 12.356681443411306, 12.196518598270933, 12.331351937260811, 12.464311235099583, 11.534780566604923, 12.599646160667506, 12.58554771762195, 12.569616323364908, 12.269966513689852, 11.967038343461057]\n",
      "EURGBP10080 ------------------------ RNN  12.449268988366711\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for q in currency_list:\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequences = [1]\n",
    "    \n",
    "    all_sequence_result = []\n",
    "        \n",
    "    for m in sequences:\n",
    "    \n",
    "        errors = []\n",
    "        for x in range(50):\n",
    "        \n",
    "            currency = q.replace('10080','')\n",
    "\n",
    "            data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "            #data = data.head(695)\n",
    "\n",
    "\n",
    "            X = data.drop(columns=['Unnamed: 0', \n",
    "                                   'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "                                  ])\n",
    "\n",
    "\n",
    "\n",
    "            y = data['nextweek_class']\n",
    "\n",
    "\n",
    "#             X_scaler = RobustScaler(quantile_range=(10.0, 90.0),)\n",
    "            \n",
    "#             X_scaler.fit(X)\n",
    "           \n",
    "#             X = X_scaler.transform(X)\n",
    "           \n",
    "#             X = pd.DataFrame(X, columns = [q+\"_class\", q+'_volume'])\n",
    "            \n",
    "\n",
    "            #print(X)\n",
    "\n",
    "\n",
    "            # after scaling the df, resulted in \"scaled_dataset\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            result = []\n",
    "            # for loop will walk for each of the 1500 rows\n",
    "            for i in range(0,len(X)):\n",
    "                # every group must have the same length, so if current loop position i + number \n",
    "                # of sequences is higher than df length, breaks\n",
    "                if i+m <= len(X):\n",
    "                    # this will add into the list as [[R1a,R1b...R1t],[R2a,R2b...R2t],...[R5a,R5b...R5t]]\n",
    "                    result.append(X[i:i+m].values)\n",
    "            # Converting to array + keras takes float32 better than 64\n",
    "            train_x = np.array(result)\n",
    "            #train_x  = train_x.astype('float32')\n",
    "            # making the y into same length as X\n",
    "            train_y = np.array(y.head(len(train_x)).values)\n",
    "\n",
    "            print(train_x.shape, train_y.shape)\n",
    "            #print(train_x[len(train_x)-10])\n",
    "            #print(train_y[len(train_x)-10])\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.15 )\n",
    "                               \n",
    "            \n",
    "\n",
    "            X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size = 0.15 )\n",
    "\n",
    "            \n",
    "\n",
    "            #Initializing the classifier Network\n",
    "            classifier = Sequential()\n",
    "\n",
    "            #Adding the input LSTM network layer\n",
    "            #classifier.add(CuDNNLSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "            classifier.add(LSTM(100, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "           \n",
    "           \n",
    "            classifier.add(LSTM(100,  return_sequences=True), )\n",
    "            #classifier.add(LSTM(100,  return_sequences=True))\n",
    "            \n",
    "\n",
    "            #classifier.add(Dense(units = 1))\n",
    "            classifier.add(LSTM(100,  return_sequences=False))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "            #Adding a second LSTM network layer\n",
    "\n",
    "            #classifier.add(LSTM(128))\n",
    "            #Adding a dense hidden layer\n",
    "            #classifier.add(Dense(64, activation='relu'))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "\n",
    "            #Adding the output layer\n",
    "            #classifier.add(Dense(35, activation='softmax'))\n",
    "\n",
    "            #Compiling the network\n",
    "            classifier.compile( loss='mean_squared_error',\n",
    "                            optimizer=Adam(learning_rate=0.001, decay=1e-6),\n",
    "                             )\n",
    "\n",
    "            #print(classifier.summary())\n",
    "\n",
    "            #Fitting the data to the model\n",
    "            history = classifier.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=5,\n",
    "                        validation_data=(X_val, y_val))        \n",
    "\n",
    "            val_loss  = classifier.evaluate(X_test, y_test)\n",
    "            error = sqrt(val_loss)\n",
    "            errors.append(error)\n",
    "            plt.plot(history.history['loss'],'red')\n",
    "            plt.plot(history.history['val_loss'], 'blue')\n",
    "            print('------------------------------------------------------------------------------------',x)\n",
    "        average_error = sum(errors)/len(errors)\n",
    "        print(errors)\n",
    "        print(q , \"------------------------ RNN \" , average_error)\n",
    "        all_sequence_result.append(str(m)+\" sequence\" )\n",
    "        all_sequence_result.append(average_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a49ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "65668a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 sequence', 12.449268988366711]\n"
     ]
    }
   ],
   "source": [
    "print(all_sequence_result)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ea025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798afda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86036c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
