{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "37ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "fde693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_list = [#'USDCHF10080',\n",
    "                 #'GBPUSD10080', 'EURUSD10080', \n",
    "    #'USDJPY10080', \n",
    "    #'USDCAD10080', \n",
    "    #'AUDUSD10080', \n",
    "    #'NZDUSD10080',\n",
    "                 #'GBPCHF10080',\n",
    "    #'EURCHF10080', \n",
    "    #'CHFJPY10080', \n",
    "    #'CADCHF10080',\n",
    "    #'AUDCHF10080', \n",
    "    #'NZDCHF10080', \n",
    "    'EURGBP10080',\n",
    "             #   'GBPCAD10080',\n",
    "     #'GBPAUD10080', \n",
    "    #'EURJPY10080',\n",
    "    #'EURCAD10080',\n",
    "    #'EURAUD10080',\n",
    "    #'EURNZD10080',\n",
    "    #'CADJPY10080', \n",
    "    #'AUDJPY10080',\n",
    "    #'NZDJPY10080',\n",
    "    #'AUDCAD10080', \n",
    "    #'NZDCAD10080', \n",
    "                #'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "# for q in currency_list:\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     for x in range(5):\n",
    "\n",
    "#         currency = q.replace('10080','')\n",
    "\n",
    "#         data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "#         #data = data.head(695)\n",
    "\n",
    "\n",
    "#         X = data.drop(columns=['Unnamed: 0', \n",
    "#                                'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "#                               ])\n",
    "\n",
    "\n",
    "\n",
    "#         y = data['nextweek_class']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 )\n",
    "\n",
    "\n",
    "\n",
    "#         lnr= LinearRegression()\n",
    "#         lnr.fit(X_train, y_train)\n",
    "#         y_predict = lnr.predict(X_test)\n",
    "        \n",
    "        \n",
    "#         error = sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         errors.append(error)\n",
    "       \n",
    "        \n",
    "#     average_error = sum(errors)/len(errors)\n",
    "       \n",
    "#     print(q + \" Linear regression Average \" + str(average_error))\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "1fcc8706",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 9s 32ms/step - loss: 151.1319\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 151.1290\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 151.1277\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 151.1184\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 151.1126\n",
      "7/7 [==============================] - 2s 14ms/step - loss: 160.5611\n",
      "------------------------------------------------------------------------------------ 0\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 29ms/step - loss: 152.2665\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 152.2615\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 152.2583\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 152.2552\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 152.2535\n",
      "7/7 [==============================] - 2s 12ms/step - loss: 154.1359\n",
      "------------------------------------------------------------------------------------ 1\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 29ms/step - loss: 153.5482\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 153.5426\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 153.5359\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 153.5265\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 153.5111\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 146.9891\n",
      "------------------------------------------------------------------------------------ 2\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 32ms/step - loss: 154.0716\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 154.0636\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 154.0628\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 154.0630\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 154.0562\n",
      "7/7 [==============================] - 3s 12ms/step - loss: 144.0371\n",
      "------------------------------------------------------------------------------------ 3\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 29ms/step - loss: 151.8274\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 151.8269\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 151.8230: 0s - loss: 15\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 151.8235\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 151.8127\n",
      "7/7 [==============================] - 2s 12ms/step - loss: 156.5582\n",
      "------------------------------------------------------------------------------------ 4\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 28ms/step - loss: 153.1747\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 153.1731\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 153.1715\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 153.1674\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 153.1679\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 148.9404\n",
      "------------------------------------------------------------------------------------ 5\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 27ms/step - loss: 155.3964\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 155.3946\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 155.3910\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 155.3929\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 155.3621\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 136.5082\n",
      "------------------------------------------------------------------------------------ 6\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 28ms/step - loss: 153.2969\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 153.2875\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 153.2720\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 153.2589\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 153.2303\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 148.4640\n",
      "------------------------------------------------------------------------------------ 7\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 32ms/step - loss: 155.1052\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 155.1006\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 155.0977\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 155.0891\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 155.0666\n",
      "7/7 [==============================] - 2s 14ms/step - loss: 138.1917\n",
      "------------------------------------------------------------------------------------ 8\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 31ms/step - loss: 150.8952\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 150.8896: 0s - loss: 150.29\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 150.8806: 0s - loss: 151.8\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 150.8687\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - ETA: 0s - loss: 149.990 - 1s 36ms/step - loss: 150.8447\n",
      "7/7 [==============================] - 2s 19ms/step - loss: 161.9035\n",
      "------------------------------------------------------------------------------------ 9\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 10s 29ms/step - loss: 153.7790\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 153.7749\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 153.7701\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 153.7620\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 153.7288\n",
      "7/7 [==============================] - 2s 10ms/step - loss: 145.7774\n",
      "------------------------------------------------------------------------------------ 10\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 33ms/step - loss: 153.4347\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 153.4174\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 153.3913\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 153.3526\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 153.3038\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 147.9591\n",
      "------------------------------------------------------------------------------------ 11\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 28ms/step - loss: 154.0889\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 154.0840\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 154.0799\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 154.0771\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 154.0750\n",
      "7/7 [==============================] - 2s 10ms/step - loss: 143.8816\n",
      "------------------------------------------------------------------------------------ 12\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 26ms/step - loss: 152.5639\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 152.5555\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 152.5514\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 152.5264\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 152.5104\n",
      "7/7 [==============================] - 2s 9ms/step - loss: 152.5051\n",
      "------------------------------------------------------------------------------------ 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 25ms/step - loss: 153.7200\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 153.7154\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 153.7107\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 153.6947\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 153.6896\n",
      "7/7 [==============================] - 2s 9ms/step - loss: 146.1365\n",
      "------------------------------------------------------------------------------------ 14\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 9s 29ms/step - loss: 150.8756\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 150.8726\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 150.8715\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 150.8652\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 150.8687\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 161.9648\n",
      "------------------------------------------------------------------------------------ 15\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 32ms/step - loss: 155.8215: 0s - loss: 158.\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 155.8213\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 155.8093\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 155.7958\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 155.7541: 0s - loss: 152\n",
      "7/7 [==============================] - 2s 15ms/step - loss: 133.9842\n",
      "------------------------------------------------------------------------------------ 16\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 34ms/step - loss: 152.5680: 0s - loss: 153.6\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 152.5570\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 152.5340\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 152.4784\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 152.4381\n",
      "7/7 [==============================] - 2s 10ms/step - loss: 152.6917\n",
      "------------------------------------------------------------------------------------ 17\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 9s 32ms/step - loss: 150.3734\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 150.3673\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 150.3659\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 150.3738\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 150.3666\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 164.7958\n",
      "------------------------------------------------------------------------------------ 18\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 13s 32ms/step - loss: 155.4563\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 155.4516\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 155.4465\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 155.4383\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 155.4279\n",
      "7/7 [==============================] - 3s 13ms/step - loss: 136.0891\n",
      "------------------------------------------------------------------------------------ 19\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 9s 36ms/step - loss: 149.7668\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 149.7594\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 149.7527\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 149.7486\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 149.7595\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 168.2327\n",
      "------------------------------------------------------------------------------------ 20\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 9s 30ms/step - loss: 150.1878\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 150.1817\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 150.1733\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 150.1609\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 150.1149\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 166.1629\n",
      "------------------------------------------------------------------------------------ 21\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 10s 29ms/step - loss: 153.9279\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 153.9226\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 153.9125\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 153.8902\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 153.8735\n",
      "7/7 [==============================] - 2s 10ms/step - loss: 144.8971\n",
      "------------------------------------------------------------------------------------ 22\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 9s 29ms/step - loss: 151.7076\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 151.6918\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 151.6872\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 151.6599\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 151.6137\n",
      "7/7 [==============================] - 2s 10ms/step - loss: 157.5879\n",
      "------------------------------------------------------------------------------------ 23\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 10s 39ms/step - loss: 149.0935\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 149.0903\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 149.0900\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 149.0891\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 149.0847\n",
      "7/7 [==============================] - 2s 13ms/step - loss: 171.9964\n",
      "------------------------------------------------------------------------------------ 24\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 10s 35ms/step - loss: 153.7671\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 153.7627\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 153.7567\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 153.7468\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 153.7260: 0s - loss: 153.452\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 145.7105\n",
      "------------------------------------------------------------------------------------ 25\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 9s 30ms/step - loss: 150.8938\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 150.8786\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 150.8477\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 150.7923\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 150.7402\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 162.6185\n",
      "------------------------------------------------------------------------------------ 26\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 9s 33ms/step - loss: 152.7033\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 152.7002\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 152.6999\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 152.6932\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 152.6726\n",
      "7/7 [==============================] - 3s 11ms/step - loss: 151.6134\n",
      "------------------------------------------------------------------------------------ 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 28ms/step - loss: 153.9659\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 153.9610\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 153.9487\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 153.9225: 0s - loss: 154.071\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 153.8801\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 144.9698\n",
      "------------------------------------------------------------------------------------ 28\n",
      "(1415, 1, 6) (1415,)\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 8s 27ms/step - loss: 151.3405\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 151.3364\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 151.3351\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 151.3376\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 151.3315\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 159.3282\n",
      "------------------------------------------------------------------------------------ 29\n",
      "[12.671269300027843, 12.4151477951489, 12.123906351692485, 12.001544852952135, 12.512322417531983, 12.20411465157186, 11.683672109817469, 12.184581857174242, 11.755498370692727, 12.724130752942173, 12.073831404535854, 12.16384548417525, 11.9950665823268, 12.349297235548024, 12.088692645119409, 12.726540319003076, 11.575154735610246, 12.356846913732243, 12.8372825061831, 11.665722472720962, 12.970453577867854, 12.890417848714335, 12.03731964388187, 12.55340337921821, 13.114739758217898, 12.07106149071801, 12.75219468320184, 12.313138219102974, 12.0403406453657, 12.622528136341561]\n",
      "EURGBP10080 ------------------------ RNN  12.315802204704568\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for q in currency_list:\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequences = [1]\n",
    "    \n",
    "    all_sequence_result = []\n",
    "        \n",
    "    for m in sequences:\n",
    "    \n",
    "        errors = []\n",
    "        for x in range(30):\n",
    "        \n",
    "            currency = q.replace('10080','')\n",
    "\n",
    "            data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "            #data = data.head(695)\n",
    "\n",
    "\n",
    "            X = data.drop(columns=['Unnamed: 0', \n",
    "                                   'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "                                  ])\n",
    "\n",
    "\n",
    "\n",
    "            y = data['nextweek_class']\n",
    "\n",
    "\n",
    "#             X_scaler = RobustScaler(quantile_range=(10.0, 90.0),)\n",
    "            \n",
    "#             X_scaler.fit(X)\n",
    "           \n",
    "#             X = X_scaler.transform(X)\n",
    "           \n",
    "#             X = pd.DataFrame(X, columns = [q+\"_class\", q+'_volume'])\n",
    "            \n",
    "\n",
    "            #print(X)\n",
    "\n",
    "\n",
    "            # after scaling the df, resulted in \"scaled_dataset\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            result = []\n",
    "            # for loop will walk for each of the 1500 rows\n",
    "            for i in range(0,len(X)):\n",
    "                # every group must have the same length, so if current loop position i + number \n",
    "                # of sequences is higher than df length, breaks\n",
    "                if i+m <= len(X):\n",
    "                    # this will add into the list as [[R1a,R1b...R1t],[R2a,R2b...R2t],...[R5a,R5b...R5t]]\n",
    "                    result.append(X[i:i+m].values)\n",
    "            # Converting to array + keras takes float32 better than 64\n",
    "            train_x = np.array(result)\n",
    "            #train_x  = train_x.astype('float32')\n",
    "            # making the y into same length as X\n",
    "            train_y = np.array(y.head(len(train_x)).values)\n",
    "\n",
    "            print(train_x.shape, train_y.shape)\n",
    "            #print(train_x[len(train_x)-10])\n",
    "            #print(train_y[len(train_x)-10])\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.15 )\n",
    "                               \n",
    "            \n",
    "\n",
    "            #X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size = 0.15 )\n",
    "\n",
    "            \n",
    "\n",
    "            #Initializing the classifier Network\n",
    "            classifier = Sequential()\n",
    "\n",
    "            #Adding the input LSTM network layer\n",
    "            #classifier.add(CuDNNLSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "            classifier.add(LSTM(100, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "           \n",
    "           \n",
    "            classifier.add(LSTM(100,  return_sequences=True), )\n",
    "            #classifier.add(LSTM(100,  return_sequences=True))\n",
    "            \n",
    "\n",
    "            #classifier.add(Dense(units = 1))\n",
    "            classifier.add(LSTM(100,  return_sequences=False))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "            #Adding a second LSTM network layer\n",
    "\n",
    "            #classifier.add(LSTM(128))\n",
    "            #Adding a dense hidden layer\n",
    "            #classifier.add(Dense(64, activation='relu'))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "\n",
    "            #Adding the output layer\n",
    "            #classifier.add(Dense(35, activation='softmax'))\n",
    "\n",
    "            #Compiling the network\n",
    "            classifier.compile( loss='mean_squared_error',\n",
    "                            optimizer=Adam(learning_rate=0.001, decay=1e-6),\n",
    "                             )\n",
    "\n",
    "            #print(classifier.summary())\n",
    "\n",
    "            #Fitting the data to the model\n",
    "            history = classifier.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=5,\n",
    "                        #validation_data=(X_val, y_val)\n",
    "                                    )        \n",
    "\n",
    "            val_loss  = classifier.evaluate(X_test, y_test)\n",
    "            error = sqrt(val_loss)\n",
    "            errors.append(error)\n",
    "            plt.plot(history.history['loss'],'red')\n",
    "            #plt.plot(history.history['val_loss'], 'blue')\n",
    "            print('------------------------------------------------------------------------------------',x)\n",
    "        average_error = sum(errors)/len(errors)\n",
    "        print(errors)\n",
    "        print(q , \"------------------------ RNN \" , average_error)\n",
    "        all_sequence_result.append(str(m)+\" sequence\" )\n",
    "        all_sequence_result.append(average_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a49ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "65668a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 sequence', 12.315802204704568]\n"
     ]
    }
   ],
   "source": [
    "print(all_sequence_result)   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
