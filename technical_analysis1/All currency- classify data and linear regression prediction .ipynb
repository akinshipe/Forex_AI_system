{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "37ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "fde693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_list = [#'USDCHF10080',\n",
    "                 #'GBPUSD10080', 'EURUSD10080', \n",
    "    #'USDJPY10080', \n",
    "    #'USDCAD10080', \n",
    "    #'AUDUSD10080', \n",
    "    #'NZDUSD10080',\n",
    "                 #'GBPCHF10080',\n",
    "    #'EURCHF10080', \n",
    "    #'CHFJPY10080', \n",
    "    #'CADCHF10080',\n",
    "    #'AUDCHF10080', \n",
    "    #'NZDCHF10080', \n",
    "    'EURGBP10080',\n",
    "             #   'GBPCAD10080',\n",
    "     #'GBPAUD10080', \n",
    "    #'EURJPY10080',\n",
    "    #'EURCAD10080',\n",
    "    #'EURAUD10080',\n",
    "    #'EURNZD10080',\n",
    "    #'CADJPY10080', \n",
    "    #'AUDJPY10080',\n",
    "    #'NZDJPY10080',\n",
    "    #'AUDCAD10080', \n",
    "    #'NZDCAD10080', \n",
    "                #'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "# for q in currency_list:\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     for x in range(5):\n",
    "\n",
    "#         currency = q.replace('10080','')\n",
    "\n",
    "#         data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "#         #data = data.head(695)\n",
    "\n",
    "\n",
    "#         X = data.drop(columns=['Unnamed: 0', \n",
    "#                                'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "#                               ])\n",
    "\n",
    "\n",
    "\n",
    "#         y = data['nextweek_class']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 )\n",
    "\n",
    "\n",
    "\n",
    "#         lnr= LinearRegression()\n",
    "#         lnr.fit(X_train, y_train)\n",
    "#         y_predict = lnr.predict(X_test)\n",
    "        \n",
    "        \n",
    "#         error = sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         errors.append(error)\n",
    "       \n",
    "        \n",
    "#     average_error = sum(errors)/len(errors)\n",
    "       \n",
    "#     print(q + \" Linear regression Average \" + str(average_error))\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "1fcc8706",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 36ms/step - loss: 158.5206 - val_loss: 152.8289\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 158.5187 - val_loss: 152.8226\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 158.5204 - val_loss: 152.8221\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 158.5199 - val_loss: 152.8191\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 158.5201 - val_loss: 152.8192\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 152.7235\n",
      "------------------------------------------------------------------------------------ 0\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 34ms/step - loss: 154.8320 - val_loss: 171.3991\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 154.8263 - val_loss: 171.3847\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.8133 - val_loss: 171.3385\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.7824 - val_loss: 171.1263\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.7362 - val_loss: 171.0504\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 154.9085\n",
      "------------------------------------------------------------------------------------ 1\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 36ms/step - loss: 161.6026 - val_loss: 133.7431\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 161.5987 - val_loss: 133.7244\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.5958 - val_loss: 133.7131\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 161.5753 - val_loss: 133.6687\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.5667 - val_loss: 133.4890\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 154.7950\n",
      "------------------------------------------------------------------------------------ 2\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 44ms/step - loss: 154.8552 - val_loss: 172.9912\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.8456 - val_loss: 173.0068\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 154.8373 - val_loss: 173.0585\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 154.7899 - val_loss: 173.0910\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.7592 - val_loss: 173.2337\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 153.2427\n",
      "------------------------------------------------------------------------------------ 3\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 152.6684 - val_loss: 177.2175\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 152.6591 - val_loss: 177.2205\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 152.6540 - val_loss: 177.2147\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 152.6457 - val_loss: 177.2170\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 152.6417 - val_loss: 177.2109\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 160.0627\n",
      "------------------------------------------------------------------------------------ 4\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 51ms/step - loss: 157.0294 - val_loss: 150.3195\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 157.0252 - val_loss: 150.3104\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.0212 - val_loss: 150.2998\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 157.0205 - val_loss: 150.2931\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 157.0036 - val_loss: 150.2746\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 162.0343\n",
      "------------------------------------------------------------------------------------ 5\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 34ms/step - loss: 160.0873 - val_loss: 138.8819\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 160.0828 - val_loss: 138.8884\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 160.0789 - val_loss: 138.9059\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 160.0739 - val_loss: 138.9244\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 160.0755 - val_loss: 138.9926\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 156.9587\n",
      "------------------------------------------------------------------------------------ 6\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 37ms/step - loss: 157.2190 - val_loss: 151.5250\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.2105 - val_loss: 151.5254\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.1922 - val_loss: 151.5802\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 157.1387 - val_loss: 151.7167\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.0384 - val_loss: 152.0197\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 160.2455\n",
      "------------------------------------------------------------------------------------ 7\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 37ms/step - loss: 157.5887 - val_loss: 145.7918\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.5690 - val_loss: 145.8067\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.5260 - val_loss: 145.8723\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.4584 - val_loss: 145.9171\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.4090 - val_loss: 146.0003\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 163.5408\n",
      "------------------------------------------------------------------------------------ 8\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 157.4841 - val_loss: 151.5018\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 157.4700 - val_loss: 151.5520\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.4534 - val_loss: 151.6752\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.3940 - val_loss: 151.8385\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.3415 - val_loss: 152.1882\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 158.7313\n",
      "------------------------------------------------------------------------------------ 9\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 35ms/step - loss: 160.1875 - val_loss: 167.2954\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 160.1864 - val_loss: 167.3013\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 160.1883 - val_loss: 167.3000\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 160.1900 - val_loss: 167.2962\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 160.1870 - val_loss: 167.2957\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 132.4408\n",
      "------------------------------------------------------------------------------------ 10\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 47ms/step - loss: 145.9100 - val_loss: 190.4941\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 145.9053 - val_loss: 190.4798\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 145.9044 - val_loss: 190.4589\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 145.8903 - val_loss: 190.3863\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 145.8786 - val_loss: 190.2449\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 181.4027\n",
      "------------------------------------------------------------------------------------ 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 42ms/step - loss: 154.3526 - val_loss: 165.9111\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 154.3502 - val_loss: 165.9103\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.3542 - val_loss: 165.9061\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 154.3479 - val_loss: 165.9070\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 154.3479 - val_loss: 165.9004\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 161.5695\n",
      "------------------------------------------------------------------------------------ 12\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 35ms/step - loss: 158.6715 - val_loss: 152.8365\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 158.6664 - val_loss: 152.8318\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 158.6647 - val_loss: 152.8349\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 158.6624 - val_loss: 152.8318\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 158.6629 - val_loss: 152.8192\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 152.0090\n",
      "------------------------------------------------------------------------------------ 13\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 35ms/step - loss: 155.2099 - val_loss: 171.3204\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 155.2053 - val_loss: 171.3244\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 155.2028 - val_loss: 171.3021\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 155.1912 - val_loss: 171.3002\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 155.1860 - val_loss: 171.3121\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 152.8355\n",
      "------------------------------------------------------------------------------------ 14\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 38ms/step - loss: 161.1934 - val_loss: 144.7377\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.1832 - val_loss: 144.7413\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.1718 - val_loss: 144.7296\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.1463 - val_loss: 144.7206\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 161.0983 - val_loss: 144.8282\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 146.8348\n",
      "------------------------------------------------------------------------------------ 15\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 35ms/step - loss: 152.4924 - val_loss: 152.0401\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 152.4863 - val_loss: 152.0450\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 152.4853 - val_loss: 152.0389\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 152.4805 - val_loss: 152.0520\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 152.4756 - val_loss: 152.0560\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 182.3226\n",
      "------------------------------------------------------------------------------------ 16\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 43ms/step - loss: 156.6630 - val_loss: 171.2886\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 156.6547 - val_loss: 171.2887\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 156.6501 - val_loss: 171.2939\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.6341 - val_loss: 171.3227\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.5832 - val_loss: 171.3540\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 146.0889\n",
      "------------------------------------------------------------------------------------ 17\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 33ms/step - loss: 160.7905 - val_loss: 158.5887\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 160.7865 - val_loss: 158.6010\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 160.7727 - val_loss: 158.6194\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 160.7578 - val_loss: 158.6395\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 160.7836 - val_loss: 158.8356\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 137.1237\n",
      "------------------------------------------------------------------------------------ 18\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 159.1624 - val_loss: 143.1286\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 159.1630 - val_loss: 143.1579\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 159.1556 - val_loss: 143.1479\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 159.1605 - val_loss: 143.1419\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 159.1483 - val_loss: 143.1894\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 157.9327\n",
      "------------------------------------------------------------------------------------ 19\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 33ms/step - loss: 156.2107 - val_loss: 151.7028\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 156.1563 - val_loss: 151.9046\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 156.0344 - val_loss: 152.2863\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 155.9056 - val_loss: 152.8808\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 155.8807 - val_loss: 153.2702\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 165.8938\n",
      "------------------------------------------------------------------------------------ 20\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 41ms/step - loss: 153.2289 - val_loss: 183.4984\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 153.2219 - val_loss: 183.4882\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 153.2200 - val_loss: 183.4870\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 153.2137 - val_loss: 183.4871\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 153.2153 - val_loss: 183.4862\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 152.0473\n",
      "------------------------------------------------------------------------------------ 21\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 33ms/step - loss: 153.4493 - val_loss: 159.3210\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 153.4045 - val_loss: 159.4086\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 153.3018 - val_loss: 159.6129\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 153.1338 - val_loss: 159.8331\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 153.0192 - val_loss: 160.0504\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 173.2638\n",
      "------------------------------------------------------------------------------------ 22\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 42ms/step - loss: 153.9694 - val_loss: 173.9870\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 153.9650 - val_loss: 173.9838\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 153.9638 - val_loss: 173.9637\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 153.9608 - val_loss: 173.9420\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 153.9407 - val_loss: 173.9380\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 156.5855\n",
      "------------------------------------------------------------------------------------ 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 42ms/step - loss: 156.7844 - val_loss: 129.0976\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.7816 - val_loss: 129.1013\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 156.7800 - val_loss: 129.0954\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 156.7787 - val_loss: 129.0973\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.7802 - val_loss: 129.0897\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 181.2147\n",
      "------------------------------------------------------------------------------------ 24\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 35ms/step - loss: 161.3982 - val_loss: 159.2308\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.3934 - val_loss: 159.2343\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.3900 - val_loss: 159.2354\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.3852 - val_loss: 159.2188\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 161.3797 - val_loss: 159.2381\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 133.5176\n",
      "------------------------------------------------------------------------------------ 25\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 157.7035 - val_loss: 184.6940\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 157.7016 - val_loss: 184.6888\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.6938 - val_loss: 184.6797\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 157.6835 - val_loss: 184.6617\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 157.6729 - val_loss: 184.6307\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 129.5821\n",
      "------------------------------------------------------------------------------------ 26\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 39ms/step - loss: 155.8217 - val_loss: 148.5248\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 155.8145 - val_loss: 148.5233\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 155.8047 - val_loss: 148.5214\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 155.7689 - val_loss: 148.4955\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 155.7672 - val_loss: 148.6153\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 169.8293\n",
      "------------------------------------------------------------------------------------ 27\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 35ms/step - loss: 161.7925 - val_loss: 157.5778\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.7829 - val_loss: 157.5856\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 161.7767 - val_loss: 157.5992\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.7688 - val_loss: 157.6244\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.7610 - val_loss: 157.6960\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 133.2931\n",
      "------------------------------------------------------------------------------------ 28\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 159.7605 - val_loss: 147.8195\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 159.7494 - val_loss: 147.8184\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 159.7468 - val_loss: 147.8183\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 159.7385 - val_loss: 147.8289\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 159.7338 - val_loss: 147.8469\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 150.9887\n",
      "------------------------------------------------------------------------------------ 29\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 40ms/step - loss: 158.6305 - val_loss: 143.5728\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 158.6234 - val_loss: 143.5696\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 158.6214 - val_loss: 143.5649\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 158.6220 - val_loss: 143.5687\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 158.6194 - val_loss: 143.5521\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 160.0816\n",
      "------------------------------------------------------------------------------------ 30\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 41ms/step - loss: 153.4530 - val_loss: 180.0186\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 153.4457 - val_loss: 180.0315\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 153.4439 - val_loss: 180.0551\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 153.4138 - val_loss: 180.0825\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 153.4027 - val_loss: 180.1404\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 154.1595\n",
      "------------------------------------------------------------------------------------ 31\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 159.1186 - val_loss: 146.3904\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 159.1069 - val_loss: 146.4184\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 159.0839 - val_loss: 146.5175\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 159.0289 - val_loss: 146.6138\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 159.0141 - val_loss: 146.8998\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 155.8062\n",
      "------------------------------------------------------------------------------------ 32\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 158.0355 - val_loss: 136.3920\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 158.0288 - val_loss: 136.3903\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 158.0209 - val_loss: 136.3889\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 158.0100 - val_loss: 136.3771\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.9918 - val_loss: 136.3694\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 169.2921\n",
      "------------------------------------------------------------------------------------ 33\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 35ms/step - loss: 161.9325 - val_loss: 141.9467\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.9295 - val_loss: 141.9696\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.9200 - val_loss: 141.9724\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.9112 - val_loss: 142.0497\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 161.8613 - val_loss: 142.1657\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 145.6235\n",
      "------------------------------------------------------------------------------------ 34\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 33ms/step - loss: 156.3035 - val_loss: 141.9036\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.3006 - val_loss: 141.9074\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 156.3016 - val_loss: 141.9212\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 156.2983 - val_loss: 141.9049\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 156.2991 - val_loss: 141.9289\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 172.6403\n",
      "------------------------------------------------------------------------------------ 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 34ms/step - loss: 161.3285 - val_loss: 152.2071\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.3233 - val_loss: 152.2100\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.3204 - val_loss: 152.2250\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 161.3168 - val_loss: 152.2542\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 161.3062 - val_loss: 152.2654\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 139.9653\n",
      "------------------------------------------------------------------------------------ 36\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 33ms/step - loss: 156.1768 - val_loss: 172.0083\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.1512 - val_loss: 172.0426\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.1041 - val_loss: 172.1789\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.0222 - val_loss: 172.3649\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 155.9551 - val_loss: 172.4559\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 148.3795\n",
      "------------------------------------------------------------------------------------ 37\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 36ms/step - loss: 155.9110 - val_loss: 179.7940\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 155.9054 - val_loss: 179.8023\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 155.9092 - val_loss: 179.8349\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 155.8681 - val_loss: 179.8633\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 155.8315 - val_loss: 179.8948\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 142.4508\n",
      "------------------------------------------------------------------------------------ 38\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 157.9040 - val_loss: 155.7923\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 157.8918 - val_loss: 155.8061\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.8795 - val_loss: 155.8757\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 157.8512 - val_loss: 155.9663\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.8516 - val_loss: 156.0788\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 152.9979\n",
      "------------------------------------------------------------------------------------ 39\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 154.6676 - val_loss: 155.2667\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.6611 - val_loss: 155.2478\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 154.6435 - val_loss: 155.2451\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 154.6224 - val_loss: 155.2294\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.6143 - val_loss: 155.1585\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 169.3760\n",
      "------------------------------------------------------------------------------------ 40\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 36ms/step - loss: 157.7735 - val_loss: 151.1078\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 157.7686 - val_loss: 151.1087\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.7639 - val_loss: 151.1065\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.7624 - val_loss: 151.1111\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 157.7603 - val_loss: 151.1130\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 157.7845\n",
      "------------------------------------------------------------------------------------ 41\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 6s 46ms/step - loss: 154.6895 - val_loss: 166.5478\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.6826 - val_loss: 166.5338\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 154.6639 - val_loss: 166.5342\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 154.6210 - val_loss: 166.5090\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 154.5475 - val_loss: 166.4807\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 159.9911\n",
      "------------------------------------------------------------------------------------ 42\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 47ms/step - loss: 156.1426 - val_loss: 158.1911\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.1396 - val_loss: 158.2169\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.1342 - val_loss: 158.2129\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 156.1324 - val_loss: 158.2281\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 156.1233 - val_loss: 158.2543\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 159.5064\n",
      "------------------------------------------------------------------------------------ 43\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 5s 39ms/step - loss: 157.3936 - val_loss: 157.6686\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.3876 - val_loss: 157.6706\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 157.3940 - val_loss: 157.6841\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 157.3826 - val_loss: 157.6844\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.3824 - val_loss: 157.6803\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 154.0206\n",
      "------------------------------------------------------------------------------------ 44\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 35ms/step - loss: 157.3670 - val_loss: 149.2374\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.3644 - val_loss: 149.2395\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 157.3629 - val_loss: 149.2388\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.3640 - val_loss: 149.2308\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 157.3544 - val_loss: 149.2311\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 161.3230\n",
      "------------------------------------------------------------------------------------ 45\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 35ms/step - loss: 151.5557 - val_loss: 171.3460\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 151.5543 - val_loss: 171.3422\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 151.5525 - val_loss: 171.3420\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 151.5524 - val_loss: 171.3412\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 151.5571 - val_loss: 171.3414\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 170.3931\n",
      "------------------------------------------------------------------------------------ 46\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 6s 36ms/step - loss: 157.0812 - val_loss: 157.1824\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 157.0708 - val_loss: 157.1858\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 157.0732 - val_loss: 157.1847\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.0683 - val_loss: 157.1927\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 157.0713 - val_loss: 157.2088\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 155.9331\n",
      "------------------------------------------------------------------------------------ 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 150.8907 - val_loss: 182.2603\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 150.8855 - val_loss: 182.2635\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 150.8863 - val_loss: 182.2592\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 150.8863 - val_loss: 182.2624\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 150.8857 - val_loss: 182.2592\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 164.2768\n",
      "------------------------------------------------------------------------------------ 48\n",
      "(1461, 1, 4) (1461,)\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 4s 34ms/step - loss: 155.7953 - val_loss: 174.8523\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 155.7851 - val_loss: 174.8695\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 155.7699 - val_loss: 174.8887\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 155.7416 - val_loss: 174.9840\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 155.7176 - val_loss: 174.9392\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 147.2879\n",
      "------------------------------------------------------------------------------------ 49\n",
      "[12.358134789821579, 12.44622282157981, 12.441661962639, 12.379124426130355, 12.651586959266835, 12.729268291627543, 12.528316925093566, 12.658811710267896, 12.788308430732004, 12.598862587590062, 11.508292484049816, 13.468580629916811, 12.710997522138555, 12.329192488835504, 12.362665984887979, 12.117541349201552, 13.502686974894745, 12.086724658230086, 11.709981094201753, 12.567127495233162, 12.879977254906706, 12.330745597379936, 13.162971138922305, 12.513412603886966, 13.461600616646944, 11.554981323385558, 11.383412363011681, 13.031858873665145, 11.545263361184169, 12.287745032287885, 12.652334101956804, 12.416099040393458, 12.48223407898358, 13.011228553885498, 12.067456427875424, 13.139264012457566, 11.830693196667381, 12.181111857461303, 11.935275045229307, 12.369230524552902, 13.014453189484723, 12.561230040170043, 12.648758392316122, 12.629583452110689, 12.410503590315518, 12.701299669941815, 13.053468931569912, 12.487319007149939, 12.817050925762672, 12.136220872069858]\n",
      "EURGBP10080 ------------------------ RNN  12.492817453239411\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmPUlEQVR4nO2de7wdVZXnv+smgPJGE+SRxNDKw4QGGi8BBEew1QZljN3T0MH2jcYH+EKHKDM22sqnaadbHeXz0UkLg9jKQ9qxM4pGaZmhR0EMKshLCC1KgBZ8BRVFcu+aP06d3Dp1qk49Tj1O1f19P5/6nKq1115rnV1V69TZtWuXuTtCCCG6xVTTAQghhCgfJXchhOggSu5CCNFBlNyFEKKDKLkLIUQHWdh0AACLFi3y5cuXNx2GEEK0iptuuumn7r44rmwikvvy5cvZtGlT02EIIUSrMLMfJZWpW0YIITqIkrsQQnQQJXchhOggSu5CCNFBlNyFEKKDKLkLIUQHUXIXQogOkjrO3cwuBk4BHnL3QwPZ4cAngF2Be4G/dPdHgrJ3A2cAM8Bb3H1jNaHDrbfClVeOir0ceV11mvIfpyedwe2+rL+eJMui0yZbRepNTRX/zFtn1PE/38nyENMlwIXApSHZJ4F3uvv/NbPXAP8ZeI+ZrQDWACuB/YBrzOwgd58pN+wed9wBH/hAfJmmqRdiflDnj0nROqPqnnoqvOpV5bdLanJ39+vMbHlEfBBwXbD+NWAj8B5gNXC5uz8G/NDMNgOrgOtLizjEqaf2ljIY9WOQVFZmnab8x+lJZ3C7L+uvJ8my6LTJ1jgxzM4W/6yrTp3+ZmZg27b4ur/61fBxWAZFpx+4jV4i/wJwKrA0kO8P3BDS2xLIhjCztcBagGXLlhUMozyKdG8IIcSkUvSG6muAN5nZTcBuwO/zGnD39e4+7e7TixfHznsjhBCiIIWu3N39TuAFAGZ2EPCioOh+5q7iAZYEMiGEEDVS6MrdzPYOPqeA/0pv5AzABmCNme1kZgcABwI3lhGoEEKI7GQZCnkZcAKwyMy2AOcBu5rZmYHK54H/CeDut5nZlcDtwDbgzKpGygghhEjGfALGDE5PT7vmcxdCiHyY2U3uPh1XpidUhRCigyi5CyFEB1FyF0KIDqLkLoQQHUTJXQghOoiSuxBCdBAldyGE6CBK7kII0UGU3IUQooMouQshRAcpOp/7RPCVr8DZZ49nY5y52puqW6fvpnWb9p+kW4esSd9lydq23oTPU06B006jdFqd3PfYAw49tHj9cabVaapunb6b1m3af5JuHbI6fRd5Q1UWWdvWm/K/ciWV0OrkfuyxvUUIIcQg6nMXQogO0uor96uugjVrsulm6WMtux+4bp9V9GMLtZeolrPPhve9r3y7rU7uhxwC73pXul6WPtay+4Hr9llFP7ZQe4nqOeqoauy2Orkfeih84ANNRyGEEJNHq5N7XVdVdfhp6xVimV0Wk2qrarp0HNdJHfu4TcdRlFYn96uuqmZ8qBBC1MW6dXDBBeXbbXVyX7EC3vveenzpKmGYMq8EJ9lWl/Z9246xJLr0b/q446qx2+rkvnJldQ8ACCFEm9E4dyGE6CBK7kII0UFSk7uZXWxmD5nZrSHZEWZ2g5l9z8w2mdmqQG5m9lEz22xmt5jZkVUGL4QQIp4sfe6XABcCl4ZkHwTe5+5fNrMXBtsnACcDBwbL0cDHg08hxDwlPDFX0vp8Ll+8GPbZJ77txiE1ubv7dWa2PCoGdg/W9wAeCNZXA5e6uwM3mNmeZravuz9YVsBhvvIVOPfc5PK0u92jysep2xbbeWbGG3e7i7by2Cnivw6bVfsW6bziFfCpT5Vvt+hombcBG83s7+h17TwrkO8P3BfS2xLIhpK7ma0F1gIsW7asUBA33gjf/W6hqkIIMREsrGjMYlGzbwTe7u7/ZGanARcBz8tjwN3XA+sBpqenC/3er1kDu++ertdnUl/80KRuVS8saPJlCU34Liv2SbNVZixtWG/C5267UQlFk/srgbcG658DPhms3w8sDektCWSVcNBBvUUIIcQgRYdCPgA8J1h/LnB3sL4BeEUwauYYYGtV/e1CCCGSSb1yN7PL6I2EWWRmW4DzgNcB/93MFgK/I+g7B64GXghsBh4FXl1BzEIIIVLIMlrm9ISiZ8boOnDmuEEJIYQYDz2hKoQQHUTJXQghOkirZ4X8+tfhPe+p3k+Xphcdl3GmjB13utkmfU8abTleitDUfm7q+HzpS2Ht2nS9vLQ6uS9YADvvXI+vLs3pXZRxEsq4yagp33XN516ESY1rHJrcz+PQpO8kWp3cn/Oc3iKEEGIQ9bkLIUQHUXIXQogOouQuhBAdRMldCCE6SKtvqD7yCDzwwLA87u5z0h1p6WaTzWdb4y6zs+XYaYOfMNGZFqv6rNNXFZ/T03DccZROq5P7xo1w2mlNRyFENzBLX6am0nVgLtFX/Vm0ziSxbp2S+xBHHw2XXRZfFjcGOGlcsHSzyeazraJLlmRYxjKun/lIXT9AaZ877TTe90ii1cl9dhZ+//t6fNVxAtR1kk1yEm2DrSI6ebe7ZqMKunJO7rdfNQ9jtjq5f/vb8MpXNh2FEEIUZ906uOCC8u22OrmffDLcc0/1furoq6urP3CSb1y2wVYRnbzbXbNRBV06Jw84oBq7rU7us7Pwu98Ny5N2yiTJm44l/DmqT7BoWddsV71el5864nKfG1GT5bMsnap0q/b9trfB+95H6bQ6uWu0jBCTT/9mb9znqLIiukXtLVhQT3xxukcdVU27tzq5H3MMXHFFfFnSjZBJkjcdS/gzTjZuWddsV71el5+49SxXoFnXo/Sv5qta6vBR5bLnnsNtVgatTu5Ll/YWyP43so3lZdvM8rcx61/Lqm1MUjzjLDMz49uochHNsW4dHH98+XZbndw/9zl1y4jx6V+lp/2NLmvpdwFEl4ULy/dV9xJut7qW8D5s4/KEJ1RzXLc6uR98MJx77tz2qL/WceXR9amp0eVx9ft1ovJR/pPqjIqvSJ1RMY9KZmmJLstnGTbqikeILtLq5P6Od8A11zQdhRDjox+Z7hPuHg2zYgXcdlv5/lqd3PfZZ/CKVlRP0gE6nymjTdSu85ff/rYau6nJ3cwuBk4BHnL3QwPZFcDBgcqewC/d/Yig7N3AGcAM8BZ331h+2D0+/eneIsR8I3yDOHyzNmm9Lr2ZmeQRLHGyvPK26Wax8YIXlHdchMly5X4JcCFwaV/g7n/RXzezvwe2BusrgDXASmA/4BozO8jdZ0qMWYh5T/g+wsJW//8WVZHaqeHu1wE/jyszMwNOA/pzM64GLnf3x9z9h8BmYFVJsQohhMjIuD3WzwZ+4u53B9v7A/eFyrcEsiHMbK2ZbTKzTQ8//PCYYQghhAgzbnI/nbmr9ly4+3p3n3b36cWLF48ZhhBCiDCFe+vMbCHwZ8AzQ+L7gaWh7SWBTAghRI2Mc+X+POBOd98Skm0A1pjZTmZ2AHAgcOM4AQohhMhPanI3s8uA64GDzWyLmZ0RFK0h0iXj7rcBVwK3A18BztRIGSGEqB/zCXh6Ynp62jdt2tR0GEII0SrM7CZ3n44r0/OdQgjRQZTchRCig7T62baNG3uThxVlnB6ppuqWUV/ko45JveqaOKxL36UrnHEGvP3t5dttdXLfbTc45JDxbIxzIDZVt4z6Iht1/JDW9WPdpe/SJap6zKfVyX3vveHEE5PLRyVAlYmiJM2dn7ZdtKyrPqXX+9x3Xyqh1cn9u9+Fs85qOgohhCjOunVwwQXl2211cj/sMPjYx/LXG/XXsejfyrpt1h1LEmX+C5hUW2HytG1W3bR90rTPsnSLlOX9PnH7Pc93SdLLEp9ZsbY45phsMeWl1cn9llvgzW9uOgohhCjOunXwkpeUb7fVyf3kk+Gee5qOYv5S5r+ASbalexT1MR9HsD3pSeP5TqLVyX3XXXuLEEKIQfQQkxBCdBAldyGE6CBK7kII0UGU3IUQooMouQshRAdRchdCiA6i5C6EEB1EyV0IITqIkrsQQnSQVj+hyvXXw0UX1eNr1Nydk2h3FFMZf9OzxJM1ZrPyJrEvO640srZXHr9l6CbVL/O79/WKxJrlM69u0bqj/BaJI4tu/7hJq3vIIXDEEZRNu5P7+vVwySVNRyGEEMVZuRJuvbV0s+3ulvnZz5qOQAghxuPXv67EbLuT+x57NB2BEEKMx447VmI2tVvGzC4GTgEecvdDQ/I3A2cCM8CX3P2cQP5u4IxA/hZ331hF4AA873nw5S+XZy+pX7HofJ6TOlds0bjaUK/uGOuwF7YVfTtEHUT9ZH0zRtx2Vr0823ne9JHXTx26q1Yll41Blj73S4ALgUv7AjM7EVgNHO7uj5nZ3oF8BbAGWAnsB1xjZge5+0zZgQOwYgWsXl2OrbJfUTTJE5S3uazNcbTNVlH/bX7JaxO6p5xCFaQmd3e/zsyWR8RvBC5w98cCnYcC+Wrg8kD+QzPbDKwCri8v5BDXXguf/nQlpoWYaMq+GJlw3GGWKWZYwCxTvXVbOCzLsT7DFLNepF5S+dTcume3cdyP7+b5f1F+mxUdLXMQ8GwzOx/4HfBOd/82sD9wQ0hvSyAbwszWAmsBli1bViyKn/60WD3RDQomuF4tYxbDsyze+5xlCodAPjWkN2hvaljmUf2wjV7yYshW2M6c/1m3EXFMZYxpKrYNZpkaGWuczbB8lgVzccbElyRPtht/a9CpvluqDh/33luN3aLJfSHwJOAY4CjgSjP7gzwG3H09sB5genq60Fn66BHPYqcnfrJnL95JWhD5y3xoZftquIbhsXIAC9mO8zKq7vbyUX5HMfI7J7RjGkXrheqmxh3rq4wTz4laDFvNHFfLdKeK7zFRNqevq8Rs0eS+Bfi8uztwo5nNAouA+4GlIb0lgawS/sflu/PII6PfkJ32yzuqfJy6bbI9uO0D2zZCv59I5rb75RF/ZhEPUXuMLB8otWGRD3keUT+ib0F8Yc2h+ENO+7qOYeG2MhuWRer2t7dHud1WKEYbiCz4NMzm2ql/RWvmA3bn1ue+jVv8d4+LsR9bz1dYFv1eFvu9oHftELd/+200JBuoG2kDH7QTjWfkd3KGyqPE/SOY9TnZ3PHNUDtGv3fcdxq8jrLA53As//Gubbw1NsLxKJrcvwCcCFxrZgcBOwI/BTYAnzWzD9G7oXogcGMJccZy/MIbOIq/rsq8KIsqLhJ14Sk6wrdvXE0vnZZLlqGQlwEnAIvMbAtwHnAxcLGZ3Qr8HnhlcBV/m5ldCdwObAPOrGykDLDjIz9jK7uPYcETf9Wz1W6mbpO+466lyiJvXPGebcRWcq3RftLjir9+K8bg/5ChTr2McRSPJd5DHlt59mPdv9JFjv3y9mmcTX/0t2PbjyPLaJnTE4pelqB/PnD+OEFl5a6dVnJ+r9s+IO7vcH+boTKL0R3sv04uG/Y3qmxUF8pgnXDHQnL3SbQjI/5vdhVE+3Tz9AfntT1cHkc2/2XGOYr8P1DxXQ/j2ojrXorqR2vFx5KExWoN2vagC2V4fbRVH7AT7nzq+xi2SUgz2j3X7+SKL5vbHlUWth/1FxfL6HMyvH3a3jdTxUj3Vs8tY7vsyv/iTwdlgz2OKkvYLoMyf0Qm2VZS21Upb8JnT16+7d69gYSyUo71ZP/1xBKvl1jPBrcf2+spVEGrk/vs9TfwdP6w6TBaRdEbsZNSNilxTBpF2qs2xriuKPuixEp8PqCs2H6y6ZpS7ERpdXL3X/2K83hv9X5qOEHqPQnrPuHbfvczX/z592X+/RHvY7SdIsdY3j2X50cmm+7wqJQ43cFu16TYhkfHJLVjli6quFE6o+32bEfZebahPvdJZmqvvTht6z80HYYQQhRmnf1dJXZbndxPPORBvnHvs2rxVccNubpu+onsjOpzH0XeOnX4qKtOVfcWuqq715N2AN4ZqzsOrU7uiw7dh0XXXF6/4zpm40vrG0yaKbBO5tn8JgNU+d2rbtf5vN8mkUPLH+MOLU/uXHMNbNvWdBRiQsjfPwx5+ruz6Ge12YReXbbSh/7GDVNOt5XHZ5JuFr0itrLpxPfj33/XHhw1VDI+rU7ud/x6Cftwb6pe8sCl7KQnjvGu5ouM8B5tJ6lOdKxuuCT7ePw8OoOjgdPqx58A0ZHH6bHEj8Mefz+N10ZpevnbeVCvrhiS9YaPr/h4i+2TdFvDJXFj6wfL5qzn+0kbPNs8tD4q2uh4/AX/Xs0MLa1O7r854RTu+NHWxPK4nTon769nSdtpqTf5/nzUX9x2j7hZJyL1Uv5OD8URY9C2x5Q8Hnewatx4hLgxDIPjeRPf3exO3Ek04N+i4yVGnSRxJ2jadxmMN+oj/oSPu06LH/vcWx+MY27fxc/qErUBztyQ7PD3TLpedPAYG7HfJclnKNaBnJl2LRttu/hjJVoUf96MGmcyPF5l2E+FVNSddcBTF1Rit9XJ/Yd7Hclpj7++6TCE6AzGbIws+03EvtxCPwBm4W2PlPt2nWh5Fp3B7TSdND/9C5MUG7E6g9892cZc/b7sL4/4BVVksVYn96N+eAUb7AMDsmyPUI8anzpM9nGsw9c3WccjD19vjtYN+8iiN6BvceN9030XiS+5bra2H6UXPqVG2hp5A3z0d+yfzoNlw9f5czFNgQXbPud78H9Z9Hp98HvE6tqoWKLxDB7f0f0RNxviYIoCD46RJBtR/bAsuvT9bZ/DPWQ7bGf7djDDZu/PSIJOzHYWncHtYH9FZATywe0YPx6KNeqnH7unx2oPPjC0P8qg1cl9+QPXs9y/2XQY7aOaf5dCiCLcuhvwqtLNxr/ipC2U9f5UIYRoiqc/vRKzrb5y58lPhl13Lc9emePX414UPA51vem+LNoWbxuZxDZOOu6zxJr2guksdcap11Q8J56YbrcA7U7ue+wBhx3WW08cnlFw50f18+7YtOSe503p49oKy/t3/Ps6Wd7QnqSTVD4qhlFMarIKM07iyCsfpReOaxy7ZdeNO1ajbRg36iTLSJQiOmm+wudEUTv971v0ex1ySLpOAdqd3P/5n+Gb6nMXQrSXex/eheWve13pdlud3B9YchR7T12Rs1aBu4kFxrfmvgatw0fPUaFaVfuYwGv2xlGbzA+m/u3uSuy2OrlfcucqPjv7nbFspD2TNol1m/Y93yizvWZjhgqGhzMmDScc1rXAFtsH7Q2OqR7cDg/si+pOBWPb+3pTzDAVWJ9idmgZJV/ItgEfU9u/cV9vUGY4C0L1w3rh7bnYZgNZ2H5/e651Fwy09GxkOxyDh/wN64Tlg3Xi9aPtPafDgA4hvS380US9IHsiePFe/49juLrpMGKZ1ASaFFcZ8qpsz2LMsIAZFgafU2xjIbOh9RkWBNsL2BZ8hpc53R2YYSpGvnBI1rO1cPvyODuwjR22rz/OwoHtOb2FA7K5sh2Im1N8HIzZkMeZYH0mJAsvvW+0A9sGPsNlUTvhFujvgYU8zoLtfvs6MyxkG1PMBntgdvuPxFRk5H7auZHl3KnXRi89z2SeDz5fHE/Z+depOkVodXL//F6v47wKpsoUoi04UzzOTjzOTk2HIgry1K1beWkFdlud3J+4s/HMXe5M7K7uy6Ofo3Sy2InTj9VJNtko4/6r2H49EzNYJstAmqhuf70fV5y9LDa22yl5FOqo9oo7JtKOx6z6ectybyebLkzSc9ZN2yrbXh5bcedLeP2gP3xyaXGFaXVyZ+NGNv3mtKajmL945FMIkUzS+fKsdcAFpbtrdXLf5blH8frb/zF/xYQLsfAVWpELv0JXixnrOFZKTMbwZW2WK+UydLbLhmIKejVThtOP6yt6BdUXJLVrTy86A2JG2wmxpunkabcscWWixB9nd/BSn1co995VmffCyrK1YqdD+LNSLA2SmtzN7GLgFOAhdz80kL0XeB3wcKB2rrtfHZS9GzgDmAHe4u4bK4gbgGfv+G3e9JuXVWVeCCEq5zv7rQMOL91uliv3S4ALgUsj8g+7+8CbXc1sBbAGWAnsB1xjZge5+0wJsQ6x/EUr+fdfvD+z/sjf2UiH5NgXHwmdpcXspl9aZTbrw1fIRZCN+m024aMsP3lsFHlgt069sm0e9uzjszvOQWpyd/frzGx5Rnurgcvd/THgh2a2GVgFXF88xGS+8uMVnHbhiipMCyFELaxbBxecVL7dcfrczzKzVwCbgHe4+y+A/YEbQjpbAlklHHssXHVVNt08D4DOZ90ypviYbzbGrVOHj7rqZJ1eJeuIokmTVWHz6KPj/YxL0eT+ceD99PoL3g/8PfCaPAbMbC2wFmDZsmWFgliypLcIIYQYpFByd/ef9NfN7B+ALwab9wNLQ6pLAlmcjfXAeoDp6elC9+u/8Q34278tUrN6Knrdophwqui3rUq3af+ix0teAi+rYFxIoeRuZvu6+4PB5p8CtwbrG4DPmtmH6N1QPRC4cewoE3j0UdiypSrr46ODfH7Rhm63SfEv5nj44XSdImQZCnkZcAKwyMy2AOcBJ5jZEfS6Ze6F3vtd3f02M7sSuB3YBpxZ1UgZgKc9Dd7whqqsd5dJ/dFpS1yjxtgX1S3LziT4dO8ts7Nz69HtpPX5pjc723vnUBVkGS1zeoz4ohH65wPnjxNUVm66CV5fxWvDhRCdpP/o/9TU3Hp0O2m9bL3++i9/Wc13bfUTqieeCNdXMsiyu5Q970pZTOrf+dnZwe088xOF5aPmeckyJ0wWH0lx9Ql/lzzz0ETX03TDSa5/rE0FEyr2k1p/PW4J60XnY4nqhPXcB5NnUr1JGy2z337xfsal1cn92mvhNE0tI4RoMevWwQXlTy3T7uR+1FFwySVNR9EuJvUKeZLJ8k8nTWfc8rbbyCobt34dsrJtHnBAvI9xaXVyX768twghRJP0b47OzGRbtm2bW99jj2pianVyF2LSiRtFUdUyKX5mZweTV9YkV6deFTaLom6ZGL7/ffjMZ+a2R90ECjPf9cpMEEUSStfqJC2iPKamYMGC9GXhwux6T3xiefby+g5vP+MZ1bRZq5P7XXfBRz4yKEsam5t1DO980YtbosO50pa8+v06CxbU46eOOk3YnEQ/4WNsamowGfe3o0u/LKrT9xNe+mT9US1Dpy69JzyBSmh1cj9i81X8+vdxw/AL0j86S2ISXwwADH5Pj12dHCY4vpGv3yvjZeEeX+bEy6uIq0idcV8anfR9w2UWLGX6LjvurGW3PedNHPh/3jXSdhFandzv2/lgvrTLObnrxeXw1HciJuybpF3We+NRvjqJ+l5sDvb4OsFh1r/aiq5H6g3YiNSxkDx2PcFWFTYH9JK+W147MetzH54gDx1LYfsj62SwFYkzqzzqZyCsSJ2hw8V6x97QG6uS5Ax+97g27J8Xcfujt+3D9ayfzD2iO8J2nJ4Plw+1W0JsI8sD25ZQntYm0y96GlVgPgGdg9PT075p06amwxBCiFZhZje5+3RcWauv3H/+c9i8uXo/dfz+TcBv7HZG/UtI+wdRVd0qbY8bV1t1q/Kf9SZ1lfImfBaN5fjj4fnPz96+WWl1cv+Xf9ETqkKIdrNunZL7EMcfD1/6Uj2+Sr7X2piPNEb9g0j7d1FV3SptjxtXW3Wr9J9ldE2V8iZ8jhNLVbQ6ue+7b28RQggxSKuT+w9+ABs2NB1FMpNwJR5HmXHNB1tVU9f9lqbv68SOUkvYT/NJ9/DDYdWqeN1xaHVy/9734Jz8IyGFEGJieMMbqknuU+kqk0vTVyJCCDEuekI1hsMPh7/5m7nt6N+dpIdUsqx3uX4Wsvxwlnnzru22yq7bpO9x625/MGiMzzJstMVHVTPbtjq5P+MZ1U26I4QQbabVyX3LFrj55rnt6BVHnu3wxD5Z6yfJwvJxYqpiO/rauKyMM5wwS70sbZ3HXp6yNJvhYyNuO+0zrn7aelSW5jvJX1RWh3zUAzyjtmFu6tykh3+y2AvHlKafZn9UOeTzH6fv3nsP9Ac/SOm0Orl/6EPw4Q83HYUQQhTnnnuqsdvq5H7qqfD446N10vqa0/qlR/Vjp9nMM2wqrTxP/3lazKPqFy3LE09SWVb7VcSfpU2T2jH86T6sG11PsxMn79uO2hglz+sjjrR/pnHyvMdfnntFbbGdx9fBB1MJrU7uxx7bW4QQQgzS6qGQQggh4klN7mZ2sZk9ZGa3xpS9w8zczBYF22ZmHzWzzWZ2i5kdWUXQQgghRpPlyv0S4KSo0MyWAi8AfhwSnwwcGCxrgY+PH6IQQoi8pCZ3d78O+HlM0YeBc2Dg1S+rgUu9xw3Anmamqb2EEKJmCvW5m9lq4H53vzlStD9wX2h7SyCLs7HWzDaZ2aaHH364SBhCCCESyJ3czWxn4Fzgr8Zx7O7r3X3a3acXL148jikhhBARigyFfBpwAHCz9QZrLgG+Y2argPuBpSHdJYGsEn70I/jXf81Xp+wnH8uq02RcecYy16nbprjKlk1aPHllcU/TVrFdp6+qfJ96KrzmNcNtOS65k7u7fx/Yu79tZvcC0+7+UzPbAJxlZpcDRwNb3f3BsoKNcuON8PKXV2VdCFEG0Yexyt6u0nYdvh99tFi7ppGa3M3sMuAEYJGZbQHOc/eLEtSvBl4IbAYeBV5dUpyxnHQS3H13/npFnrSso06TceV5mrZO3TbFVbZs0uLJKytybIrySE3u7n56Svny0LoDZ44fVjZ22623CCGEGERPqAohRAdRchdCiA6i5C6EEB1EyV0IITpIq6f8ve8++OY3m46ifWgUQz7S2mtU+Th1q7TdZFxtqlOHjwMOgAMPzO8njVYn9xtugDVrmo5CCCGKs24dXHBB+XZbndz/5E/g9tubjqJdFHmqdT6T1l6jysepW6XtJuNqU5264tpvv/x1stDq5L777r1FCCHEILqhKoQQHUTJXQghOoiSuxBCdBAldyGE6CBK7kII0UFaPVrmq1+Fc84ZlndpStU6/WQtn682in6WYaOszzp8TE3lW8zy1+mSzapodXLfZRdYvnxQ1qU33dTpJ2t5X2fcsc5lxVGXjaKfZdgo67MuX+4wOzt60fMWc+ghphiOO663CCHaRfRHIMsPQt6lLTaPP76aNm51chdCtJP+a+amdNevMtS0QgjRQZTchRCigyi5CyFEB1FyF0KIDqLkLoQQHUTJXQghOkhqcjezi83sITO7NSR7v5ndYmbfM7Ovmtl+gdzM7KNmtjkoP7LK4IUQQsST5cr9EuCkiOy/ufth7n4E8EXgrwL5ycCBwbIW+Hg5YQohhMhDanJ39+uAn0dkj4Q2dwH6DxOvBi71HjcAe5rZvmUFK4QQIhuFn1A1s/OBVwBbgRMD8f7AfSG1LYHswZj6a+ld3bNs2bKiYQghhIih8A1Vd/8v7r4U+AxwVoH669192t2nFy9eXDQMIYQQMZQxt8xngKuB84D7gaWhsiWBrBKuvhre/OaqrM9Rxwx2bZklb5wpSsed3rRJ35NGW46XNPLsl67qvva1cPbZ2e1mpVByN7MD3f3uYHM1cGewvgE4y8wuB44Gtrr7UJdMWTz5yfCsZ1VlfZA6ksOkJ6BxEsq4yagp3+6Tu18mNa6s5NkvXdZ9ylOy6+YhNbmb2WXACcAiM9tC7wr9hWZ2MDAL/Ah4Q6B+NfBCYDPwKPDqCmLeztFH9xYhhBCDpCZ3dz89RnxRgq4DZ44blBBCiPHQE6pCCNFBlNyFEKKDKLkLIUQHUXIXQogOouQuhBAdRMldCCE6iJK7EEJ0EPMJeI7ZzB6m9zBUERYBPy0xnLKY1LhgcmNTXPlQXPnoYlxPdffYybkmIrmPg5ltcvfppuOIMqlxweTGprjyobjyMd/iUreMEEJ0ECV3IYToIF1I7uubDiCBSY0LJjc2xZUPxZWPeRVX6/vchRBCDNOFK3chhBARlNyFEKKDtCa5m9lJZvYDM9tsZu+KKd/JzK4Iyr9lZssnJK5XmdnDZva9YHltTXFdbGYPmdmtCeVmZh8N4r7FzI6ckLhOMLOtofb6qxpiWmpm15rZ7WZ2m5m9NUan9vbKGFft7RX4fYKZ3WhmNwexvS9Gp/ZzMmNcTZ2TC8zsu2b2xZiy8tvK3Sd+ARYA9wB/AOwI3AysiOi8CfhEsL4GuGJC4noVcGEDbfYfgCOBWxPKXwh8GTDgGOBbExLXCcAXa26rfYEjg/XdgLti9mPt7ZUxrtrbK/BrwK7B+g7At4BjIjpNnJNZ4mrqnDwb+Gzc/qqirdpy5b4K2Ozu/+buvwcup/fu1jCrgU8F61cBf2xW+Vsms8TVCO5+HfDzESqrgUu9xw3Anma27wTEVTvu/qC7fydY/xVwB7B/RK329soYVyME7fDrYHOHYImOzqj9nMwYV+2Y2RLgRcAnE1RKb6u2JPf9gftC21sYPsi367j7NmAr8OQJiAvgPwV/5a8ys6UVx5SVrLE3wbHB3+ovm9nKOh0Hf4f/iN4VX5hG22tEXNBQewXdDN8DHgK+5u6JbVbjOZklLqj/nPwIcA69907HUXpbtSW5t5n/DSx398OArzH36yzi+Q69+TIOBz4GfKEux2a2K/BPwNvc/ZG6/KaREldj7eXuM+5+BLAEWGVmh9blexQZ4qr1nDSzU4CH3P2mKv1EaUtyvx8I/7ouCWSxOma2ENgD+FnTcbn7z9z9sWDzk8AzK44pK1natHbc/ZH+32p3vxrYwcwWVe3XzHagl0A/4+6fj1FppL3S4mqqvSIx/BK4FjgpUtTEOZkaVwPn5HHAi83sXnpdt881s3+M6JTeVm1J7t8GDjSzA8xsR3o3HDZEdDYArwzW/xz4ugd3J5qMK9Iv+2J6/aaTwAbgFcEokGOAre7+YNNBmdk+/b5GM1tF7xitNCEE/i4C7nD3DyWo1d5eWeJqor0CX4vNbM9g/YnA84E7I2q1n5NZ4qr7nHT3d7v7EndfTi9HfN3dXxZRK72tFo5TuS7cfZuZnQVspDdC5WJ3v83M/hrY5O4b6J0EnzazzfRu2K2ZkLjeYmYvBrYFcb2q6rgAzOwyeiMpFpnZFuA8ejeXcPdPAFfTGwGyGXgUePWExPXnwBvNbBvwW2BNDT/SxwEvB74f9NUCnAssC8XVRHtliauJ9oLeSJ5PmdkCej8oV7r7F5s+JzPG1cg5GaXqttL0A0II0UHa0i0jhBAiB0ruQgjRQZTchRCigyi5CyFEB1FyF0KIDqLkLoQQHUTJXQghOsj/B5wPgLivzCEbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for q in currency_list:\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequences = [1]\n",
    "    \n",
    "    all_sequence_result = []\n",
    "        \n",
    "    for m in sequences:\n",
    "    \n",
    "        errors = []\n",
    "        for x in range(50):\n",
    "        \n",
    "            currency = q.replace('10080','')\n",
    "\n",
    "            data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "            #data = data.head(695)\n",
    "\n",
    "\n",
    "            X = data.drop(columns=['Unnamed: 0', \n",
    "                                   'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "                                  ])\n",
    "\n",
    "\n",
    "\n",
    "            y = data['nextweek_class']\n",
    "\n",
    "\n",
    "#             X_scaler = RobustScaler(quantile_range=(10.0, 90.0),)\n",
    "            \n",
    "#             X_scaler.fit(X)\n",
    "           \n",
    "#             X = X_scaler.transform(X)\n",
    "           \n",
    "#             X = pd.DataFrame(X, columns = [q+\"_class\", q+'_volume'])\n",
    "            \n",
    "\n",
    "            #print(X)\n",
    "\n",
    "\n",
    "            # after scaling the df, resulted in \"scaled_dataset\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            result = []\n",
    "            # for loop will walk for each of the 1500 rows\n",
    "            for i in range(0,len(X)):\n",
    "                # every group must have the same length, so if current loop position i + number \n",
    "                # of sequences is higher than df length, breaks\n",
    "                if i+m <= len(X):\n",
    "                    # this will add into the list as [[R1a,R1b...R1t],[R2a,R2b...R2t],...[R5a,R5b...R5t]]\n",
    "                    result.append(X[i:i+m].values)\n",
    "            # Converting to array + keras takes float32 better than 64\n",
    "            train_x = np.array(result)\n",
    "            #train_x  = train_x.astype('float32')\n",
    "            # making the y into same length as X\n",
    "            train_y = np.array(y.head(len(train_x)).values)\n",
    "\n",
    "            print(train_x.shape, train_y.shape)\n",
    "            #print(train_x[len(train_x)-10])\n",
    "            #print(train_y[len(train_x)-10])\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.15 )\n",
    "                               \n",
    "            \n",
    "\n",
    "            X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size = 0.15 )\n",
    "\n",
    "            \n",
    "\n",
    "            #Initializing the classifier Network\n",
    "            classifier = Sequential()\n",
    "\n",
    "            #Adding the input LSTM network layer\n",
    "            #classifier.add(CuDNNLSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "            classifier.add(LSTM(100, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "           \n",
    "           \n",
    "            classifier.add(LSTM(100,  return_sequences=True), )\n",
    "            #classifier.add(LSTM(100,  return_sequences=True))\n",
    "            \n",
    "\n",
    "            #classifier.add(Dense(units = 1))\n",
    "            classifier.add(LSTM(100,  return_sequences=False))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "            #Adding a second LSTM network layer\n",
    "\n",
    "            #classifier.add(LSTM(128))\n",
    "            #Adding a dense hidden layer\n",
    "            #classifier.add(Dense(64, activation='relu'))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "\n",
    "            #Adding the output layer\n",
    "            #classifier.add(Dense(35, activation='softmax'))\n",
    "\n",
    "            #Compiling the network\n",
    "            classifier.compile( loss='mean_squared_error',\n",
    "                            optimizer=Adam(learning_rate=0.001, decay=1e-6),\n",
    "                             )\n",
    "\n",
    "            #print(classifier.summary())\n",
    "\n",
    "            #Fitting the data to the model\n",
    "            history = classifier.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=5,\n",
    "                        validation_data=(X_val, y_val))        \n",
    "\n",
    "            val_loss  = classifier.evaluate(X_test, y_test)\n",
    "            error = sqrt(val_loss)\n",
    "            errors.append(error)\n",
    "            plt.plot(history.history['loss'],'red')\n",
    "            plt.plot(history.history['val_loss'], 'blue')\n",
    "            print('------------------------------------------------------------------------------------',x)\n",
    "        average_error = sum(errors)/len(errors)\n",
    "        print(errors)\n",
    "        print(q , \"------------------------ RNN \" , average_error)\n",
    "        all_sequence_result.append(str(m)+\" sequence\" )\n",
    "        all_sequence_result.append(average_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "65668a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 sequence', 12.492817453239411]\n"
     ]
    }
   ],
   "source": [
    "print(all_sequence_result)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ea025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798afda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86036c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
