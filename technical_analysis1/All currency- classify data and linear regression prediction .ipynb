{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "37ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fde693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_list = [#'USDCHF10080',\n",
    "                 #'GBPUSD10080', 'EURUSD10080', 'USDJPY10080', 'USDCAD10080', 'AUDUSD10080', 'NZDUSD10080',\n",
    "                 #'GBPCHF10080', 'EURCHF10080', 'CHFJPY10080', 'CADCHF10080', 'AUDCHF10080', 'NZDCHF10080', 'EURGBP10080',\n",
    "                 #'GBPJPY10080', 'GBPCAD10080', 'GBPAUD10080', 'EURJPY10080', 'EURCAD10080', 'EURAUD10080', 'EURNZD10080',\n",
    "                #'CADJPY10080', 'AUDJPY10080', 'NZDJPY10080', 'AUDCAD10080', 'NZDCAD10080', \n",
    "                'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "# for q in currency_list:\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     for x in range(5):\n",
    "\n",
    "#         currency = q.replace('10080','')\n",
    "\n",
    "#         data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "#         #data = data.head(695)\n",
    "\n",
    "\n",
    "#         X = data.drop(columns=['Unnamed: 0', \n",
    "#                                'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "#                               ])\n",
    "\n",
    "\n",
    "\n",
    "#         y = data['nextweek_class']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 )\n",
    "\n",
    "\n",
    "\n",
    "#         lnr= LinearRegression()\n",
    "#         lnr.fit(X_train, y_train)\n",
    "#         y_predict = lnr.predict(X_test)\n",
    "        \n",
    "        \n",
    "#         error = sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         errors.append(error)\n",
    "       \n",
    "        \n",
    "#     average_error = sum(errors)/len(errors)\n",
    "       \n",
    "#     print(q + \" Linear regression Average \" + str(average_error))\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1fcc8706",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 4, 1) (1429,)\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_174 (LSTM)              (None, 4, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_175 (LSTM)              (None, 1)                 408       \n",
      "=================================================================\n",
      "Total params: 41,208\n",
      "Trainable params: 41,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 3s 23ms/step - loss: 221.4101 - val_loss: 201.6375\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.9620 - val_loss: 202.2189\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 220.4920 - val_loss: 202.5220\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.1016 - val_loss: 203.3078\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.6090 - val_loss: 203.7383\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 219.3683 - val_loss: 204.0751\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.2013 - val_loss: 204.7528\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 219.3880 - val_loss: 204.6286\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.1288 - val_loss: 204.9236\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 219.0881 - val_loss: 204.7017\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.9206 - val_loss: 205.0881\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.8962 - val_loss: 204.7903\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.7836 - val_loss: 204.8534\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.6113 - val_loss: 204.9322\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 218.5816 - val_loss: 205.0842\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.7219 - val_loss: 204.7486\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.6231 - val_loss: 204.7699\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.5080 - val_loss: 204.9095\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 218.2473 - val_loss: 204.8382\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.2712 - val_loss: 205.0911\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 209.7849\n",
      "(1429, 4, 1) (1429,)\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_176 (LSTM)              (None, 4, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_177 (LSTM)              (None, 1)                 408       \n",
      "=================================================================\n",
      "Total params: 41,208\n",
      "Trainable params: 41,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 3s 29ms/step - loss: 214.9076 - val_loss: 216.6283\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 214.6208 - val_loss: 216.3210\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 214.4566 - val_loss: 216.2336\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 214.4094 - val_loss: 216.0357\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 214.1832 - val_loss: 215.9305\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 214.0022 - val_loss: 216.0134\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 213.8999 - val_loss: 215.8829\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 213.5863 - val_loss: 215.8145\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 213.4402 - val_loss: 215.6806\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 213.2861 - val_loss: 215.6444\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 212.9631 - val_loss: 215.9195\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 212.7217 - val_loss: 215.2339\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 212.6252 - val_loss: 214.9688\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 212.3225 - val_loss: 215.6942\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 211.9719 - val_loss: 214.7771\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 211.6467 - val_loss: 214.5858\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 211.4001 - val_loss: 215.1463\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 211.3978 - val_loss: 214.1738\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 211.1310 - val_loss: 214.6396\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 210.9522 - val_loss: 214.9349\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 225.3573\n",
      "(1429, 4, 1) (1429,)\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_178 (LSTM)              (None, 4, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_179 (LSTM)              (None, 1)                 408       \n",
      "=================================================================\n",
      "Total params: 41,208\n",
      "Trainable params: 41,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 3s 22ms/step - loss: 216.0659 - val_loss: 204.4707\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 215.6539 - val_loss: 204.7078\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 215.3502 - val_loss: 204.4237\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 214.9216 - val_loss: 204.6492\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 214.6660 - val_loss: 204.6993\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 214.5290 - val_loss: 204.7988\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 214.3045 - val_loss: 204.7966\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 214.4168 - val_loss: 204.5821\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 214.0138 - val_loss: 204.5630\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 213.7678 - val_loss: 204.2733\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 213.5148 - val_loss: 204.3759\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 213.5255 - val_loss: 204.5447\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 213.1734 - val_loss: 204.0543\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 212.9748 - val_loss: 204.5263\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 213.1831 - val_loss: 203.9561\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 212.8717 - val_loss: 203.8604\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 212.6173 - val_loss: 203.8598\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 212.3477 - val_loss: 203.9169\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 212.1723 - val_loss: 203.1893\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 8ms/step - loss: 212.0871 - val_loss: 203.1770\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 232.9074\n",
      "(1429, 4, 1) (1429,)\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_180 (LSTM)              (None, 4, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_181 (LSTM)              (None, 1)                 408       \n",
      "=================================================================\n",
      "Total params: 41,208\n",
      "Trainable params: 41,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 3s 22ms/step - loss: 221.0322 - val_loss: 237.4338\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.8177 - val_loss: 237.2253\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.6994 - val_loss: 237.0251\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.6031 - val_loss: 237.0628\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.4668 - val_loss: 236.8846\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.2459 - val_loss: 236.6768\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.0916 - val_loss: 236.3705\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.9467 - val_loss: 236.0491\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.7256 - val_loss: 236.0872\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.5408 - val_loss: 235.9801\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.4714 - val_loss: 236.0104\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.1326 - val_loss: 235.9063\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 219.1394 - val_loss: 235.7793\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.7959 - val_loss: 235.8688\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.4216 - val_loss: 236.1179\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 218.1863 - val_loss: 236.0760\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 217.8002 - val_loss: 236.4623\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 217.4010 - val_loss: 236.5360\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 217.0655 - val_loss: 237.0164\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 216.8877 - val_loss: 237.0875\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 179.7064\n",
      "(1429, 4, 1) (1429,)\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_182 (LSTM)              (None, 4, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_183 (LSTM)              (None, 1)                 408       \n",
      "=================================================================\n",
      "Total params: 41,208\n",
      "Trainable params: 41,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 3s 22ms/step - loss: 222.1435 - val_loss: 198.7941\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 221.9154 - val_loss: 198.4288\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 221.8767 - val_loss: 198.3880\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 221.6566 - val_loss: 198.3537\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 221.5933 - val_loss: 198.5000\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 221.4056 - val_loss: 198.2211\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 221.4241 - val_loss: 198.1841\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 221.1841 - val_loss: 198.2934\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 221.0392 - val_loss: 198.2907\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.8778 - val_loss: 198.2041\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.7964 - val_loss: 198.4208\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.5896 - val_loss: 198.3753\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.4731 - val_loss: 198.6002\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.3098 - val_loss: 198.4350\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.3497 - val_loss: 198.7416\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.8922 - val_loss: 198.4864\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 220.0672 - val_loss: 198.8524\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.6943 - val_loss: 198.5317\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.7332 - val_loss: 198.9242\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 219.5942 - val_loss: 198.5906\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 204.6379\n",
      "[14.48395150068581, 15.01190425252937, 15.261304823859518, 13.405462353027497, 14.30517123960199]\n",
      "AUDNZD10080 ------------------------ RNN  14.493558833940835\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for q in currency_list:\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for x in range(5):\n",
    "\n",
    "        currency = q.replace('10080','')\n",
    "\n",
    "        data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "        #data = data.head(695)\n",
    "\n",
    "\n",
    "        X = data.drop(columns=['Unnamed: 0', \n",
    "                               'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "                              ])\n",
    "\n",
    "\n",
    "\n",
    "        y = data['nextweek_class']\n",
    "      \n",
    "    \n",
    "        \n",
    "\n",
    "        #print(X.shape)\n",
    "        \n",
    "        \n",
    "        # after scaling the df, resulted in \"scaled_dataset\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        sequences = 4\n",
    "        \n",
    "        \n",
    "        \n",
    "        result = []\n",
    "        # for loop will walk for each of the 1500 rows\n",
    "        for i in range(0,len(X)):\n",
    "            # every group must have the same length, so if current loop position i + number \n",
    "            # of sequences is higher than df length, breaks\n",
    "            if i+sequences <= len(X):\n",
    "                # this will add into the list as [[R1a,R1b...R1t],[R2a,R2b...R2t],...[R5a,R5b...R5t]]\n",
    "                result.append(X[i:i+sequences].values)\n",
    "        # Converting to array + keras takes float32 better than 64\n",
    "        train_x = np.array(result)\n",
    "        #train_x  = train_x.astype('float32')\n",
    "        # making the y into same length as X\n",
    "        train_y = np.array(y.head(len(train_x)).values)\n",
    "\n",
    "        print(train_x.shape, train_y.shape)\n",
    "        #print(train_x[len(train_x)-10])\n",
    "        #print(train_y[len(train_x)-10])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.15 )\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size = 0.15 )\n",
    "       \n",
    "        \n",
    "       \n",
    "        #Initializing the classifier Network\n",
    "        classifier = Sequential()\n",
    "\n",
    "        #Adding the input LSTM network layer\n",
    "        #classifier.add(CuDNNLSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "        classifier.add(LSTM(100, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "        #classifier.add(LSTM(100,  return_sequences=True),)\n",
    "        #classifier.add(LSTM(100,  return_sequences=True), )\n",
    "        #classifier.add(LSTM(100,  return_sequences=True))\n",
    "      \n",
    "        #classifier.add(Dense(units = 1))\n",
    "        classifier.add(LSTM(1,  return_sequences=False))\n",
    "        #classifier.add(Dropout(0.2))\n",
    "        #Adding a second LSTM network layer\n",
    "        \n",
    "        #classifier.add(LSTM(128))\n",
    "        #Adding a dense hidden layer\n",
    "        #classifier.add(Dense(64, activation='relu'))\n",
    "        #classifier.add(Dropout(0.2))\n",
    "\n",
    "        #Adding the output layer\n",
    "        #classifier.add(Dense(35, activation='softmax'))\n",
    "      \n",
    "        #Compiling the network\n",
    "        classifier.compile( loss='mean_squared_error',\n",
    "                      optimizer=Adam(learning_rate=0.001, decay=1e-6),\n",
    "                      )\n",
    "        \n",
    "        print(classifier.summary())\n",
    "\n",
    "        #Fitting the data to the model\n",
    "        history = classifier.fit(X_train,\n",
    "                 y_train,\n",
    "                  epochs=20,\n",
    "                  validation_data=(X_val, y_val))        \n",
    "     \n",
    "        val_loss  = classifier.evaluate(X_test, y_test)\n",
    "        error = sqrt(val_loss)\n",
    "        errors.append(error)\n",
    "        plt.plot(history.history['loss'],'red')\n",
    "        plt.plot(history.history['val_loss'], 'blue')\n",
    "    average_error = sum(errors)/len(errors)\n",
    "    print(errors)\n",
    "    print(q , \"------------------------ RNN \" , average_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65668a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ea025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798afda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
