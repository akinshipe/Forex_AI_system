{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "37ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fde693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_list = [#'USDCHF10080',\n",
    "                 #'GBPUSD10080', 'EURUSD10080', \n",
    "    #'USDJPY10080', \n",
    "    #'USDCAD10080', \n",
    "    #'AUDUSD10080', \n",
    "    #'NZDUSD10080',\n",
    "                 #'GBPCHF10080',\n",
    "    #'EURCHF10080', \n",
    "    #'CHFJPY10080', \n",
    "    #'CADCHF10080',\n",
    "    #'AUDCHF10080', \n",
    "    #'NZDCHF10080', \n",
    "    'EURGBP10080',\n",
    "             #   'GBPCAD10080',\n",
    "     #'GBPAUD10080', \n",
    "    #'EURJPY10080',\n",
    "    #'EURCAD10080',\n",
    "    #'EURAUD10080',\n",
    "    #'EURNZD10080',\n",
    "    #'CADJPY10080', \n",
    "    #'AUDJPY10080',\n",
    "    #'NZDJPY10080',\n",
    "    #'AUDCAD10080', \n",
    "    #'NZDCAD10080', \n",
    "                #'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "# for q in currency_list:\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     for x in range(5):\n",
    "\n",
    "#         currency = q.replace('10080','')\n",
    "\n",
    "#         data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "#         #data = data.head(695)\n",
    "\n",
    "\n",
    "#         X = data.drop(columns=['Unnamed: 0', \n",
    "#                                'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "#                               ])\n",
    "\n",
    "\n",
    "\n",
    "#         y = data['nextweek_class']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 )\n",
    "\n",
    "\n",
    "\n",
    "#         lnr= LinearRegression()\n",
    "#         lnr.fit(X_train, y_train)\n",
    "#         y_predict = lnr.predict(X_test)\n",
    "        \n",
    "        \n",
    "#         error = sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         errors.append(error)\n",
    "       \n",
    "        \n",
    "#     average_error = sum(errors)/len(errors)\n",
    "       \n",
    "#     print(q + \" Linear regression Average \" + str(average_error))\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc8706",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 32ms/step - loss: 169.3234\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 169.3100\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 169.2922\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 169.2500\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 169.2112\n",
      "4/4 [==============================] - 2s 11ms/step - loss: 174.6616\n",
      "------------------------------------------------------------------------------------ 0\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 34ms/step - loss: 169.6727\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 169.6684\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 169.6621\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 169.6528\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 169.6395\n",
      "4/4 [==============================] - 2s 10ms/step - loss: 172.6933\n",
      "------------------------------------------------------------------------------------ 1\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 30ms/step - loss: 171.9514\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 171.9126\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 171.8471\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 171.6911\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 171.4868\n",
      "4/4 [==============================] - 2s 10ms/step - loss: 160.9707\n",
      "------------------------------------------------------------------------------------ 2\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 30ms/step - loss: 173.7406\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 173.7275\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 173.7168\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 173.6944\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 173.6171\n",
      "4/4 [==============================] - 3s 10ms/step - loss: 149.7075\n",
      "------------------------------------------------------------------------------------ 3\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 29ms/step - loss: 173.2801\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 173.2734\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 173.2635\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 173.2408\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 173.2260\n",
      "4/4 [==============================] - 2s 11ms/step - loss: 152.0433\n",
      "------------------------------------------------------------------------------------ 4\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 10s 29ms/step - loss: 167.0767\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 167.0724\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 167.0537\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 167.0320\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 167.0043\n",
      "4/4 [==============================] - 2s 9ms/step - loss: 187.4325\n",
      "------------------------------------------------------------------------------------ 5\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 10s 28ms/step - loss: 168.2410\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 168.2335\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 168.2259\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 168.2126\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 168.1796\n",
      "4/4 [==============================] - 2s 9ms/step - loss: 180.6810\n",
      "------------------------------------------------------------------------------------ 6\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 33ms/step - loss: 171.9011\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 171.8902\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 171.8766\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 171.8488\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 171.7938\n",
      "4/4 [==============================] - 2s 11ms/step - loss: 160.1382\n",
      "------------------------------------------------------------------------------------ 7\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 33ms/step - loss: 174.2135\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 174.1946: 0s - loss: 166\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 174.1425\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 174.0683\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 173.9300\n",
      "4/4 [==============================] - 2s 13ms/step - loss: 147.7678\n",
      "------------------------------------------------------------------------------------ 8\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 32ms/step - loss: 165.4966\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 165.4923\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 165.4869\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 165.4828\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 165.4680\n",
      "4/4 [==============================] - 2s 13ms/step - loss: 196.3776\n",
      "------------------------------------------------------------------------------------ 9\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 37ms/step - loss: 169.1023\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 169.0782\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 169.0474\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 168.9385\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 168.7507\n",
      "4/4 [==============================] - 3s 12ms/step - loss: 177.6571\n",
      "------------------------------------------------------------------------------------ 10\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 33ms/step - loss: 167.0340\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 167.0262\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 167.0179\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 167.0023\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 166.9833\n",
      "4/4 [==============================] - 2s 12ms/step - loss: 187.5437\n",
      "------------------------------------------------------------------------------------ 11\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 34ms/step - loss: 173.4887\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 173.4784\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 173.4545\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 173.4307\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 173.3815\n",
      "4/4 [==============================] - 2s 12ms/step - loss: 151.0699\n",
      "------------------------------------------------------------------------------------ 12\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 32ms/step - loss: 171.3280\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 171.3121\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 171.2869\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 171.2562\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 171.1385\n",
      "4/4 [==============================] - 2s 12ms/step - loss: 163.4174\n",
      "------------------------------------------------------------------------------------ 13\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 8s 36ms/step - loss: 170.6480\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 170.6309\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 170.6022\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 170.5462\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 170.4453\n",
      "4/4 [==============================] - 2s 14ms/step - loss: 167.4398\n",
      "------------------------------------------------------------------------------------ 14\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 33ms/step - loss: 176.1024\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 176.0965\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 176.0908\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 176.0793\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 176.0484\n",
      "4/4 [==============================] - 2s 13ms/step - loss: 136.3617\n",
      "------------------------------------------------------------------------------------ 15\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 33ms/step - loss: 169.1105\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 169.1022\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 169.0881\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 169.0391\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 168.9648\n",
      "4/4 [==============================] - 2s 10ms/step - loss: 175.5367\n",
      "------------------------------------------------------------------------------------ 16\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 12s 32ms/step - loss: 161.2234\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 161.2116: 0s - loss: 164.\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 161.2027\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 161.1584\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 161.0734\n",
      "4/4 [==============================] - 3s 10ms/step - loss: 220.6165\n",
      "------------------------------------------------------------------------------------ 17\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 34ms/step - loss: 174.1688\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 174.1631\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 174.1572\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 174.1549\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 174.1435\n",
      "4/4 [==============================] - 2s 12ms/step - loss: 147.2700\n",
      "------------------------------------------------------------------------------------ 18\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 32ms/step - loss: 171.2123\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 171.1977\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 171.1756\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 171.1514\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 171.1033: 0s - loss: 169\n",
      "4/4 [==============================] - 2s 11ms/step - loss: 164.0367\n",
      "------------------------------------------------------------------------------------ 19\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 32ms/step - loss: 172.3166\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 172.3093\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 172.2906\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 172.2660\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 172.2509\n",
      "4/4 [==============================] - 2s 10ms/step - loss: 157.4501\n",
      "------------------------------------------------------------------------------------ 20\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 31ms/step - loss: 167.0080\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 166.9967\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 166.9768\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 166.9346\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 166.8631\n",
      "4/4 [==============================] - 2s 11ms/step - loss: 187.9568\n",
      "------------------------------------------------------------------------------------ 21\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 8s 33ms/step - loss: 172.8987\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 172.8848\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 172.8694\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 172.8388: 0s - loss: 167.\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 172.7801\n",
      "4/4 [==============================] - 3s 13ms/step - loss: 154.6208\n",
      "------------------------------------------------------------------------------------ 22\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 11s 33ms/step - loss: 171.8565\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 171.8479\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 171.8417\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 171.8249\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 171.8038\n",
      "4/4 [==============================] - 2s 12ms/step - loss: 160.3867\n",
      "------------------------------------------------------------------------------------ 23\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 12s 33ms/step - loss: 164.8283\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 164.8224\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 164.8148\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 164.8066\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 164.7929\n",
      "4/4 [==============================] - 2s 10ms/step - loss: 200.0680\n",
      "------------------------------------------------------------------------------------ 24\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 33ms/step - loss: 167.8907\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 167.8814\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 167.8651\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 167.8403\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 167.7941\n",
      "4/4 [==============================] - 2s 11ms/step - loss: 182.7184\n",
      "------------------------------------------------------------------------------------ 25\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 9s 32ms/step - loss: 173.5904\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 173.5871\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 173.5765\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 173.5700\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 173.5570\n",
      "4/4 [==============================] - 2s 11ms/step - loss: 150.4244\n",
      "------------------------------------------------------------------------------------ 26\n",
      "(713, 1, 6) (713,)\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "for q in currency_list:\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequences = [1]\n",
    "    \n",
    "    all_sequence_result = []\n",
    "        \n",
    "    for m in sequences:\n",
    "    \n",
    "        errors = []\n",
    "        for x in range(30):\n",
    "        \n",
    "            currency = q.replace('10080','')\n",
    "\n",
    "            data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "            #data = data.head(695)\n",
    "\n",
    "\n",
    "            X = data.drop(columns=['Unnamed: 0', \n",
    "                                   'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "                                  ])\n",
    "\n",
    "\n",
    "\n",
    "            y = data['nextweek_class']\n",
    "\n",
    "\n",
    "#             X_scaler = RobustScaler(quantile_range=(10.0, 90.0),)\n",
    "            \n",
    "#             X_scaler.fit(X)\n",
    "           \n",
    "#             X = X_scaler.transform(X)\n",
    "           \n",
    "#             X = pd.DataFrame(X, columns = [q+\"_class\", q+'_volume'])\n",
    "            \n",
    "\n",
    "            #print(X)\n",
    "\n",
    "\n",
    "            # after scaling the df, resulted in \"scaled_dataset\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            result = []\n",
    "            # for loop will walk for each of the 1500 rows\n",
    "            for i in range(0,len(X)):\n",
    "                # every group must have the same length, so if current loop position i + number \n",
    "                # of sequences is higher than df length, breaks\n",
    "                if i+m <= len(X):\n",
    "                    # this will add into the list as [[R1a,R1b...R1t],[R2a,R2b...R2t],...[R5a,R5b...R5t]]\n",
    "                    result.append(X[i:i+m].values)\n",
    "            # Converting to array + keras takes float32 better than 64\n",
    "            train_x = np.array(result)\n",
    "            #train_x  = train_x.astype('float32')\n",
    "            # making the y into same length as X\n",
    "            train_y = np.array(y.head(len(train_x)).values)\n",
    "\n",
    "            print(train_x.shape, train_y.shape)\n",
    "            #print(train_x[len(train_x)-10])\n",
    "            #print(train_y[len(train_x)-10])\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.15 )\n",
    "                               \n",
    "            \n",
    "\n",
    "            #X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size = 0.15 )\n",
    "\n",
    "            \n",
    "\n",
    "            #Initializing the classifier Network\n",
    "            classifier = Sequential()\n",
    "\n",
    "            #Adding the input LSTM network layer\n",
    "            #classifier.add(CuDNNLSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "            classifier.add(LSTM(100, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "           \n",
    "           \n",
    "            classifier.add(LSTM(100,  return_sequences=True), )\n",
    "            #classifier.add(LSTM(100,  return_sequences=True))\n",
    "            \n",
    "\n",
    "            #classifier.add(Dense(units = 1))\n",
    "            classifier.add(LSTM(100,  return_sequences=False))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "            #Adding a second LSTM network layer\n",
    "\n",
    "            #classifier.add(LSTM(128))\n",
    "            #Adding a dense hidden layer\n",
    "            #classifier.add(Dense(64, activation='relu'))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "\n",
    "            #Adding the output layer\n",
    "            #classifier.add(Dense(35, activation='softmax'))\n",
    "\n",
    "            #Compiling the network\n",
    "            classifier.compile( loss='mean_squared_error',\n",
    "                            optimizer=Adam(learning_rate=0.001, decay=1e-6),\n",
    "                             )\n",
    "\n",
    "            #print(classifier.summary())\n",
    "\n",
    "            #Fitting the data to the model\n",
    "            history = classifier.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=5,\n",
    "                        #validation_data=(X_val, y_val)\n",
    "                                    )        \n",
    "\n",
    "            val_loss  = classifier.evaluate(X_test, y_test)\n",
    "            error = sqrt(val_loss)\n",
    "            errors.append(error)\n",
    "            plt.plot(history.history['loss'],'red')\n",
    "            #plt.plot(history.history['val_loss'], 'blue')\n",
    "            print('------------------------------------------------------------------------------------',x)\n",
    "        average_error = sum(errors)/len(errors)\n",
    "        print(errors)\n",
    "        print(q , \"------------------------ RNN \" , average_error)\n",
    "        all_sequence_result.append(str(m)+\" sequence\" )\n",
    "        all_sequence_result.append(average_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a49ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65668a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_sequence_result)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ea025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798afda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4128197",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
