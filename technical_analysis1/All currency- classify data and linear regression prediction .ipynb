{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "37ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "fde693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_list = [#'USDCHF1440',\n",
    "                 'GBPUSD1440',\n",
    "    #'EURUSD1440', \n",
    "    #'USDJPY1440', \n",
    "    #'USDCAD1440', \n",
    "    #'AUDUSD1440', \n",
    "    #'NZDUSD1440',\n",
    "                 #'GBPCHF1440',\n",
    "    #'EURCHF1440', \n",
    "    #'CHFJPY1440', \n",
    "    #'CADCHF1440',\n",
    "    #'AUDCHF1440', \n",
    "    #'NZDCHF1440', \n",
    "    #'EURGBP1440',\n",
    "             #   'GBPCAD1440',\n",
    "     #'GBPAUD1440', \n",
    "    #'EURJPY1440',\n",
    "    #'EURCAD1440',\n",
    "    #'EURAUD1440',\n",
    "    #'EURNZD1440',\n",
    "    #'CADJPY1440', \n",
    "    #'AUDJPY1440',\n",
    "    #'NZDJPY1440',\n",
    "    #'AUDCAD1440', \n",
    "    #'NZDCAD1440', \n",
    "                #'AUDNZD1440'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "# for q in currency_list:\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     for x in range(5):\n",
    "\n",
    "#         currency = q.replace('1440','')\n",
    "\n",
    "#         data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "#         #data = data.head(695)\n",
    "\n",
    "\n",
    "#         X = data.drop(columns=['Unnamed: 0', \n",
    "#                                'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "#                               ])\n",
    "\n",
    "\n",
    "\n",
    "#         y = data['nextweek_class']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 )\n",
    "\n",
    "\n",
    "\n",
    "#         lnr= LinearRegression()\n",
    "#         lnr.fit(X_train, y_train)\n",
    "#         y_predict = lnr.predict(X_test)\n",
    "        \n",
    "        \n",
    "#         error = sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         errors.append(error)\n",
    "       \n",
    "        \n",
    "#     average_error = sum(errors)/len(errors)\n",
    "       \n",
    "#     print(q + \" Linear regression Average \" + str(average_error))\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc8706",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 111ms/step - loss: 134.3039 - val_loss: 137.8347\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 134.1902 - val_loss: 137.9800\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 133.9090 - val_loss: 138.3350\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 133.6292 - val_loss: 138.6577\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 133.5353 - val_loss: 138.8952\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 138.8952\n",
      "------------------------------------------------------------------------------------ 0\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 114ms/step - loss: 134.6408 - val_loss: 135.9736\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.4997 - val_loss: 136.2151\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.2323 - val_loss: 136.5261\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.0271 - val_loss: 136.7811\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 133.8707 - val_loss: 136.9876\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 136.9876\n",
      "------------------------------------------------------------------------------------ 1\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 110ms/step - loss: 135.0904 - val_loss: 133.4494\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 135.0347 - val_loss: 133.3188\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.9370 - val_loss: 133.1422\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 134.8012 - val_loss: 133.0139\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 134.7292 - val_loss: 133.0125\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 133.0125\n",
      "------------------------------------------------------------------------------------ 2\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 110ms/step - loss: 138.6313 - val_loss: 113.4653\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 138.6024 - val_loss: 113.5513\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 138.3993 - val_loss: 113.7241\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 138.1537 - val_loss: 113.8971\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 138.0123 - val_loss: 114.0259\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 114.0259\n",
      "------------------------------------------------------------------------------------ 3\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 115ms/step - loss: 133.4726 - val_loss: 142.5404\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 133.4362 - val_loss: 142.4332\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 133.3393 - val_loss: 142.2925\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 133.2096 - val_loss: 142.0770\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 133.0455 - val_loss: 141.8642\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 141.8642\n",
      "------------------------------------------------------------------------------------ 4\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 108ms/step - loss: 134.9039 - val_loss: 134.4274\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 134.7917 - val_loss: 134.4853\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 134.5791 - val_loss: 134.6977\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 134.3637 - val_loss: 134.8930\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 134.2042 - val_loss: 134.9638\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 134.9638\n",
      "------------------------------------------------------------------------------------ 5\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 105ms/step - loss: 137.2545 - val_loss: 121.2129\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 137.2091 - val_loss: 121.1141\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 137.1252 - val_loss: 120.7062\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 136.9708 - val_loss: 120.4014\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 136.9102 - val_loss: 120.2096\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 120.2096\n",
      "------------------------------------------------------------------------------------ 6\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 111ms/step - loss: 136.4139 - val_loss: 125.9525\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 136.3839 - val_loss: 125.7117\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 136.2408 - val_loss: 125.5389\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 136.1661 - val_loss: 125.4768\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 136.1134 - val_loss: 125.2813\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 125.2813\n",
      "------------------------------------------------------------------------------------ 7\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 118ms/step - loss: 134.2589 - val_loss: 138.1137\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 134.2257 - val_loss: 138.0094\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 134.1569 - val_loss: 137.7770\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 134.0125 - val_loss: 137.4346\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 133.8809 - val_loss: 137.2809\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 137.2809\n",
      "------------------------------------------------------------------------------------ 8\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 116ms/step - loss: 133.7492 - val_loss: 141.1062\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 133.7179 - val_loss: 141.0653\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 133.6490 - val_loss: 140.9216\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 133.4938 - val_loss: 140.7793\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 133.3947 - val_loss: 140.7485\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 140.7485\n",
      "------------------------------------------------------------------------------------ 9\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 108ms/step - loss: 134.6189 - val_loss: 136.0742\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.5429 - val_loss: 136.0564\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.3876 - val_loss: 136.0407\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.1964 - val_loss: 136.1147\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.0107 - val_loss: 136.1457\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 136.1457\n",
      "------------------------------------------------------------------------------------ 10\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 111ms/step - loss: 130.6586 - val_loss: 158.4159\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 130.5982 - val_loss: 158.4170\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 130.4064 - val_loss: 158.4528\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 130.1425 - val_loss: 158.6333\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 130.0070 - val_loss: 158.6467\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 158.6467\n",
      "------------------------------------------------------------------------------------ 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 110ms/step - loss: 133.7950 - val_loss: 140.8206\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 133.7512 - val_loss: 140.7442\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 133.6662 - val_loss: 140.5742\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 133.5905 - val_loss: 140.4912\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 133.4546 - val_loss: 140.3647\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 140.3647\n",
      "------------------------------------------------------------------------------------ 12\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 108ms/step - loss: 132.3268 - val_loss: 149.1087\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 132.3080 - val_loss: 149.0507\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 132.2337 - val_loss: 149.0079\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 132.1174 - val_loss: 148.8218\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 131.9052 - val_loss: 148.7410\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 148.7410\n",
      "------------------------------------------------------------------------------------ 13\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 13s 148ms/step - loss: 138.4788 - val_loss: 114.3515\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 138.4322 - val_loss: 114.2958\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 138.3427 - val_loss: 114.1693\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 138.1689 - val_loss: 114.0850\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 138.0020 - val_loss: 114.0023\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 114.0023\n",
      "------------------------------------------------------------------------------------ 14\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 121ms/step - loss: 133.9975 - val_loss: 139.6617\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 133.9391 - val_loss: 139.5553\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 133.8540 - val_loss: 139.4288\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 133.7053 - val_loss: 139.2379\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 133.5928 - val_loss: 139.1310\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 139.1310\n",
      "------------------------------------------------------------------------------------ 15\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 115ms/step - loss: 132.5240 - val_loss: 147.8684\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 132.4906 - val_loss: 147.8233\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 132.4575 - val_loss: 147.5741\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 132.3895 - val_loss: 147.3196\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 132.3460 - val_loss: 147.2209\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 147.2209\n",
      "------------------------------------------------------------------------------------ 16\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 142ms/step - loss: 136.9205 - val_loss: 123.0489\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 136.8969 - val_loss: 122.9053\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 136.7961 - val_loss: 122.8151\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 136.7268 - val_loss: 122.6603\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 136.6322 - val_loss: 122.4400\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 122.4400\n",
      "------------------------------------------------------------------------------------ 17\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 110ms/step - loss: 133.4065 - val_loss: 142.9190\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 133.3126 - val_loss: 142.9401\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 133.1157 - val_loss: 143.0352\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 132.9287 - val_loss: 143.0985\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 132.8528 - val_loss: 143.1436\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 143.1436\n",
      "------------------------------------------------------------------------------------ 18\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 113ms/step - loss: 136.3783 - val_loss: 126.1631\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 136.3271 - val_loss: 126.0521\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 136.1959 - val_loss: 125.8240\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 136.0445 - val_loss: 125.5912\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 135.9380 - val_loss: 125.5580\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 125.5580\n",
      "------------------------------------------------------------------------------------ 19\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 117ms/step - loss: 135.3988 - val_loss: 131.7461\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 135.3035 - val_loss: 131.8252\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 135.1385 - val_loss: 132.1040\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.7704 - val_loss: 132.2551\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 134.6728 - val_loss: 132.4010\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 132.4010\n",
      "------------------------------------------------------------------------------------ 20\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 112ms/step - loss: 130.1915 - val_loss: 161.0863\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 130.1328 - val_loss: 161.1101\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 129.9699 - val_loss: 161.2271\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 129.6865 - val_loss: 161.5759\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 129.4855 - val_loss: 161.6784\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 161.6784\n",
      "------------------------------------------------------------------------------------ 21\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 113ms/step - loss: 130.3353 - val_loss: 160.1367\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 130.3072 - val_loss: 159.9766\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 130.2671 - val_loss: 159.8518\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 130.2081 - val_loss: 159.3937\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 130.1600 - val_loss: 159.2639\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 159.2639\n",
      "------------------------------------------------------------------------------------ 22\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 113ms/step - loss: 134.2100 - val_loss: 138.3710\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 134.1589 - val_loss: 138.2646\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 134.0519 - val_loss: 138.1698\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 133.9547 - val_loss: 138.1081\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 133.8058 - val_loss: 137.9762\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 137.9762\n",
      "------------------------------------------------------------------------------------ 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 111ms/step - loss: 132.2657 - val_loss: 149.2925\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 132.2041 - val_loss: 149.1805\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 132.0851 - val_loss: 149.1162\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 131.9733 - val_loss: 148.9885\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 131.8401 - val_loss: 148.9253\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 148.9253\n",
      "------------------------------------------------------------------------------------ 24\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 107ms/step - loss: 138.1483 - val_loss: 116.1996\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 138.1027 - val_loss: 116.0951\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 138.0075 - val_loss: 115.8345\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 137.8876 - val_loss: 115.8701\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 137.7670 - val_loss: 115.6705\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 115.6705\n",
      "------------------------------------------------------------------------------------ 25\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 140ms/step - loss: 134.4303 - val_loss: 137.1862\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 134.4193 - val_loss: 137.1217\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 134.3934 - val_loss: 136.8867\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 134.3415 - val_loss: 136.7594\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 134.3067 - val_loss: 136.3155\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 136.3155\n",
      "------------------------------------------------------------------------------------ 26\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 11s 110ms/step - loss: 135.0133 - val_loss: 133.8764\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 134.9035 - val_loss: 133.8391\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 134.6870 - val_loss: 133.8344\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 134.5266 - val_loss: 133.8789\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 134.4356 - val_loss: 133.8766\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 133.8766\n",
      "------------------------------------------------------------------------------------ 27\n",
      "(969, 1, 2) (969,)\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "for q in currency_list:\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequences = [1,]\n",
    "    \n",
    "    all_sequence_result = []\n",
    "        \n",
    "    for m in sequences:\n",
    "    \n",
    "        errors = []\n",
    "        for x in range(30):\n",
    "        \n",
    "            currency = q.replace('1440','')\n",
    "\n",
    "            data = pd.read_excel('files/currency_training_data/' + q +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "            #data = data.head(695)\n",
    "\n",
    "\n",
    "            X = data.drop(columns=['Unnamed: 0', \n",
    "                                   'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "                                  ])\n",
    "\n",
    "\n",
    "\n",
    "            y = data['nextweek_class']\n",
    "\n",
    "\n",
    "#             X_scaler = RobustScaler(quantile_range=(10.0, 90.0),)\n",
    "            \n",
    "#             X_scaler.fit(X)\n",
    "           \n",
    "#             X = X_scaler.transform(X)\n",
    "           \n",
    "#             X = pd.DataFrame(X, columns = [q+\"_class\", q+'_volume'])\n",
    "            \n",
    "\n",
    "            #print(X)\n",
    "\n",
    "\n",
    "            # after scaling the df, resulted in \"scaled_dataset\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            result = []\n",
    "            # for loop will walk for each of the 1500 rows\n",
    "            for i in range(0,len(X)):\n",
    "                # every group must have the same length, so if current loop position i + number \n",
    "                # of sequences is higher than df length, breaks\n",
    "                if i+m <= len(X):\n",
    "                    # this will add into the list as [[R1a,R1b...R1t],[R2a,R2b...R2t],...[R5a,R5b...R5t]]\n",
    "                    result.append(X[i:i+m].values)\n",
    "            # Converting to array + keras takes float32 better than 64\n",
    "            train_x = np.array(result)\n",
    "            #train_x  = train_x.astype('float32')\n",
    "            # making the y into same length as X\n",
    "            train_y = np.array(y.head(len(train_x)).values)\n",
    "\n",
    "            print(train_x.shape, train_y.shape)\n",
    "            #print(train_x[len(train_x)-10])\n",
    "            #print(train_y[len(train_x)-10])\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.15 )\n",
    "                               \n",
    "            \n",
    "\n",
    "            #X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size = 0.15 )\n",
    "\n",
    "            \n",
    "\n",
    "            #Initializing the classifier Network\n",
    "            classifier = Sequential()\n",
    "\n",
    "            #Adding the input LSTM network layer\n",
    "            #classifier.add(CuDNNLSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "            classifier.add(LSTM(100, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "           \n",
    "           \n",
    "            classifier.add(LSTM(100,  return_sequences=True), )\n",
    "            #classifier.add(LSTM(100,  return_sequences=True))\n",
    "            \n",
    "\n",
    "            #classifier.add(Dense(units = 1))\n",
    "            classifier.add(LSTM(100,  return_sequences=False))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "            #Adding a second LSTM network layer\n",
    "\n",
    "            #classifier.add(LSTM(128))\n",
    "            #Adding a dense hidden layer\n",
    "            #classifier.add(Dense(64, activation='relu'))\n",
    "            #classifier.add(Dropout(0.2))\n",
    "\n",
    "            #Adding the output layer\n",
    "            #classifier.add(Dense(35, activation='softmax'))\n",
    "\n",
    "            #Compiling the network\n",
    "            classifier.compile( loss='mean_squared_error',\n",
    "                            optimizer=Adam(learning_rate=0.001, decay=1e-6),\n",
    "                             )\n",
    "\n",
    "            #print(classifier.summary())\n",
    "\n",
    "            #Fitting the data to the model\n",
    "            history = classifier.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=5,\n",
    "                        validation_data=(X_test, y_test)\n",
    "                                    )        \n",
    "\n",
    "            val_loss  = classifier.evaluate(X_test, y_test)\n",
    "            error = sqrt(val_loss)\n",
    "            errors.append(error)\n",
    "            plt.plot(history.history['loss'],'red')\n",
    "            plt.plot(history.history['val_loss'], 'blue')\n",
    "            print('------------------------------------------------------------------------------------',x)\n",
    "        average_error = sum(errors)/len(errors)\n",
    "        print(errors)\n",
    "        print(q , \"------------------------ RNN \" , average_error)\n",
    "        all_sequence_result.append(str(m)+\" sequence\" )\n",
    "        all_sequence_result.append(average_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d5e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a49ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65668a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_sequence_result)   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
