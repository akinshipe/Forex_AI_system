{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "37ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fde693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_list = ['USDCHF10080',\n",
    "                 #'GBPUSD10080', 'EURUSD10080', 'USDJPY10080', 'USDCAD10080', 'AUDUSD10080', 'NZDUSD10080',\n",
    "                 #'GBPCHF10080', 'EURCHF10080', 'CHFJPY10080', 'CADCHF10080', 'AUDCHF10080', 'NZDCHF10080', 'EURGBP10080',\n",
    "                 #'GBPJPY10080', 'GBPCAD10080', 'GBPAUD10080', 'EURJPY10080', 'EURCAD10080', 'EURAUD10080', 'EURNZD10080',\n",
    "                #'CADJPY10080', 'AUDJPY10080', 'NZDJPY10080', 'AUDCAD10080', 'NZDCAD10080', 'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "# for q in currency_list:\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     for x in range(5):\n",
    "\n",
    "#         currency = q.replace('10080','')\n",
    "\n",
    "#         data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "#         #data = data.head(695)\n",
    "\n",
    "\n",
    "#         X = data.drop(columns=['Unnamed: 0', \n",
    "#                                'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "#                               ])\n",
    "\n",
    "\n",
    "\n",
    "#         y = data['nextweek_class']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 )\n",
    "\n",
    "\n",
    "\n",
    "#         lnr= LinearRegression()\n",
    "#         lnr.fit(X_train, y_train)\n",
    "#         y_predict = lnr.predict(X_test)\n",
    "        \n",
    "        \n",
    "#         error = sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         errors.append(error)\n",
    "       \n",
    "        \n",
    "#     average_error = sum(errors)/len(errors)\n",
    "       \n",
    "#     print(q + \" Linear regression Average \" + str(average_error))\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1fcc8706",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3495, 3, 27) (3495,)\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_53 (LSTM)               (None, 3, 200)            182400    \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 3, 200)            320800    \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 1)                 808       \n",
      "=================================================================\n",
      "Total params: 504,008\n",
      "Trainable params: 504,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "88/88 [==============================] - 15s 79ms/step - loss: 9.3499 - accuracy: 0.0111 - val_loss: 9.4382 - val_accuracy: 0.0315\n",
      "Epoch 2/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 9.2897 - accuracy: 0.0415 - val_loss: 9.4348 - val_accuracy: 0.0358\n",
      "Epoch 3/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 9.2352 - accuracy: 0.0393 - val_loss: 9.3832 - val_accuracy: 0.0429\n",
      "Epoch 4/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 9.1921 - accuracy: 0.0347 - val_loss: 9.4215 - val_accuracy: 0.0043\n",
      "Epoch 5/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 9.2063 - accuracy: 0.0265 - val_loss: 9.4055 - val_accuracy: 0.0272\n",
      "Epoch 6/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 9.1402 - accuracy: 0.0275 - val_loss: 9.4258 - val_accuracy: 0.0329\n",
      "Epoch 7/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 9.0909 - accuracy: 0.0290 - val_loss: 9.4331 - val_accuracy: 0.0258\n",
      "Epoch 8/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 9.0571 - accuracy: 0.0325 - val_loss: 9.4136 - val_accuracy: 0.0229\n",
      "Epoch 9/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 9.0309 - accuracy: 0.0333 - val_loss: 9.3906 - val_accuracy: 0.0243\n",
      "Epoch 10/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.9891 - accuracy: 0.0318 - val_loss: 9.4476 - val_accuracy: 0.0243\n",
      "Epoch 11/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.9702 - accuracy: 0.0340 - val_loss: 9.4501 - val_accuracy: 0.0258\n",
      "Epoch 12/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.9626 - accuracy: 0.0308 - val_loss: 9.4129 - val_accuracy: 0.0258\n",
      "Epoch 13/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.9225 - accuracy: 0.0358 - val_loss: 9.4342 - val_accuracy: 0.0300\n",
      "Epoch 14/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.9239 - accuracy: 0.0340 - val_loss: 9.3920 - val_accuracy: 0.0172\n",
      "Epoch 15/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.9294 - accuracy: 0.0329 - val_loss: 9.4165 - val_accuracy: 0.0243\n",
      "Epoch 16/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.8780 - accuracy: 0.0340 - val_loss: 9.4155 - val_accuracy: 0.0215\n",
      "Epoch 17/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.8455 - accuracy: 0.0361 - val_loss: 9.4134 - val_accuracy: 0.0172\n",
      "Epoch 18/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.8520 - accuracy: 0.0365 - val_loss: 9.4072 - val_accuracy: 0.0157\n",
      "Epoch 19/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.8299 - accuracy: 0.0351 - val_loss: 9.4405 - val_accuracy: 0.0286\n",
      "Epoch 20/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.7829 - accuracy: 0.0372 - val_loss: 9.4338 - val_accuracy: 0.0200\n",
      "Epoch 21/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.7680 - accuracy: 0.0390 - val_loss: 9.4409 - val_accuracy: 0.0215\n",
      "Epoch 22/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.7782 - accuracy: 0.0383 - val_loss: 9.4701 - val_accuracy: 0.0272\n",
      "Epoch 23/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.7674 - accuracy: 0.0372 - val_loss: 9.4300 - val_accuracy: 0.0286\n",
      "Epoch 24/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.7445 - accuracy: 0.0365 - val_loss: 9.4607 - val_accuracy: 0.0258\n",
      "Epoch 25/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.7504 - accuracy: 0.0383 - val_loss: 9.4818 - val_accuracy: 0.0286\n",
      "Epoch 26/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.7320 - accuracy: 0.0383 - val_loss: 9.4580 - val_accuracy: 0.0229\n",
      "Epoch 27/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.7227 - accuracy: 0.0376 - val_loss: 9.4513 - val_accuracy: 0.0143\n",
      "Epoch 28/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.7320 - accuracy: 0.0368 - val_loss: 9.4322 - val_accuracy: 0.0286\n",
      "Epoch 29/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.7162 - accuracy: 0.0390 - val_loss: 9.4490 - val_accuracy: 0.0200\n",
      "Epoch 30/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.7133 - accuracy: 0.0379 - val_loss: 9.4324 - val_accuracy: 0.0215\n",
      "Epoch 31/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.7013 - accuracy: 0.0386 - val_loss: 9.4577 - val_accuracy: 0.0215\n",
      "Epoch 32/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.6837 - accuracy: 0.0393 - val_loss: 9.4729 - val_accuracy: 0.0215\n",
      "Epoch 33/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.6859 - accuracy: 0.0401 - val_loss: 9.4337 - val_accuracy: 0.0258\n",
      "Epoch 34/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.6808 - accuracy: 0.0393 - val_loss: 9.4890 - val_accuracy: 0.0200\n",
      "Epoch 35/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.6896 - accuracy: 0.0404 - val_loss: 9.4712 - val_accuracy: 0.0186\n",
      "Epoch 36/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.6973 - accuracy: 0.0368 - val_loss: 9.4205 - val_accuracy: 0.0229\n",
      "Epoch 37/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.6874 - accuracy: 0.0379 - val_loss: 9.4571 - val_accuracy: 0.0243\n",
      "Epoch 38/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.6655 - accuracy: 0.0379 - val_loss: 9.4466 - val_accuracy: 0.0286\n",
      "Epoch 39/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.6569 - accuracy: 0.0397 - val_loss: 9.4701 - val_accuracy: 0.0229\n",
      "Epoch 40/500\n",
      "88/88 [==============================] - 6s 69ms/step - loss: 8.6386 - accuracy: 0.0418 - val_loss: 9.4269 - val_accuracy: 0.0286\n",
      "Epoch 41/500\n",
      "88/88 [==============================] - 6s 69ms/step - loss: 8.6171 - accuracy: 0.0415 - val_loss: 9.4341 - val_accuracy: 0.0243\n",
      "Epoch 42/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.6327 - accuracy: 0.0408 - val_loss: 9.4356 - val_accuracy: 0.0243\n",
      "Epoch 43/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.6246 - accuracy: 0.0408 - val_loss: 9.4762 - val_accuracy: 0.0229\n",
      "Epoch 44/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.6426 - accuracy: 0.0397 - val_loss: 9.4819 - val_accuracy: 0.0200\n",
      "Epoch 45/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.6431 - accuracy: 0.0393 - val_loss: 9.4599 - val_accuracy: 0.0243\n",
      "Epoch 46/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.6327 - accuracy: 0.0408 - val_loss: 9.4337 - val_accuracy: 0.0272\n",
      "Epoch 47/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.6392 - accuracy: 0.0397 - val_loss: 9.4692 - val_accuracy: 0.0243\n",
      "Epoch 48/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.6523 - accuracy: 0.0401 - val_loss: 9.4609 - val_accuracy: 0.0186\n",
      "Epoch 49/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.6478 - accuracy: 0.0408 - val_loss: 9.4461 - val_accuracy: 0.0215\n",
      "Epoch 50/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.6256 - accuracy: 0.0401 - val_loss: 9.4676 - val_accuracy: 0.0258\n",
      "Epoch 51/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.6156 - accuracy: 0.0426 - val_loss: 9.4778 - val_accuracy: 0.0258\n",
      "Epoch 52/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.6333 - accuracy: 0.0418 - val_loss: 9.4947 - val_accuracy: 0.0286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.6066 - accuracy: 0.0415 - val_loss: 9.4466 - val_accuracy: 0.0258\n",
      "Epoch 54/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5830 - accuracy: 0.0429 - val_loss: 9.4772 - val_accuracy: 0.0315\n",
      "Epoch 55/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5847 - accuracy: 0.0422 - val_loss: 9.4738 - val_accuracy: 0.0258\n",
      "Epoch 56/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5880 - accuracy: 0.0404 - val_loss: 9.4739 - val_accuracy: 0.0243\n",
      "Epoch 57/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5546 - accuracy: 0.0418 - val_loss: 9.4506 - val_accuracy: 0.0258\n",
      "Epoch 58/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5727 - accuracy: 0.0415 - val_loss: 9.4788 - val_accuracy: 0.0200\n",
      "Epoch 59/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5804 - accuracy: 0.0411 - val_loss: 9.4665 - val_accuracy: 0.0258\n",
      "Epoch 60/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5794 - accuracy: 0.0415 - val_loss: 9.4510 - val_accuracy: 0.0315\n",
      "Epoch 61/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.6226 - accuracy: 0.0404 - val_loss: 9.4520 - val_accuracy: 0.0300\n",
      "Epoch 62/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.6015 - accuracy: 0.0411 - val_loss: 9.4716 - val_accuracy: 0.0243\n",
      "Epoch 63/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.6085 - accuracy: 0.0408 - val_loss: 9.4651 - val_accuracy: 0.0286\n",
      "Epoch 64/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5827 - accuracy: 0.0415 - val_loss: 9.4663 - val_accuracy: 0.0229\n",
      "Epoch 65/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5653 - accuracy: 0.0436 - val_loss: 9.5039 - val_accuracy: 0.0229\n",
      "Epoch 66/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5892 - accuracy: 0.0443 - val_loss: 9.4897 - val_accuracy: 0.0200\n",
      "Epoch 67/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5781 - accuracy: 0.0415 - val_loss: 9.4894 - val_accuracy: 0.0300\n",
      "Epoch 68/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5801 - accuracy: 0.0415 - val_loss: 9.4721 - val_accuracy: 0.0329\n",
      "Epoch 69/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5571 - accuracy: 0.0436 - val_loss: 9.4979 - val_accuracy: 0.0243\n",
      "Epoch 70/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5403 - accuracy: 0.0436 - val_loss: 9.4722 - val_accuracy: 0.0272\n",
      "Epoch 71/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5493 - accuracy: 0.0433 - val_loss: 9.4785 - val_accuracy: 0.0272\n",
      "Epoch 72/500\n",
      "88/88 [==============================] - 5s 63ms/step - loss: 8.5400 - accuracy: 0.0426 - val_loss: 9.5005 - val_accuracy: 0.0258\n",
      "Epoch 73/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.5732 - accuracy: 0.0415 - val_loss: 9.4566 - val_accuracy: 0.0300\n",
      "Epoch 74/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5579 - accuracy: 0.0436 - val_loss: 9.4743 - val_accuracy: 0.0272\n",
      "Epoch 75/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5695 - accuracy: 0.0443 - val_loss: 9.4464 - val_accuracy: 0.0300\n",
      "Epoch 76/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5596 - accuracy: 0.0429 - val_loss: 9.4642 - val_accuracy: 0.0300\n",
      "Epoch 77/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5576 - accuracy: 0.0447 - val_loss: 9.4246 - val_accuracy: 0.0315\n",
      "Epoch 78/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.5736 - accuracy: 0.0436 - val_loss: 9.4624 - val_accuracy: 0.0272\n",
      "Epoch 79/500\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 8.5974 - accuracy: 0.0404 - val_loss: 9.4600 - val_accuracy: 0.0272\n",
      "Epoch 80/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.5792 - accuracy: 0.0418 - val_loss: 9.4872 - val_accuracy: 0.0286\n",
      "Epoch 81/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5651 - accuracy: 0.0433 - val_loss: 9.4593 - val_accuracy: 0.0300\n",
      "Epoch 82/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5525 - accuracy: 0.0418 - val_loss: 9.4570 - val_accuracy: 0.0286\n",
      "Epoch 83/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5501 - accuracy: 0.0429 - val_loss: 9.4611 - val_accuracy: 0.0243\n",
      "Epoch 84/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5658 - accuracy: 0.0418 - val_loss: 9.4877 - val_accuracy: 0.0243\n",
      "Epoch 85/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5495 - accuracy: 0.0433 - val_loss: 9.4827 - val_accuracy: 0.0243\n",
      "Epoch 86/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5532 - accuracy: 0.0433 - val_loss: 9.4478 - val_accuracy: 0.0258\n",
      "Epoch 87/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5511 - accuracy: 0.0447 - val_loss: 9.4313 - val_accuracy: 0.0258\n",
      "Epoch 88/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5461 - accuracy: 0.0443 - val_loss: 9.4185 - val_accuracy: 0.0243\n",
      "Epoch 89/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5546 - accuracy: 0.0436 - val_loss: 9.4353 - val_accuracy: 0.0272\n",
      "Epoch 90/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5473 - accuracy: 0.0440 - val_loss: 9.4261 - val_accuracy: 0.0300\n",
      "Epoch 91/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5278 - accuracy: 0.0426 - val_loss: 9.4292 - val_accuracy: 0.0258\n",
      "Epoch 92/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5357 - accuracy: 0.0429 - val_loss: 9.4410 - val_accuracy: 0.0229\n",
      "Epoch 93/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5347 - accuracy: 0.0429 - val_loss: 9.4338 - val_accuracy: 0.0286\n",
      "Epoch 94/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5532 - accuracy: 0.0408 - val_loss: 9.4484 - val_accuracy: 0.0215\n",
      "Epoch 95/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.5611 - accuracy: 0.0418 - val_loss: 9.4600 - val_accuracy: 0.0286\n",
      "Epoch 96/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5483 - accuracy: 0.0415 - val_loss: 9.4715 - val_accuracy: 0.0258\n",
      "Epoch 97/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5451 - accuracy: 0.0429 - val_loss: 9.4329 - val_accuracy: 0.0243\n",
      "Epoch 98/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.5203 - accuracy: 0.0433 - val_loss: 9.4328 - val_accuracy: 0.0229\n",
      "Epoch 99/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5133 - accuracy: 0.0436 - val_loss: 9.4233 - val_accuracy: 0.0243\n",
      "Epoch 100/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5254 - accuracy: 0.0436 - val_loss: 9.3957 - val_accuracy: 0.0258\n",
      "Epoch 101/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.5013 - accuracy: 0.0451 - val_loss: 9.4435 - val_accuracy: 0.0215\n",
      "Epoch 102/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4876 - accuracy: 0.0443 - val_loss: 9.4325 - val_accuracy: 0.0229\n",
      "Epoch 103/500\n",
      "88/88 [==============================] - 6s 70ms/step - loss: 8.4734 - accuracy: 0.0443 - val_loss: 9.4604 - val_accuracy: 0.0243\n",
      "Epoch 104/500\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 8.4650 - accuracy: 0.0451 - val_loss: 9.4539 - val_accuracy: 0.0215\n",
      "Epoch 105/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4676 - accuracy: 0.0451 - val_loss: 9.4601 - val_accuracy: 0.0258\n",
      "Epoch 106/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4714 - accuracy: 0.0443 - val_loss: 9.4713 - val_accuracy: 0.0272\n",
      "Epoch 107/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4931 - accuracy: 0.0440 - val_loss: 9.4711 - val_accuracy: 0.0172\n",
      "Epoch 108/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4961 - accuracy: 0.0443 - val_loss: 9.4611 - val_accuracy: 0.0272\n",
      "Epoch 109/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4908 - accuracy: 0.0443 - val_loss: 9.4772 - val_accuracy: 0.0229\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4957 - accuracy: 0.0443 - val_loss: 9.4560 - val_accuracy: 0.0272\n",
      "Epoch 111/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4971 - accuracy: 0.0443 - val_loss: 9.4478 - val_accuracy: 0.0258\n",
      "Epoch 112/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5557 - accuracy: 0.0429 - val_loss: 9.4734 - val_accuracy: 0.0258\n",
      "Epoch 113/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5292 - accuracy: 0.0433 - val_loss: 9.4531 - val_accuracy: 0.0200\n",
      "Epoch 114/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5217 - accuracy: 0.0447 - val_loss: 9.4460 - val_accuracy: 0.0272\n",
      "Epoch 115/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5116 - accuracy: 0.0447 - val_loss: 9.4477 - val_accuracy: 0.0272\n",
      "Epoch 116/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5136 - accuracy: 0.0426 - val_loss: 9.4530 - val_accuracy: 0.0258\n",
      "Epoch 117/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5126 - accuracy: 0.0433 - val_loss: 9.4470 - val_accuracy: 0.0258\n",
      "Epoch 118/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5318 - accuracy: 0.0436 - val_loss: 9.4635 - val_accuracy: 0.0243\n",
      "Epoch 119/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5193 - accuracy: 0.0436 - val_loss: 9.4414 - val_accuracy: 0.0229\n",
      "Epoch 120/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5114 - accuracy: 0.0443 - val_loss: 9.4420 - val_accuracy: 0.0229\n",
      "Epoch 121/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5204 - accuracy: 0.0433 - val_loss: 9.4097 - val_accuracy: 0.0272\n",
      "Epoch 122/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5092 - accuracy: 0.0433 - val_loss: 9.4517 - val_accuracy: 0.0258\n",
      "Epoch 123/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.5170 - accuracy: 0.0443 - val_loss: 9.4268 - val_accuracy: 0.0258\n",
      "Epoch 124/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5099 - accuracy: 0.0436 - val_loss: 9.4224 - val_accuracy: 0.0229\n",
      "Epoch 125/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5119 - accuracy: 0.0447 - val_loss: 9.4270 - val_accuracy: 0.0243\n",
      "Epoch 126/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5278 - accuracy: 0.0433 - val_loss: 9.4583 - val_accuracy: 0.0229\n",
      "Epoch 127/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5165 - accuracy: 0.0440 - val_loss: 9.4109 - val_accuracy: 0.0243\n",
      "Epoch 128/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5156 - accuracy: 0.0433 - val_loss: 9.3957 - val_accuracy: 0.0215\n",
      "Epoch 129/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5021 - accuracy: 0.0443 - val_loss: 9.4272 - val_accuracy: 0.0186\n",
      "Epoch 130/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4844 - accuracy: 0.0447 - val_loss: 9.4113 - val_accuracy: 0.0229\n",
      "Epoch 131/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4907 - accuracy: 0.0451 - val_loss: 9.3853 - val_accuracy: 0.0258\n",
      "Epoch 132/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4896 - accuracy: 0.0454 - val_loss: 9.4290 - val_accuracy: 0.0200\n",
      "Epoch 133/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4861 - accuracy: 0.0458 - val_loss: 9.4224 - val_accuracy: 0.0215\n",
      "Epoch 134/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4964 - accuracy: 0.0440 - val_loss: 9.4058 - val_accuracy: 0.0229\n",
      "Epoch 135/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4915 - accuracy: 0.0440 - val_loss: 9.4012 - val_accuracy: 0.0258\n",
      "Epoch 136/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4847 - accuracy: 0.0451 - val_loss: 9.4181 - val_accuracy: 0.0215\n",
      "Epoch 137/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4807 - accuracy: 0.0451 - val_loss: 9.4222 - val_accuracy: 0.0200\n",
      "Epoch 138/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4843 - accuracy: 0.0426 - val_loss: 9.4340 - val_accuracy: 0.0200\n",
      "Epoch 139/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4752 - accuracy: 0.0443 - val_loss: 9.4275 - val_accuracy: 0.0215\n",
      "Epoch 140/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4791 - accuracy: 0.0443 - val_loss: 9.4319 - val_accuracy: 0.0243\n",
      "Epoch 141/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4865 - accuracy: 0.0454 - val_loss: 9.4386 - val_accuracy: 0.0243\n",
      "Epoch 142/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4810 - accuracy: 0.0451 - val_loss: 9.4187 - val_accuracy: 0.0229\n",
      "Epoch 143/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4660 - accuracy: 0.0458 - val_loss: 9.4357 - val_accuracy: 0.0229\n",
      "Epoch 144/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4668 - accuracy: 0.0454 - val_loss: 9.4389 - val_accuracy: 0.0215\n",
      "Epoch 145/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4709 - accuracy: 0.0451 - val_loss: 9.4364 - val_accuracy: 0.0215\n",
      "Epoch 146/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4766 - accuracy: 0.0447 - val_loss: 9.4303 - val_accuracy: 0.0186\n",
      "Epoch 147/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4771 - accuracy: 0.0451 - val_loss: 9.4521 - val_accuracy: 0.0200\n",
      "Epoch 148/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4570 - accuracy: 0.0454 - val_loss: 9.4515 - val_accuracy: 0.0272\n",
      "Epoch 149/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4685 - accuracy: 0.0454 - val_loss: 9.4452 - val_accuracy: 0.0258\n",
      "Epoch 150/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4712 - accuracy: 0.0443 - val_loss: 9.4567 - val_accuracy: 0.0258\n",
      "Epoch 151/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4769 - accuracy: 0.0440 - val_loss: 9.4536 - val_accuracy: 0.0286\n",
      "Epoch 152/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4715 - accuracy: 0.0451 - val_loss: 9.4189 - val_accuracy: 0.0286\n",
      "Epoch 153/500\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 8.4830 - accuracy: 0.0426 - val_loss: 9.4601 - val_accuracy: 0.0272\n",
      "Epoch 154/500\n",
      "88/88 [==============================] - 6s 70ms/step - loss: 8.4751 - accuracy: 0.0436 - val_loss: 9.4577 - val_accuracy: 0.0215\n",
      "Epoch 155/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4707 - accuracy: 0.0454 - val_loss: 9.4259 - val_accuracy: 0.0300\n",
      "Epoch 156/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4697 - accuracy: 0.0454 - val_loss: 9.4405 - val_accuracy: 0.0258\n",
      "Epoch 157/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4611 - accuracy: 0.0451 - val_loss: 9.4653 - val_accuracy: 0.0229\n",
      "Epoch 158/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4467 - accuracy: 0.0458 - val_loss: 9.4364 - val_accuracy: 0.0215\n",
      "Epoch 159/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4519 - accuracy: 0.0454 - val_loss: 9.4309 - val_accuracy: 0.0272\n",
      "Epoch 160/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4510 - accuracy: 0.0458 - val_loss: 9.4624 - val_accuracy: 0.0272\n",
      "Epoch 161/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4503 - accuracy: 0.0458 - val_loss: 9.4846 - val_accuracy: 0.0229\n",
      "Epoch 162/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4527 - accuracy: 0.0454 - val_loss: 9.4639 - val_accuracy: 0.0258\n",
      "Epoch 163/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4683 - accuracy: 0.0443 - val_loss: 9.4618 - val_accuracy: 0.0215\n",
      "Epoch 164/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4623 - accuracy: 0.0451 - val_loss: 9.4603 - val_accuracy: 0.0258\n",
      "Epoch 165/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4729 - accuracy: 0.0443 - val_loss: 9.4842 - val_accuracy: 0.0200\n",
      "Epoch 166/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4936 - accuracy: 0.0443 - val_loss: 9.4650 - val_accuracy: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/500\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 8.4890 - accuracy: 0.0458 - val_loss: 9.4728 - val_accuracy: 0.0186\n",
      "Epoch 168/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4801 - accuracy: 0.0454 - val_loss: 9.4438 - val_accuracy: 0.0243\n",
      "Epoch 169/500\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 8.4910 - accuracy: 0.0447 - val_loss: 9.4332 - val_accuracy: 0.0286\n",
      "Epoch 170/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4924 - accuracy: 0.0461 - val_loss: 9.4448 - val_accuracy: 0.0272\n",
      "Epoch 171/500\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 8.4947 - accuracy: 0.0447 - val_loss: 9.4547 - val_accuracy: 0.0215\n",
      "Epoch 172/500\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 8.4811 - accuracy: 0.0443 - val_loss: 9.4516 - val_accuracy: 0.0229\n",
      "Epoch 173/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4708 - accuracy: 0.0440 - val_loss: 9.4227 - val_accuracy: 0.0186\n",
      "Epoch 174/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4747 - accuracy: 0.0443 - val_loss: 9.4426 - val_accuracy: 0.0229\n",
      "Epoch 175/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4751 - accuracy: 0.0451 - val_loss: 9.4374 - val_accuracy: 0.0286\n",
      "Epoch 176/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4816 - accuracy: 0.0440 - val_loss: 9.4361 - val_accuracy: 0.0258\n",
      "Epoch 177/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4878 - accuracy: 0.0447 - val_loss: 9.4386 - val_accuracy: 0.0258\n",
      "Epoch 178/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4588 - accuracy: 0.0461 - val_loss: 9.4729 - val_accuracy: 0.0243\n",
      "Epoch 179/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4601 - accuracy: 0.0461 - val_loss: 9.4705 - val_accuracy: 0.0243\n",
      "Epoch 180/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4682 - accuracy: 0.0451 - val_loss: 9.4366 - val_accuracy: 0.0215\n",
      "Epoch 181/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4841 - accuracy: 0.0447 - val_loss: 9.4215 - val_accuracy: 0.0200\n",
      "Epoch 182/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4625 - accuracy: 0.0447 - val_loss: 9.4280 - val_accuracy: 0.0215\n",
      "Epoch 183/500\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 8.4519 - accuracy: 0.0454 - val_loss: 9.4260 - val_accuracy: 0.0258\n",
      "Epoch 184/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4449 - accuracy: 0.0458 - val_loss: 9.4145 - val_accuracy: 0.0243\n",
      "Epoch 185/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4370 - accuracy: 0.0461 - val_loss: 9.4234 - val_accuracy: 0.0258\n",
      "Epoch 186/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4394 - accuracy: 0.0461 - val_loss: 9.4385 - val_accuracy: 0.0258\n",
      "Epoch 187/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4545 - accuracy: 0.0451 - val_loss: 9.4262 - val_accuracy: 0.0258\n",
      "Epoch 188/500\n",
      "88/88 [==============================] - 5s 63ms/step - loss: 8.4574 - accuracy: 0.0454 - val_loss: 9.4337 - val_accuracy: 0.0258\n",
      "Epoch 189/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4597 - accuracy: 0.0454 - val_loss: 9.4053 - val_accuracy: 0.0272\n",
      "Epoch 190/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4649 - accuracy: 0.0447 - val_loss: 9.3976 - val_accuracy: 0.0272\n",
      "Epoch 191/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4635 - accuracy: 0.0447 - val_loss: 9.3987 - val_accuracy: 0.0272\n",
      "Epoch 192/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4495 - accuracy: 0.0454 - val_loss: 9.3941 - val_accuracy: 0.0272\n",
      "Epoch 193/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4543 - accuracy: 0.0458 - val_loss: 9.3858 - val_accuracy: 0.0272\n",
      "Epoch 194/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4471 - accuracy: 0.0461 - val_loss: 9.4070 - val_accuracy: 0.0243\n",
      "Epoch 195/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4567 - accuracy: 0.0465 - val_loss: 9.3888 - val_accuracy: 0.0229\n",
      "Epoch 196/500\n",
      "88/88 [==============================] - 5s 63ms/step - loss: 8.4483 - accuracy: 0.0454 - val_loss: 9.4050 - val_accuracy: 0.0215\n",
      "Epoch 197/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4461 - accuracy: 0.0465 - val_loss: 9.4033 - val_accuracy: 0.0243\n",
      "Epoch 198/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4481 - accuracy: 0.0458 - val_loss: 9.3627 - val_accuracy: 0.0200\n",
      "Epoch 199/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4525 - accuracy: 0.0454 - val_loss: 9.4095 - val_accuracy: 0.0300\n",
      "Epoch 200/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4536 - accuracy: 0.0461 - val_loss: 9.4182 - val_accuracy: 0.0286\n",
      "Epoch 201/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4541 - accuracy: 0.0454 - val_loss: 9.4175 - val_accuracy: 0.0315\n",
      "Epoch 202/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4471 - accuracy: 0.0461 - val_loss: 9.4259 - val_accuracy: 0.0286\n",
      "Epoch 203/500\n",
      "88/88 [==============================] - 7s 77ms/step - loss: 8.4520 - accuracy: 0.0461 - val_loss: 9.4316 - val_accuracy: 0.0243\n",
      "Epoch 204/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4663 - accuracy: 0.0451 - val_loss: 9.4094 - val_accuracy: 0.0272\n",
      "Epoch 205/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4732 - accuracy: 0.0451 - val_loss: 9.4138 - val_accuracy: 0.0272\n",
      "Epoch 206/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4618 - accuracy: 0.0465 - val_loss: 9.4154 - val_accuracy: 0.0315\n",
      "Epoch 207/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4476 - accuracy: 0.0469 - val_loss: 9.4288 - val_accuracy: 0.0286\n",
      "Epoch 208/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4482 - accuracy: 0.0469 - val_loss: 9.4423 - val_accuracy: 0.0272\n",
      "Epoch 209/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4479 - accuracy: 0.0465 - val_loss: 9.4287 - val_accuracy: 0.0300\n",
      "Epoch 210/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4497 - accuracy: 0.0461 - val_loss: 9.4694 - val_accuracy: 0.0272\n",
      "Epoch 211/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4470 - accuracy: 0.0458 - val_loss: 9.4661 - val_accuracy: 0.0272\n",
      "Epoch 212/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4517 - accuracy: 0.0469 - val_loss: 9.4656 - val_accuracy: 0.0258\n",
      "Epoch 213/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4435 - accuracy: 0.0465 - val_loss: 9.4714 - val_accuracy: 0.0215\n",
      "Epoch 214/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4482 - accuracy: 0.0458 - val_loss: 9.4737 - val_accuracy: 0.0215\n",
      "Epoch 215/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4506 - accuracy: 0.0454 - val_loss: 9.4480 - val_accuracy: 0.0229\n",
      "Epoch 216/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4408 - accuracy: 0.0458 - val_loss: 9.4223 - val_accuracy: 0.0243\n",
      "Epoch 217/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4369 - accuracy: 0.0465 - val_loss: 9.4330 - val_accuracy: 0.0258\n",
      "Epoch 218/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4386 - accuracy: 0.0465 - val_loss: 9.4459 - val_accuracy: 0.0229\n",
      "Epoch 219/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4422 - accuracy: 0.0465 - val_loss: 9.4363 - val_accuracy: 0.0215\n",
      "Epoch 220/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4402 - accuracy: 0.0469 - val_loss: 9.4298 - val_accuracy: 0.0286\n",
      "Epoch 221/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4319 - accuracy: 0.0469 - val_loss: 9.4070 - val_accuracy: 0.0258\n",
      "Epoch 222/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4286 - accuracy: 0.0469 - val_loss: 9.4125 - val_accuracy: 0.0272\n",
      "Epoch 223/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4258 - accuracy: 0.0469 - val_loss: 9.4073 - val_accuracy: 0.0272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 8.4283 - accuracy: 0.0465 - val_loss: 9.3863 - val_accuracy: 0.0300\n",
      "Epoch 225/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4256 - accuracy: 0.0469 - val_loss: 9.3897 - val_accuracy: 0.0272\n",
      "Epoch 226/500\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 8.4270 - accuracy: 0.0465 - val_loss: 9.4138 - val_accuracy: 0.0300\n",
      "Epoch 227/500\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 8.4270 - accuracy: 0.0465 - val_loss: 9.4050 - val_accuracy: 0.0286\n",
      "Epoch 228/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4333 - accuracy: 0.0465 - val_loss: 9.4170 - val_accuracy: 0.0258\n",
      "Epoch 229/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4459 - accuracy: 0.0461 - val_loss: 9.4378 - val_accuracy: 0.0186\n",
      "Epoch 230/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4699 - accuracy: 0.0447 - val_loss: 9.4735 - val_accuracy: 0.0258\n",
      "Epoch 231/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4633 - accuracy: 0.0454 - val_loss: 9.4391 - val_accuracy: 0.0286\n",
      "Epoch 232/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4754 - accuracy: 0.0440 - val_loss: 9.4398 - val_accuracy: 0.0272\n",
      "Epoch 233/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4810 - accuracy: 0.0454 - val_loss: 9.4517 - val_accuracy: 0.0229\n",
      "Epoch 234/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4717 - accuracy: 0.0458 - val_loss: 9.4484 - val_accuracy: 0.0258\n",
      "Epoch 235/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4822 - accuracy: 0.0461 - val_loss: 9.4201 - val_accuracy: 0.0272\n",
      "Epoch 236/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4941 - accuracy: 0.0451 - val_loss: 9.4425 - val_accuracy: 0.0243\n",
      "Epoch 237/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4971 - accuracy: 0.0451 - val_loss: 9.4336 - val_accuracy: 0.0229\n",
      "Epoch 238/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4739 - accuracy: 0.0461 - val_loss: 9.4454 - val_accuracy: 0.0229\n",
      "Epoch 239/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4744 - accuracy: 0.0458 - val_loss: 9.4287 - val_accuracy: 0.0200\n",
      "Epoch 240/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4641 - accuracy: 0.0465 - val_loss: 9.4377 - val_accuracy: 0.0200\n",
      "Epoch 241/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4585 - accuracy: 0.0454 - val_loss: 9.4397 - val_accuracy: 0.0243\n",
      "Epoch 242/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4530 - accuracy: 0.0461 - val_loss: 9.4523 - val_accuracy: 0.0200\n",
      "Epoch 243/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4444 - accuracy: 0.0461 - val_loss: 9.4682 - val_accuracy: 0.0258\n",
      "Epoch 244/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4457 - accuracy: 0.0458 - val_loss: 9.4591 - val_accuracy: 0.0243\n",
      "Epoch 245/500\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 8.4479 - accuracy: 0.0458 - val_loss: 9.4424 - val_accuracy: 0.0272\n",
      "Epoch 246/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4374 - accuracy: 0.0461 - val_loss: 9.4352 - val_accuracy: 0.0215\n",
      "Epoch 247/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4343 - accuracy: 0.0458 - val_loss: 9.4155 - val_accuracy: 0.0258\n",
      "Epoch 248/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4352 - accuracy: 0.0458 - val_loss: 9.4676 - val_accuracy: 0.0229\n",
      "Epoch 249/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4510 - accuracy: 0.0461 - val_loss: 9.4314 - val_accuracy: 0.0258\n",
      "Epoch 250/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4484 - accuracy: 0.0451 - val_loss: 9.4413 - val_accuracy: 0.0272\n",
      "Epoch 251/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4379 - accuracy: 0.0454 - val_loss: 9.4527 - val_accuracy: 0.0215\n",
      "Epoch 252/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4320 - accuracy: 0.0458 - val_loss: 9.4537 - val_accuracy: 0.0272\n",
      "Epoch 253/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4407 - accuracy: 0.0454 - val_loss: 9.4372 - val_accuracy: 0.0258\n",
      "Epoch 254/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4349 - accuracy: 0.0461 - val_loss: 9.4333 - val_accuracy: 0.0229\n",
      "Epoch 255/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4272 - accuracy: 0.0461 - val_loss: 9.4706 - val_accuracy: 0.0229\n",
      "Epoch 256/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4353 - accuracy: 0.0461 - val_loss: 9.4561 - val_accuracy: 0.0215\n",
      "Epoch 257/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4333 - accuracy: 0.0458 - val_loss: 9.4632 - val_accuracy: 0.0215\n",
      "Epoch 258/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4248 - accuracy: 0.0458 - val_loss: 9.4724 - val_accuracy: 0.0215\n",
      "Epoch 259/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4223 - accuracy: 0.0461 - val_loss: 9.4633 - val_accuracy: 0.0243\n",
      "Epoch 260/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4183 - accuracy: 0.0461 - val_loss: 9.4688 - val_accuracy: 0.0243\n",
      "Epoch 261/500\n",
      "88/88 [==============================] - 6s 62ms/step - loss: 8.4171 - accuracy: 0.0461 - val_loss: 9.4675 - val_accuracy: 0.0243\n",
      "Epoch 262/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4169 - accuracy: 0.0461 - val_loss: 9.4671 - val_accuracy: 0.0243\n",
      "Epoch 263/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4160 - accuracy: 0.0461 - val_loss: 9.4670 - val_accuracy: 0.0243\n",
      "Epoch 264/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4158 - accuracy: 0.0461 - val_loss: 9.4670 - val_accuracy: 0.0243\n",
      "Epoch 265/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4150 - accuracy: 0.0461 - val_loss: 9.4620 - val_accuracy: 0.0243\n",
      "Epoch 266/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4141 - accuracy: 0.0461 - val_loss: 9.4690 - val_accuracy: 0.0243\n",
      "Epoch 267/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4163 - accuracy: 0.0461 - val_loss: 9.4543 - val_accuracy: 0.0186\n",
      "Epoch 268/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4225 - accuracy: 0.0458 - val_loss: 9.4855 - val_accuracy: 0.0200\n",
      "Epoch 269/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4256 - accuracy: 0.0465 - val_loss: 9.4536 - val_accuracy: 0.0272\n",
      "Epoch 270/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4343 - accuracy: 0.0465 - val_loss: 9.4604 - val_accuracy: 0.0258\n",
      "Epoch 271/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4519 - accuracy: 0.0465 - val_loss: 9.4806 - val_accuracy: 0.0258\n",
      "Epoch 272/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4588 - accuracy: 0.0465 - val_loss: 9.4352 - val_accuracy: 0.0315\n",
      "Epoch 273/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4573 - accuracy: 0.0458 - val_loss: 9.3979 - val_accuracy: 0.0329\n",
      "Epoch 274/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4556 - accuracy: 0.0458 - val_loss: 9.4027 - val_accuracy: 0.0272\n",
      "Epoch 275/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4697 - accuracy: 0.0447 - val_loss: 9.4013 - val_accuracy: 0.0243\n",
      "Epoch 276/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4746 - accuracy: 0.0447 - val_loss: 9.4326 - val_accuracy: 0.0215\n",
      "Epoch 277/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4603 - accuracy: 0.0443 - val_loss: 9.4249 - val_accuracy: 0.0229\n",
      "Epoch 278/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4757 - accuracy: 0.0451 - val_loss: 9.4491 - val_accuracy: 0.0286\n",
      "Epoch 279/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4670 - accuracy: 0.0454 - val_loss: 9.4380 - val_accuracy: 0.0243\n",
      "Epoch 280/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4729 - accuracy: 0.0451 - val_loss: 9.4403 - val_accuracy: 0.0229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 8.4559 - accuracy: 0.0458 - val_loss: 9.4459 - val_accuracy: 0.0272\n",
      "Epoch 282/500\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 8.4542 - accuracy: 0.0461 - val_loss: 9.4134 - val_accuracy: 0.0200\n",
      "Epoch 283/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4451 - accuracy: 0.0465 - val_loss: 9.4302 - val_accuracy: 0.0243\n",
      "Epoch 284/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4336 - accuracy: 0.0465 - val_loss: 9.4286 - val_accuracy: 0.0200\n",
      "Epoch 285/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4297 - accuracy: 0.0461 - val_loss: 9.4451 - val_accuracy: 0.0186\n",
      "Epoch 286/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4224 - accuracy: 0.0465 - val_loss: 9.4418 - val_accuracy: 0.0243\n",
      "Epoch 287/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4281 - accuracy: 0.0465 - val_loss: 9.4435 - val_accuracy: 0.0229\n",
      "Epoch 288/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4301 - accuracy: 0.0465 - val_loss: 9.4438 - val_accuracy: 0.0229\n",
      "Epoch 289/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4284 - accuracy: 0.0461 - val_loss: 9.4721 - val_accuracy: 0.0200\n",
      "Epoch 290/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4234 - accuracy: 0.0465 - val_loss: 9.4509 - val_accuracy: 0.0200\n",
      "Epoch 291/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4315 - accuracy: 0.0461 - val_loss: 9.4144 - val_accuracy: 0.0243\n",
      "Epoch 292/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4303 - accuracy: 0.0465 - val_loss: 9.4256 - val_accuracy: 0.0229\n",
      "Epoch 293/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4322 - accuracy: 0.0461 - val_loss: 9.4390 - val_accuracy: 0.0229\n",
      "Epoch 294/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4286 - accuracy: 0.0461 - val_loss: 9.4434 - val_accuracy: 0.0243\n",
      "Epoch 295/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4415 - accuracy: 0.0465 - val_loss: 9.4358 - val_accuracy: 0.0315\n",
      "Epoch 296/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4562 - accuracy: 0.0465 - val_loss: 9.4428 - val_accuracy: 0.0272\n",
      "Epoch 297/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4627 - accuracy: 0.0443 - val_loss: 9.4064 - val_accuracy: 0.0272\n",
      "Epoch 298/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4636 - accuracy: 0.0465 - val_loss: 9.4042 - val_accuracy: 0.0286\n",
      "Epoch 299/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4502 - accuracy: 0.0465 - val_loss: 9.4223 - val_accuracy: 0.0286\n",
      "Epoch 300/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4417 - accuracy: 0.0461 - val_loss: 9.4299 - val_accuracy: 0.0300\n",
      "Epoch 301/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4403 - accuracy: 0.0469 - val_loss: 9.4528 - val_accuracy: 0.0258\n",
      "Epoch 302/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4388 - accuracy: 0.0458 - val_loss: 9.4473 - val_accuracy: 0.0215\n",
      "Epoch 303/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4409 - accuracy: 0.0461 - val_loss: 9.4577 - val_accuracy: 0.0215\n",
      "Epoch 304/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4367 - accuracy: 0.0461 - val_loss: 9.4323 - val_accuracy: 0.0258\n",
      "Epoch 305/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4257 - accuracy: 0.0465 - val_loss: 9.4218 - val_accuracy: 0.0258\n",
      "Epoch 306/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4282 - accuracy: 0.0461 - val_loss: 9.4113 - val_accuracy: 0.0300\n",
      "Epoch 307/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4264 - accuracy: 0.0465 - val_loss: 9.4040 - val_accuracy: 0.0229\n",
      "Epoch 308/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4328 - accuracy: 0.0465 - val_loss: 9.4240 - val_accuracy: 0.0243\n",
      "Epoch 309/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4314 - accuracy: 0.0465 - val_loss: 9.4031 - val_accuracy: 0.0215\n",
      "Epoch 310/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4223 - accuracy: 0.0461 - val_loss: 9.4328 - val_accuracy: 0.0229\n",
      "Epoch 311/500\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 8.4263 - accuracy: 0.0465 - val_loss: 9.4173 - val_accuracy: 0.0243\n",
      "Epoch 312/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4249 - accuracy: 0.0461 - val_loss: 9.4131 - val_accuracy: 0.0243\n",
      "Epoch 313/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4199 - accuracy: 0.0465 - val_loss: 9.4195 - val_accuracy: 0.0272\n",
      "Epoch 314/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4331 - accuracy: 0.0458 - val_loss: 9.4508 - val_accuracy: 0.0286\n",
      "Epoch 315/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4263 - accuracy: 0.0465 - val_loss: 9.4554 - val_accuracy: 0.0229\n",
      "Epoch 316/500\n",
      "88/88 [==============================] - 6s 71ms/step - loss: 8.4241 - accuracy: 0.0469 - val_loss: 9.4421 - val_accuracy: 0.0272\n",
      "Epoch 317/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4237 - accuracy: 0.0469 - val_loss: 9.4702 - val_accuracy: 0.0272\n",
      "Epoch 318/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4272 - accuracy: 0.0458 - val_loss: 9.4733 - val_accuracy: 0.0229\n",
      "Epoch 319/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4222 - accuracy: 0.0458 - val_loss: 9.4833 - val_accuracy: 0.0200\n",
      "Epoch 320/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4216 - accuracy: 0.0461 - val_loss: 9.4810 - val_accuracy: 0.0243\n",
      "Epoch 321/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4233 - accuracy: 0.0461 - val_loss: 9.4782 - val_accuracy: 0.0215\n",
      "Epoch 322/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4216 - accuracy: 0.0458 - val_loss: 9.4565 - val_accuracy: 0.0215\n",
      "Epoch 323/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4215 - accuracy: 0.0458 - val_loss: 9.4378 - val_accuracy: 0.0258\n",
      "Epoch 324/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4203 - accuracy: 0.0458 - val_loss: 9.4635 - val_accuracy: 0.0258\n",
      "Epoch 325/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4132 - accuracy: 0.0465 - val_loss: 9.4667 - val_accuracy: 0.0258\n",
      "Epoch 326/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4117 - accuracy: 0.0465 - val_loss: 9.4726 - val_accuracy: 0.0258\n",
      "Epoch 327/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4112 - accuracy: 0.0465 - val_loss: 9.4724 - val_accuracy: 0.0258\n",
      "Epoch 328/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4110 - accuracy: 0.0465 - val_loss: 9.4723 - val_accuracy: 0.0258\n",
      "Epoch 329/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4108 - accuracy: 0.0465 - val_loss: 9.4714 - val_accuracy: 0.0258\n",
      "Epoch 330/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4093 - accuracy: 0.0465 - val_loss: 9.4704 - val_accuracy: 0.0258\n",
      "Epoch 331/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4092 - accuracy: 0.0465 - val_loss: 9.4703 - val_accuracy: 0.0258\n",
      "Epoch 332/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4091 - accuracy: 0.0465 - val_loss: 9.4702 - val_accuracy: 0.0258\n",
      "Epoch 333/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4091 - accuracy: 0.0465 - val_loss: 9.4697 - val_accuracy: 0.0258\n",
      "Epoch 334/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4090 - accuracy: 0.0465 - val_loss: 9.4691 - val_accuracy: 0.0258\n",
      "Epoch 335/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4089 - accuracy: 0.0465 - val_loss: 9.4684 - val_accuracy: 0.0258\n",
      "Epoch 336/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4075 - accuracy: 0.0469 - val_loss: 9.4677 - val_accuracy: 0.0258\n",
      "Epoch 337/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4074 - accuracy: 0.0469 - val_loss: 9.4672 - val_accuracy: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4073 - accuracy: 0.0469 - val_loss: 9.4662 - val_accuracy: 0.0258\n",
      "Epoch 339/500\n",
      "88/88 [==============================] - 7s 79ms/step - loss: 8.4073 - accuracy: 0.0469 - val_loss: 9.4659 - val_accuracy: 0.0258\n",
      "Epoch 340/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4070 - accuracy: 0.0469 - val_loss: 9.4624 - val_accuracy: 0.0258\n",
      "Epoch 341/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4067 - accuracy: 0.0472 - val_loss: 9.4588 - val_accuracy: 0.0258\n",
      "Epoch 342/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4059 - accuracy: 0.0472 - val_loss: 9.4542 - val_accuracy: 0.0258\n",
      "Epoch 343/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4051 - accuracy: 0.0472 - val_loss: 9.4525 - val_accuracy: 0.0243\n",
      "Epoch 344/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4051 - accuracy: 0.0472 - val_loss: 9.4516 - val_accuracy: 0.0243\n",
      "Epoch 345/500\n",
      "88/88 [==============================] - 6s 69ms/step - loss: 8.4051 - accuracy: 0.0472 - val_loss: 9.4506 - val_accuracy: 0.0243\n",
      "Epoch 346/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4050 - accuracy: 0.0472 - val_loss: 9.4498 - val_accuracy: 0.0243\n",
      "Epoch 347/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4048 - accuracy: 0.0472 - val_loss: 9.4520 - val_accuracy: 0.0243\n",
      "Epoch 348/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4046 - accuracy: 0.0472 - val_loss: 9.4583 - val_accuracy: 0.0243\n",
      "Epoch 349/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4058 - accuracy: 0.0472 - val_loss: 9.4575 - val_accuracy: 0.0243\n",
      "Epoch 350/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4236 - accuracy: 0.0469 - val_loss: 9.4458 - val_accuracy: 0.0286\n",
      "Epoch 351/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4789 - accuracy: 0.0461 - val_loss: 9.4681 - val_accuracy: 0.0172\n",
      "Epoch 352/500\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 8.5074 - accuracy: 0.0447 - val_loss: 9.3950 - val_accuracy: 0.0215\n",
      "Epoch 353/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5124 - accuracy: 0.0447 - val_loss: 9.4099 - val_accuracy: 0.0272\n",
      "Epoch 354/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5153 - accuracy: 0.0447 - val_loss: 9.4435 - val_accuracy: 0.0229\n",
      "Epoch 355/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5227 - accuracy: 0.0436 - val_loss: 9.4537 - val_accuracy: 0.0172\n",
      "Epoch 356/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4874 - accuracy: 0.0454 - val_loss: 9.4770 - val_accuracy: 0.0200\n",
      "Epoch 357/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4694 - accuracy: 0.0451 - val_loss: 9.4522 - val_accuracy: 0.0200\n",
      "Epoch 358/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4593 - accuracy: 0.0458 - val_loss: 9.4707 - val_accuracy: 0.0186\n",
      "Epoch 359/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4481 - accuracy: 0.0461 - val_loss: 9.4576 - val_accuracy: 0.0215\n",
      "Epoch 360/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4436 - accuracy: 0.0461 - val_loss: 9.4715 - val_accuracy: 0.0243\n",
      "Epoch 361/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4364 - accuracy: 0.0465 - val_loss: 9.4529 - val_accuracy: 0.0215\n",
      "Epoch 362/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4407 - accuracy: 0.0465 - val_loss: 9.4828 - val_accuracy: 0.0215\n",
      "Epoch 363/500\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 8.4337 - accuracy: 0.0465 - val_loss: 9.4716 - val_accuracy: 0.0215\n",
      "Epoch 364/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4353 - accuracy: 0.0458 - val_loss: 9.4725 - val_accuracy: 0.0186\n",
      "Epoch 365/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4311 - accuracy: 0.0465 - val_loss: 9.4563 - val_accuracy: 0.0186\n",
      "Epoch 366/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4245 - accuracy: 0.0465 - val_loss: 9.4279 - val_accuracy: 0.0215\n",
      "Epoch 367/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4197 - accuracy: 0.0465 - val_loss: 9.4422 - val_accuracy: 0.0215\n",
      "Epoch 368/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4194 - accuracy: 0.0465 - val_loss: 9.4551 - val_accuracy: 0.0200\n",
      "Epoch 369/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4208 - accuracy: 0.0461 - val_loss: 9.4618 - val_accuracy: 0.0229\n",
      "Epoch 370/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4172 - accuracy: 0.0465 - val_loss: 9.4510 - val_accuracy: 0.0186\n",
      "Epoch 371/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4124 - accuracy: 0.0469 - val_loss: 9.4542 - val_accuracy: 0.0186\n",
      "Epoch 372/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4127 - accuracy: 0.0469 - val_loss: 9.4466 - val_accuracy: 0.0200\n",
      "Epoch 373/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4148 - accuracy: 0.0465 - val_loss: 9.4207 - val_accuracy: 0.0229\n",
      "Epoch 374/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4125 - accuracy: 0.0465 - val_loss: 9.4209 - val_accuracy: 0.0200\n",
      "Epoch 375/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4117 - accuracy: 0.0465 - val_loss: 9.4240 - val_accuracy: 0.0200\n",
      "Epoch 376/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4111 - accuracy: 0.0458 - val_loss: 9.4301 - val_accuracy: 0.0243\n",
      "Epoch 377/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4091 - accuracy: 0.0465 - val_loss: 9.4238 - val_accuracy: 0.0229\n",
      "Epoch 378/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4083 - accuracy: 0.0465 - val_loss: 9.4240 - val_accuracy: 0.0229\n",
      "Epoch 379/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4081 - accuracy: 0.0465 - val_loss: 9.4244 - val_accuracy: 0.0229\n",
      "Epoch 380/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4079 - accuracy: 0.0465 - val_loss: 9.4239 - val_accuracy: 0.0229\n",
      "Epoch 381/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4078 - accuracy: 0.0465 - val_loss: 9.4246 - val_accuracy: 0.0229\n",
      "Epoch 382/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4080 - accuracy: 0.0465 - val_loss: 9.4224 - val_accuracy: 0.0229\n",
      "Epoch 383/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4138 - accuracy: 0.0461 - val_loss: 9.4326 - val_accuracy: 0.0215\n",
      "Epoch 384/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4170 - accuracy: 0.0458 - val_loss: 9.4282 - val_accuracy: 0.0215\n",
      "Epoch 385/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4280 - accuracy: 0.0461 - val_loss: 9.4286 - val_accuracy: 0.0243\n",
      "Epoch 386/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.4271 - accuracy: 0.0461 - val_loss: 9.4695 - val_accuracy: 0.0172\n",
      "Epoch 387/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4376 - accuracy: 0.0461 - val_loss: 9.4367 - val_accuracy: 0.0229\n",
      "Epoch 388/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4420 - accuracy: 0.0458 - val_loss: 9.4460 - val_accuracy: 0.0229\n",
      "Epoch 389/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4548 - accuracy: 0.0458 - val_loss: 9.4516 - val_accuracy: 0.0229\n",
      "Epoch 390/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4374 - accuracy: 0.0465 - val_loss: 9.4435 - val_accuracy: 0.0229\n",
      "Epoch 391/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4236 - accuracy: 0.0465 - val_loss: 9.4147 - val_accuracy: 0.0272\n",
      "Epoch 392/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4236 - accuracy: 0.0469 - val_loss: 9.4343 - val_accuracy: 0.0258\n",
      "Epoch 393/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4175 - accuracy: 0.0469 - val_loss: 9.4472 - val_accuracy: 0.0258\n",
      "Epoch 394/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4137 - accuracy: 0.0469 - val_loss: 9.4564 - val_accuracy: 0.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4210 - accuracy: 0.0458 - val_loss: 9.4446 - val_accuracy: 0.0243\n",
      "Epoch 396/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4233 - accuracy: 0.0465 - val_loss: 9.4527 - val_accuracy: 0.0200\n",
      "Epoch 397/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4192 - accuracy: 0.0469 - val_loss: 9.4617 - val_accuracy: 0.0215\n",
      "Epoch 398/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4197 - accuracy: 0.0465 - val_loss: 9.4612 - val_accuracy: 0.0200\n",
      "Epoch 399/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4158 - accuracy: 0.0469 - val_loss: 9.4610 - val_accuracy: 0.0243\n",
      "Epoch 400/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4203 - accuracy: 0.0469 - val_loss: 9.4515 - val_accuracy: 0.0186\n",
      "Epoch 401/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4128 - accuracy: 0.0469 - val_loss: 9.4286 - val_accuracy: 0.0200\n",
      "Epoch 402/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4080 - accuracy: 0.0469 - val_loss: 9.4507 - val_accuracy: 0.0200\n",
      "Epoch 403/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4120 - accuracy: 0.0469 - val_loss: 9.4521 - val_accuracy: 0.0215\n",
      "Epoch 404/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4074 - accuracy: 0.0465 - val_loss: 9.4484 - val_accuracy: 0.0243\n",
      "Epoch 405/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4016 - accuracy: 0.0469 - val_loss: 9.4486 - val_accuracy: 0.0229\n",
      "Epoch 406/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4009 - accuracy: 0.0469 - val_loss: 9.4493 - val_accuracy: 0.0229\n",
      "Epoch 407/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4005 - accuracy: 0.0469 - val_loss: 9.4560 - val_accuracy: 0.0229\n",
      "Epoch 408/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.3991 - accuracy: 0.0469 - val_loss: 9.4567 - val_accuracy: 0.0229\n",
      "Epoch 409/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3990 - accuracy: 0.0469 - val_loss: 9.4577 - val_accuracy: 0.0229\n",
      "Epoch 410/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3989 - accuracy: 0.0469 - val_loss: 9.4569 - val_accuracy: 0.0229\n",
      "Epoch 411/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3988 - accuracy: 0.0469 - val_loss: 9.4563 - val_accuracy: 0.0229\n",
      "Epoch 412/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.3988 - accuracy: 0.0469 - val_loss: 9.4560 - val_accuracy: 0.0229\n",
      "Epoch 413/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3987 - accuracy: 0.0469 - val_loss: 9.4562 - val_accuracy: 0.0229\n",
      "Epoch 414/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3986 - accuracy: 0.0469 - val_loss: 9.4571 - val_accuracy: 0.0229\n",
      "Epoch 415/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3986 - accuracy: 0.0469 - val_loss: 9.4582 - val_accuracy: 0.0229\n",
      "Epoch 416/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3986 - accuracy: 0.0469 - val_loss: 9.4588 - val_accuracy: 0.0229\n",
      "Epoch 417/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3985 - accuracy: 0.0469 - val_loss: 9.4593 - val_accuracy: 0.0229\n",
      "Epoch 418/500\n",
      "88/88 [==============================] - 6s 69ms/step - loss: 8.3985 - accuracy: 0.0469 - val_loss: 9.4595 - val_accuracy: 0.0229\n",
      "Epoch 419/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3985 - accuracy: 0.0469 - val_loss: 9.4600 - val_accuracy: 0.0229\n",
      "Epoch 420/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3985 - accuracy: 0.0469 - val_loss: 9.4608 - val_accuracy: 0.0229\n",
      "Epoch 421/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3984 - accuracy: 0.0469 - val_loss: 9.4616 - val_accuracy: 0.0229\n",
      "Epoch 422/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3984 - accuracy: 0.0469 - val_loss: 9.4622 - val_accuracy: 0.0229\n",
      "Epoch 423/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3984 - accuracy: 0.0469 - val_loss: 9.4638 - val_accuracy: 0.0229\n",
      "Epoch 424/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3984 - accuracy: 0.0469 - val_loss: 9.4636 - val_accuracy: 0.0229\n",
      "Epoch 425/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3980 - accuracy: 0.0469 - val_loss: 9.4622 - val_accuracy: 0.0229\n",
      "Epoch 426/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3977 - accuracy: 0.0469 - val_loss: 9.4609 - val_accuracy: 0.0229\n",
      "Epoch 427/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3971 - accuracy: 0.0469 - val_loss: 9.4559 - val_accuracy: 0.0229\n",
      "Epoch 428/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3970 - accuracy: 0.0469 - val_loss: 9.4582 - val_accuracy: 0.0229\n",
      "Epoch 429/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3969 - accuracy: 0.0469 - val_loss: 9.4579 - val_accuracy: 0.0229\n",
      "Epoch 430/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.3968 - accuracy: 0.0469 - val_loss: 9.4577 - val_accuracy: 0.0229\n",
      "Epoch 431/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3968 - accuracy: 0.0469 - val_loss: 9.4571 - val_accuracy: 0.0229\n",
      "Epoch 432/500\n",
      "88/88 [==============================] - 6s 71ms/step - loss: 8.3968 - accuracy: 0.0469 - val_loss: 9.4569 - val_accuracy: 0.0229\n",
      "Epoch 433/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.3968 - accuracy: 0.0469 - val_loss: 9.4567 - val_accuracy: 0.0229\n",
      "Epoch 434/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.3968 - accuracy: 0.0469 - val_loss: 9.4568 - val_accuracy: 0.0229\n",
      "Epoch 435/500\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 8.3968 - accuracy: 0.0469 - val_loss: 9.4569 - val_accuracy: 0.0229\n",
      "Epoch 436/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3967 - accuracy: 0.0469 - val_loss: 9.4570 - val_accuracy: 0.0229\n",
      "Epoch 437/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3967 - accuracy: 0.0469 - val_loss: 9.4571 - val_accuracy: 0.0229\n",
      "Epoch 438/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4054 - accuracy: 0.0469 - val_loss: 9.4507 - val_accuracy: 0.0286\n",
      "Epoch 439/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4895 - accuracy: 0.0451 - val_loss: 9.4666 - val_accuracy: 0.0172\n",
      "Epoch 440/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.5537 - accuracy: 0.0433 - val_loss: 9.4941 - val_accuracy: 0.0243\n",
      "Epoch 441/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.5628 - accuracy: 0.0411 - val_loss: 9.4987 - val_accuracy: 0.0272\n",
      "Epoch 442/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.5163 - accuracy: 0.0443 - val_loss: 9.5085 - val_accuracy: 0.0243\n",
      "Epoch 443/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4966 - accuracy: 0.0451 - val_loss: 9.5144 - val_accuracy: 0.0215\n",
      "Epoch 444/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4779 - accuracy: 0.0451 - val_loss: 9.4835 - val_accuracy: 0.0229\n",
      "Epoch 445/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4725 - accuracy: 0.0443 - val_loss: 9.4713 - val_accuracy: 0.0243\n",
      "Epoch 446/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4546 - accuracy: 0.0458 - val_loss: 9.4643 - val_accuracy: 0.0200\n",
      "Epoch 447/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4484 - accuracy: 0.0451 - val_loss: 9.5045 - val_accuracy: 0.0186\n",
      "Epoch 448/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4322 - accuracy: 0.0454 - val_loss: 9.5011 - val_accuracy: 0.0186\n",
      "Epoch 449/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4254 - accuracy: 0.0454 - val_loss: 9.4814 - val_accuracy: 0.0186\n",
      "Epoch 450/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4238 - accuracy: 0.0454 - val_loss: 9.4657 - val_accuracy: 0.0243\n",
      "Epoch 451/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4163 - accuracy: 0.0461 - val_loss: 9.4613 - val_accuracy: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/500\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 8.4199 - accuracy: 0.0458 - val_loss: 9.4738 - val_accuracy: 0.0243\n",
      "Epoch 453/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4198 - accuracy: 0.0458 - val_loss: 9.4656 - val_accuracy: 0.0215\n",
      "Epoch 454/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4166 - accuracy: 0.0465 - val_loss: 9.4877 - val_accuracy: 0.0215\n",
      "Epoch 455/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4131 - accuracy: 0.0461 - val_loss: 9.4894 - val_accuracy: 0.0243\n",
      "Epoch 456/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4127 - accuracy: 0.0461 - val_loss: 9.4731 - val_accuracy: 0.0272\n",
      "Epoch 457/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4226 - accuracy: 0.0465 - val_loss: 9.4686 - val_accuracy: 0.0215\n",
      "Epoch 458/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.4228 - accuracy: 0.0465 - val_loss: 9.4515 - val_accuracy: 0.0229\n",
      "Epoch 459/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.4200 - accuracy: 0.0465 - val_loss: 9.4653 - val_accuracy: 0.0258\n",
      "Epoch 460/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4123 - accuracy: 0.0465 - val_loss: 9.4803 - val_accuracy: 0.0272\n",
      "Epoch 461/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4109 - accuracy: 0.0465 - val_loss: 9.4749 - val_accuracy: 0.0272\n",
      "Epoch 462/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4132 - accuracy: 0.0461 - val_loss: 9.4540 - val_accuracy: 0.0272\n",
      "Epoch 463/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4060 - accuracy: 0.0465 - val_loss: 9.4465 - val_accuracy: 0.0258\n",
      "Epoch 464/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.4075 - accuracy: 0.0465 - val_loss: 9.4659 - val_accuracy: 0.0186\n",
      "Epoch 465/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.4056 - accuracy: 0.0465 - val_loss: 9.4502 - val_accuracy: 0.0215\n",
      "Epoch 466/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3998 - accuracy: 0.0469 - val_loss: 9.4471 - val_accuracy: 0.0215\n",
      "Epoch 467/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3991 - accuracy: 0.0469 - val_loss: 9.4553 - val_accuracy: 0.0215\n",
      "Epoch 468/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.4001 - accuracy: 0.0465 - val_loss: 9.4454 - val_accuracy: 0.0215\n",
      "Epoch 469/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3992 - accuracy: 0.0469 - val_loss: 9.4481 - val_accuracy: 0.0229\n",
      "Epoch 470/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3989 - accuracy: 0.0469 - val_loss: 9.4495 - val_accuracy: 0.0229\n",
      "Epoch 471/500\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 8.3981 - accuracy: 0.0469 - val_loss: 9.4495 - val_accuracy: 0.0229\n",
      "Epoch 472/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.3980 - accuracy: 0.0469 - val_loss: 9.4495 - val_accuracy: 0.0229\n",
      "Epoch 473/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.3980 - accuracy: 0.0469 - val_loss: 9.4497 - val_accuracy: 0.0229\n",
      "Epoch 474/500\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 8.3979 - accuracy: 0.0469 - val_loss: 9.4502 - val_accuracy: 0.0243\n",
      "Epoch 475/500\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 8.3979 - accuracy: 0.0469 - val_loss: 9.4502 - val_accuracy: 0.0243\n",
      "Epoch 476/500\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 8.3978 - accuracy: 0.0469 - val_loss: 9.4504 - val_accuracy: 0.0243\n",
      "Epoch 477/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3978 - accuracy: 0.0469 - val_loss: 9.4509 - val_accuracy: 0.0243\n",
      "Epoch 478/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3978 - accuracy: 0.0469 - val_loss: 9.4518 - val_accuracy: 0.0229\n",
      "Epoch 479/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3977 - accuracy: 0.0469 - val_loss: 9.4526 - val_accuracy: 0.0229\n",
      "Epoch 480/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3964 - accuracy: 0.0469 - val_loss: 9.4561 - val_accuracy: 0.0229\n",
      "Epoch 481/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3957 - accuracy: 0.0469 - val_loss: 9.4581 - val_accuracy: 0.0229\n",
      "Epoch 482/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3955 - accuracy: 0.0469 - val_loss: 9.4572 - val_accuracy: 0.0229\n",
      "Epoch 483/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3955 - accuracy: 0.0469 - val_loss: 9.4570 - val_accuracy: 0.0229\n",
      "Epoch 484/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3954 - accuracy: 0.0469 - val_loss: 9.4566 - val_accuracy: 0.0229\n",
      "Epoch 485/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3954 - accuracy: 0.0469 - val_loss: 9.4563 - val_accuracy: 0.0229\n",
      "Epoch 486/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3954 - accuracy: 0.0469 - val_loss: 9.4558 - val_accuracy: 0.0243\n",
      "Epoch 487/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3948 - accuracy: 0.0469 - val_loss: 9.4489 - val_accuracy: 0.0229\n",
      "Epoch 488/500\n",
      "88/88 [==============================] - 6s 70ms/step - loss: 8.3948 - accuracy: 0.0469 - val_loss: 9.4511 - val_accuracy: 0.0243\n",
      "Epoch 489/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3947 - accuracy: 0.0469 - val_loss: 9.4518 - val_accuracy: 0.0243\n",
      "Epoch 490/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3947 - accuracy: 0.0469 - val_loss: 9.4521 - val_accuracy: 0.0243\n",
      "Epoch 491/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3946 - accuracy: 0.0469 - val_loss: 9.4524 - val_accuracy: 0.0243\n",
      "Epoch 492/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3946 - accuracy: 0.0469 - val_loss: 9.4529 - val_accuracy: 0.0243\n",
      "Epoch 493/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3946 - accuracy: 0.0469 - val_loss: 9.4541 - val_accuracy: 0.0243\n",
      "Epoch 494/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3939 - accuracy: 0.0472 - val_loss: 9.4533 - val_accuracy: 0.0243\n",
      "Epoch 495/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3939 - accuracy: 0.0472 - val_loss: 9.4529 - val_accuracy: 0.0243\n",
      "Epoch 496/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3938 - accuracy: 0.0472 - val_loss: 9.4525 - val_accuracy: 0.0243\n",
      "Epoch 497/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3938 - accuracy: 0.0472 - val_loss: 9.4522 - val_accuracy: 0.0243\n",
      "Epoch 498/500\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 8.3938 - accuracy: 0.0472 - val_loss: 9.4518 - val_accuracy: 0.0243\n",
      "Epoch 499/500\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 8.3933 - accuracy: 0.0472 - val_loss: 9.4541 - val_accuracy: 0.0243\n",
      "Epoch 500/500\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 8.3931 - accuracy: 0.0472 - val_loss: 9.4478 - val_accuracy: 0.0243\n"
     ]
    }
   ],
   "source": [
    "for q in currency_list:\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for x in range(1):\n",
    "\n",
    "        currency = q.replace('10080','')\n",
    "\n",
    "        data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "        #data = data.head(695)\n",
    "\n",
    "\n",
    "        X = data.drop(columns=['Unnamed: 0', \n",
    "                               'date_start',  'nextweek_class',\n",
    "\n",
    "\n",
    "                              ])\n",
    "\n",
    "\n",
    "\n",
    "        y = data['nextweek_class']\n",
    "      \n",
    "    \n",
    "        \n",
    "\n",
    "        #print(X.shape)\n",
    "        \n",
    "        \n",
    "        # after scaling the df, resulted in \"scaled_dataset\"\n",
    "        sequences = 3\n",
    "        result = []\n",
    "        # for loop will walk for each of the 1500 rows\n",
    "        for i in range(0,len(X)):\n",
    "            # every group must have the same length, so if current loop position i + number \n",
    "            # of sequences is higher than df length, breaks\n",
    "            if i+sequences <= len(X):\n",
    "                # this will add into the list as [[R1a,R1b...R1t],[R2a,R2b...R2t],...[R5a,R5b...R5t]]\n",
    "                result.append(X[i:i+sequences].values)\n",
    "        # Converting to array + keras takes float32 better than 64\n",
    "        train_x = np.array(result)\n",
    "        #train_x  = train_x.astype('float32')\n",
    "        # making the y into same length as X\n",
    "        train_y = np.array(y.head(len(train_x)).values)\n",
    "\n",
    "        print(train_x.shape, train_y.shape)\n",
    "        #print(train_x[len(train_x)-10])\n",
    "        #print(train_y[len(train_x)-10])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.2 )\n",
    "\n",
    "       \n",
    "        \n",
    "       \n",
    "        #Initializing the classifier Network\n",
    "        classifier = Sequential()\n",
    "\n",
    "        #Adding the input LSTM network layer\n",
    "        #classifier.add(CuDNNLSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
    "        classifier.add(LSTM(200, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "        classifier.add(LSTM(200, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "        \n",
    "        classifier.add(LSTM(1,  return_sequences=False))\n",
    "        #classifier.add(Dropout(0.2))\n",
    "        #Adding a second LSTM network layer\n",
    "        \n",
    "        #classifier.add(LSTM(128))\n",
    "        #Adding a dense hidden layer\n",
    "        #classifier.add(Dense(64, activation='relu'))\n",
    "        #classifier.add(Dropout(0.2))\n",
    "\n",
    "        #Adding the output layer\n",
    "        #classifier.add(Dense(35, activation='softmax'))\n",
    "      \n",
    "        #Compiling the network\n",
    "        classifier.compile( loss='mean_absolute_error',\n",
    "                      optimizer=Adam(learning_rate=0.001, decay=1e-6),\n",
    "                      metrics=['accuracy'] )\n",
    "        \n",
    "        print(classifier.summary())\n",
    "\n",
    "        #Fitting the data to the model\n",
    "        history = classifier.fit(X_train,\n",
    "                 y_train,\n",
    "                  epochs=500,\n",
    "                  validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65668a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 20ms/step - loss: 8.3931 - accuracy: 0.0472\n",
      "Test Loss: 8.39311408996582\n",
      "Test Accuracy: 0.04721030220389366\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = classifier.evaluate(X_train, y_train)\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9f56b9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2243a700f40>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ea025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798afda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
