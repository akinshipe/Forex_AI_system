{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b0986e4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "currency_list = ['USDCHF10080',\n",
    "                 #'GBPUSD10080', 'EURUSD10080', 'USDJPY10080', 'USDCAD10080', 'AUDUSD10080', 'NZDUSD10080',\n",
    "                 #'GBPCHF10080', 'EURCHF10080', 'CHFJPY10080', 'CADCHF10080', 'AUDCHF10080', 'NZDCHF10080', 'EURGBP10080',\n",
    "                 #'GBPJPY10080', 'GBPCAD10080', 'GBPAUD10080', 'EURJPY10080', 'EURCAD10080', 'EURAUD10080', 'EURNZD10080',\n",
    "                #'CADJPY10080', 'AUDJPY10080', 'NZDJPY10080', 'AUDCAD10080', 'NZDCAD10080', 'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65bef777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "728\n"
     ]
    }
   ],
   "source": [
    "# #loops through all currency, identify timeframes not in nzdcad and save them in global_available_timeframes list\n",
    "\n",
    "headers = ['date_start', 'ignore', 'open', 'high', 'low', 'close', 'volume'  ]\n",
    "\n",
    "shortest_row_currency = pd.read_csv('recent_data/' + 'NZDCAD10080' + '.csv', names=headers  )  \n",
    "\n",
    "#this reverses the rows so as to have the recent timeframe at the top\n",
    "shortest_row_currency = shortest_row_currency.sort_index(axis=0,ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "shortest_row_currency_timeframes = shortest_row_currency['date_start']\n",
    "\n",
    "\n",
    "\n",
    "shortest_row_currency_timeframes = shortest_row_currency_timeframes.values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "global_unavailable_timeframes = []\n",
    "for x in currency_list:\n",
    "    \n",
    "    \n",
    "    current_currency_data = pd.read_csv('recent_data/' + x + '.csv', names=headers  )  \n",
    "    \n",
    "    current_currency_data_timeframes = current_currency_data['date_start']\n",
    "   \n",
    "    current_currency_data_timeframes = current_currency_data_timeframes.values.tolist()\n",
    "   \n",
    "    for y in shortest_row_currency_timeframes:\n",
    "        \n",
    "            if y not in current_currency_data_timeframes :\n",
    "                \n",
    "                global_unavailable_timeframes.append(y)\n",
    "                \n",
    "\n",
    "# this get the unique time frames because time frames could have been duplicated from different currencies \n",
    "global_unavailable_timeframes = np.unique(global_unavailable_timeframes)   \n",
    "\n",
    "\n",
    "print(len(global_unavailable_timeframes))   \n",
    "print(len(shortest_row_currency_timeframes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d656c82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728\n"
     ]
    }
   ],
   "source": [
    "#removes the identified time frame nzdcad timeframe list to ensure that all timeframe in nzdcad list have \n",
    "#data in other currencies\n",
    "\n",
    "globally_available_time_frame=[]\n",
    "\n",
    "for x in global_unavailable_timeframes:\n",
    "    \n",
    "    shortest_row_currency_timeframes.remove(x)\n",
    "    \n",
    "globally_available_time_frame = shortest_row_currency_timeframes\n",
    "\n",
    "print(len(globally_available_time_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc9f7a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date_start ignore     open     high      low    close  volume\n",
      "2587  2021.08.29  00:00  0.91084  0.91891  0.91009  0.91415  158583\n",
      "2586  2021.08.22  00:00  0.91594  0.91997  0.91061  0.91105  150969\n",
      "2585  2021.08.15  00:00  0.91494  0.92067  0.90994  0.91689  143626\n",
      "2584  2021.08.08  00:00  0.91364  0.92421  0.91349  0.91523  128138\n",
      "2583  2021.08.01  00:00  0.90439  0.91560  0.90183  0.91499  154705\n",
      "...          ...    ...      ...      ...      ...      ...     ...\n",
      "4     1971.01.31  00:00  4.29680  4.29690  4.29650  4.29690       5\n",
      "3     1971.01.24  00:00  4.30050  4.30050  4.29630  4.29630       5\n",
      "2     1971.01.17  00:00  4.30290  4.30290  4.29960  4.29960       5\n",
      "1     1971.01.10  00:00  4.31020  4.31020  4.30760  4.30760       5\n",
      "0     1971.01.03  00:00  4.31800  4.31800  4.31030  4.31090       5\n",
      "\n",
      "[2588 rows x 7 columns]\n",
      "[-9]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (708) does not match length of index (728)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LAOLUH~1\\AppData\\Local\\Temp/ipykernel_1916/2385141122.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvolume_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mmini_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobally_available_time_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mmini_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mcombine_data_dataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mcombine_data_dataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3605\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3606\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3607\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3609\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3777\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \"\"\"\n\u001b[1;32m-> 3779\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3781\u001b[0m         if (\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4504\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4505\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (708) does not match length of index (728)"
     ]
    }
   ],
   "source": [
    "# loop through all currency pairs, get the needed rows from them and assemble all rows to form a combine_data_dataframe\n",
    "\n",
    "combine_data_dataframe = pd.DataFrame(data={}, index = pd.Series(range(0,len(globally_available_time_frame))), )\n",
    "\n",
    "for x in currency_list :\n",
    "    \n",
    "    \n",
    "\n",
    "    current_currency_data = pd.read_csv('recent_data/' + x + '.csv', names=headers  ) \n",
    "    \n",
    "    # this sort the rows, so as to have the most recent time frame at the top\n",
    "    current_currency_data = current_currency_data.sort_index(axis=0,ascending=False)\n",
    "    print(current_currency_data)\n",
    "    current_currency_volume = []\n",
    "    \n",
    "    current_currency_class = []\n",
    "    \n",
    "    q = 0\n",
    "\n",
    "    for y in globally_available_time_frame:\n",
    "\n",
    "        for index, row in current_currency_data.iterrows():\n",
    "           \n",
    "            \n",
    "            if y  == row.date_start:            \n",
    "                        \n",
    "                current_currency_volume.append(row.volume)            \n",
    "                \n",
    "                # condition when the curreny movement is a buy\n",
    "\n",
    "                pips_corrector = 100000\n",
    "\n",
    "                if x.endswith('jpy'):# use this to correct multiplier of jpy pairs\n",
    "                    pips_corrector = 1000\n",
    "\n",
    "                if row.open < row.close:\n",
    "\n",
    "                    trend = 1\n",
    "\n",
    "\n",
    "                    #classifying the risk level\n",
    "\n",
    "\n",
    "                    if (row.open - row.low) == 0 : # no risk because open is equal to low\n",
    "\n",
    "                        risk = 6\n",
    "\n",
    "                    else : \n",
    "\n",
    "                        if (row.open - row.low)> (row.high - row.open):\n",
    "\n",
    "                            risk = 1\n",
    "\n",
    "                        if  (row.high - row.open) > (row.open - row.low):\n",
    "\n",
    "                            risk = 2\n",
    "\n",
    "\n",
    "                        if (row.high - row.open) /(row.open - row.low) >2 :\n",
    "\n",
    "                            risk = 3\n",
    "\n",
    "                        if (row.high - row.open) /(row.open - row.low) >4 :\n",
    "\n",
    "                            risk = 4\n",
    "\n",
    "\n",
    "                        if (row.high - row.open) /(row.open - row.low) >8 :\n",
    "\n",
    "                            risk = 5\n",
    "\n",
    "                        if (row.high - row.open) /(row.open - row.low) >16 :\n",
    "\n",
    "                            risk = 6  \n",
    "\n",
    "                    #classifying reward level\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 0 :\n",
    "\n",
    "                        reward = 1\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector >200 :\n",
    "\n",
    "                        reward = 2\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 400 :\n",
    "\n",
    "                        reward = 3\n",
    "\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 800 :\n",
    "\n",
    "                        reward = 4\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 1600 :\n",
    "\n",
    "                        reward = 5\n",
    "\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 3200 :\n",
    "\n",
    "                        reward = 6  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # this is for the condition when the movement is a sell\n",
    "                else: \n",
    "\n",
    "                    trend = -1\n",
    "\n",
    "                    #classifying the risk level\n",
    "\n",
    "\n",
    "                    if (row.high - row.open) == 0 : # no risk because open is equal to high\n",
    "\n",
    "                        risk = 6\n",
    "\n",
    "                    else : \n",
    "\n",
    "                        if (row.high - row.open)> (row.open - row.low):\n",
    "\n",
    "                            risk = 1\n",
    "\n",
    "                        if  (row.open - row.low) > (row.high - row.open):\n",
    "\n",
    "                            risk = 2\n",
    "\n",
    "\n",
    "                        if (row.open - row.low) /(row.high - row.open) >2 :\n",
    "\n",
    "                            risk = 3\n",
    "\n",
    "                        if (row.open - row.low) /(row.high - row.open) >4 :\n",
    "\n",
    "                            risk = 4\n",
    "\n",
    "                        if (row.open - row.low) /(row.high - row.open) >8 :\n",
    "\n",
    "                            risk = 5\n",
    "\n",
    "                        if (row.open - row.low) /(row.high - row.open) >16 :\n",
    "\n",
    "                            risk = 6 \n",
    "\n",
    "\n",
    "                     #classifying reward level\n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 0 :\n",
    "\n",
    "                        reward = 1\n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 200 :\n",
    "\n",
    "                        reward = 2\n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 400 :\n",
    "\n",
    "                        reward = 3        \n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 800 :\n",
    "\n",
    "                        reward = 4    \n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 1600 :\n",
    "\n",
    "                        reward = 5 \n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 3200 :\n",
    "\n",
    "                        reward = 6        \n",
    "\n",
    "            current_currency_class.append(trend*risk*reward)\n",
    "            \n",
    "        \n",
    "\n",
    "            #attach the classification score value to the dataframe and train a model with the data\n",
    "            #print(index)\n",
    "    print(current_currency_class)\n",
    "\n",
    "            #combine_data_dataframe[x+'_class'] = current_currency_class\n",
    "\n",
    "\n",
    "            \n",
    "                        \n",
    "\n",
    "    # this function takes a list and returns with a list of 5 list that is the data for the previous row\n",
    "    \n",
    "    def add_5_columns(real_column) :\n",
    "        \n",
    "        current_currency_column_add_on = [real_column, [], [], [], [], []]\n",
    "        \n",
    "        g = 1 \n",
    "        \n",
    "        while g < 6:\n",
    "            \n",
    "            current_currency_column_add_on[g] = current_currency_column_add_on[g-1].copy()\n",
    "            current_currency_column_add_on[g].pop(0)\n",
    "            current_currency_column_add_on[g].append(0)    \n",
    "            g = g+1\n",
    "            \n",
    "        current_currency_column_add_on.pop(0)\n",
    "        return current_currency_column_add_on\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "    combine_data_dataframe[ x +'_volume'] = current_currency_volume\n",
    "    \n",
    "    #volume_columns = add_5_columns(current_currency_volume)\n",
    "    \n",
    "    for h in volume_columns:\n",
    "        mini_df = pd.DataFrame(data={}, index = pd.Series(range(0,len(globally_available_time_frame))), )\n",
    "        mini_df[''] = h   \n",
    "        combine_data_dataframe = pd.concat([ combine_data_dataframe, mini_df], axis=1)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    combine_data_dataframe[ x +'_open'] = current_currency_open\n",
    "    \n",
    "    #open_columns = add_5_columns(current_currency_open)\n",
    "    \n",
    "    for h in open_columns:\n",
    "        mini_df = pd.DataFrame(data={}, index = pd.Series(range(0,len(globally_available_time_frame))), )\n",
    "        mini_df[''] = h   \n",
    "        combine_data_dataframe = pd.concat([ combine_data_dataframe, mini_df], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    combine_data_dataframe[ x +'_high'] = current_currency_high   \n",
    "    \n",
    "    #high_columns = add_5_columns(current_currency_high)\n",
    "    \n",
    "    for h in high_columns:\n",
    "        mini_df = pd.DataFrame(data={}, index = pd.Series(range(0,len(globally_available_time_frame))), )\n",
    "        mini_df[''] = h   \n",
    "        combine_data_dataframe = pd.concat([ combine_data_dataframe, mini_df], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    combine_data_dataframe[ x +'_low'] = current_currency_low\n",
    "    \n",
    "    #low_columns = add_5_columns(current_currency_low)\n",
    "    \n",
    "    for h in low_columns:\n",
    "        mini_df = pd.DataFrame(data={}, index = pd.Series(range(0,len(globally_available_time_frame))), )\n",
    "        mini_df[''] = h   \n",
    "        combine_data_dataframe = pd.concat([ combine_data_dataframe, mini_df], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    combine_data_dataframe[ x +'_close'] = current_currency_close\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and add the timeframe column to the combine_data_data_frame to be able to identify each rows\n",
    "\n",
    "date_series = pd.Series(globally_available_time_frame)\n",
    "\n",
    "# the code below convert it to panda date time object\n",
    "date_series = pd.to_datetime(date_series)\n",
    "\n",
    "\n",
    "#turning date_series to a data frame so as to be able to add it as the first column \n",
    "date_series_dataframe =  pd.DataFrame(data={}, index = pd.Series(range(0, len(globally_available_time_frame))), )\n",
    "date_series_dataframe['date_start'] = date_series\n",
    "\n",
    "#the two dataframes are combined along the y axis to form one dataframe with all information and date\n",
    "combine_data_dataframe = pd.concat([ date_series_dataframe, combine_data_dataframe], axis=1)\n",
    "\n",
    "combine_data_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies the data frame so as to isolate the first 10 rows for prediction\n",
    "combine_top_10_rows_dataframe = combine_data_dataframe.copy(deep=True)\n",
    "\n",
    "\n",
    "combine_top_10_rows_dataframe = combine_top_10_rows_dataframe.head(25)\n",
    "\n",
    "#saves the first 10 rows to excel\n",
    "\n",
    "combine_top_10_rows_dataframe.to_excel(\"files/combine_top_10_rows_dataframe.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "combine_data_dataframe = combine_data_dataframe.head( len(globally_available_time_frame) - 5 )\n",
    "\n",
    "combine_data_dataframe.to_excel(\"files/combine_data_dataframe.xlsx\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776bed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
