{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b0986e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "currency_list = [#'USDCHF1440',\n",
    "                 #'GBPUSD1440', \n",
    "                 'EURUSD1440',\n",
    "    #'USDJPY1440',\n",
    "    #'USDCAD1440', \n",
    "    #'AUDUSD1440',\n",
    "    #'NZDUSD1440',\n",
    "                 # 'GBPCHF1440',\n",
    "    #'EURCHF1440', \n",
    "#'CHFJPY1440',\n",
    "    #'CADCHF1440', \n",
    "    #'AUDCHF1440',\n",
    "    #'NZDCHF1440',\n",
    "    #'EURGBP1440',\n",
    "   #'GBPJPY1440',\n",
    "    #'GBPCAD1440',\n",
    "    #'GBPAUD1440',\n",
    "    #'EURJPY1440', \n",
    "    #'EURCAD1440', \n",
    "    #'EURAUD1440', \n",
    "    #'EURNZD1440',\n",
    "#'CADJPY1440', \n",
    "    #'AUDJPY1440',\n",
    "    #'NZDJPY1440',\n",
    "    #'AUDCAD1440',\n",
    "#'NZDCAD1440',\n",
    "#'AUDNZD1440'\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "headers = ['date_start', 'ignore', 'open', 'high', 'low', 'close', 'volume'  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe7194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b7617585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EURUSD1440 12735\n"
     ]
    }
   ],
   "source": [
    "shortest_row_currency = ''\n",
    "lowest_number_rows = 1000000000000000000\n",
    "\n",
    "for p in currency_list:\n",
    "    \n",
    "    current_currency_row = pd.read_csv('recent_data_daily/' + p + '.csv', names=headers  ) \n",
    "    current_currency_row = len( current_currency_row.index )\n",
    "    \n",
    "    if current_currency_row < lowest_number_rows:\n",
    "        \n",
    "        lowest_number_rows = current_currency_row\n",
    "        shortest_row_currency = p\n",
    "        \n",
    "        \n",
    "        \n",
    "print(shortest_row_currency, lowest_number_rows)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a38eceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_data = pd.read_excel('investings_weekly_fundamental_data.xlsx', sheet_name=0  ) \n",
    "    \n",
    "available_fundamental_timeframe  = fundamental_data['original date frame'].dt.strftime('%Y-%m-%d').values.tolist()\n",
    "corrected_available_fundamental_timeframe =[]\n",
    "for h in available_fundamental_timeframe:\n",
    "            \n",
    "    corrected_available_fundamental_timeframe.append(h.replace('-','.'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "65bef777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "12735\n"
     ]
    }
   ],
   "source": [
    "# #loops through all currency, identify timeframes not in nzdcad and save them in global_available_timeframes list\n",
    "\n",
    "\n",
    "\n",
    "shortest_row_currency = pd.read_csv('recent_data_daily/' + p + '.csv', names=headers  ) \n",
    "\n",
    "#this reverses the rows so as to have the recent timeframe at the top\n",
    "#shortest_row_currency = shortest_row_currency.sort_index(axis=0,ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "shortest_row_currency_timeframes = shortest_row_currency['date_start']\n",
    "\n",
    "\n",
    "\n",
    "shortest_row_currency_timeframes = shortest_row_currency_timeframes.values.tolist()\n",
    "\n",
    "\n",
    "global_unavailable_timeframes = []\n",
    "for x in currency_list:\n",
    "    \n",
    "    \n",
    "    current_currency_data = pd.read_csv('recent_data_daily/' + x + '.csv', names=headers  )  \n",
    "    \n",
    "    current_currency_data_timeframes = current_currency_data['date_start']\n",
    "   \n",
    "    current_currency_data_timeframes = current_currency_data_timeframes.values.tolist()\n",
    "   \n",
    "    for y in shortest_row_currency_timeframes:\n",
    "        \n",
    "            if y not in current_currency_data_timeframes :\n",
    "                \n",
    "                global_unavailable_timeframes.append(y)\n",
    "                \n",
    "\n",
    "# this get the unique time frames because time frames could have been duplicated from different currencies \n",
    "global_unavailable_timeframes = np.unique(global_unavailable_timeframes)   \n",
    "\n",
    "\n",
    "print(len(global_unavailable_timeframes))   \n",
    "print(len(shortest_row_currency_timeframes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d656c82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12735\n"
     ]
    }
   ],
   "source": [
    "# removing the globally unavailable timeframes from the shortest row currency\n",
    "\n",
    "for x in global_unavailable_timeframes:\n",
    "    shortest_row_currency_timeframes.remove(x)\n",
    "    \n",
    "globally_available_time_frame = shortest_row_currency_timeframes\n",
    "print(len(globally_available_time_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f7a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop through all currency pairs, get the needed rows from them and assemble all rows to form a combine_data_dataframe\n",
    "\n",
    "combine_data_dataframe = pd.DataFrame(data={}, index = pd.Series(range(0,len(globally_available_time_frame))), )\n",
    "\n",
    "for x in currency_list :\n",
    "    \n",
    "    \n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    current_currency_data = pd.read_csv('recent_data_daily/' + x + '.csv', names=headers  ) \n",
    "    \n",
    "    # this sort the rows, so as to have the most recent time frame at the top\n",
    "    current_currency_data = current_currency_data.sort_index(axis=0,ascending=False)\n",
    "   \n",
    "    current_currency_volume = []\n",
    "    \n",
    "    current_currency_class = []\n",
    "    \n",
    "    current_currency_day = []\n",
    "    \n",
    "    q = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    for y in globally_available_time_frame:\n",
    "       \n",
    "       \n",
    "        for index, row in current_currency_data.iterrows():\n",
    "            \n",
    "           # print(y, row.date_start)\n",
    "            if y  == row.date_start : \n",
    "               \n",
    "                        \n",
    "                #current_currency_volume.append(row.volume)            \n",
    "                \n",
    "                # condition when the curreny movement is a buy\n",
    "\n",
    "                pips_corrector = 100000\n",
    "\n",
    "                if x.endswith('jpy'):# use this to correct multiplier of jpy pairs\n",
    "                    pips_corrector = 1000\n",
    "\n",
    "                if row.open < row.close:\n",
    "\n",
    "                    trend = 1\n",
    "\n",
    "\n",
    "                    #classifying the risk level\n",
    "\n",
    "\n",
    "                    if (row.open - row.low) == 0 : # no risk because open is equal to low\n",
    "\n",
    "                        risk = 6\n",
    "\n",
    "                    else : \n",
    "\n",
    "                        if (row.open - row.low)> (row.high - row.open):\n",
    "\n",
    "                            risk = 1\n",
    "\n",
    "                        if  (row.high - row.open) > (row.open - row.low):\n",
    "\n",
    "                            risk = 2\n",
    "\n",
    "\n",
    "                        if (row.high - row.open) /(row.open - row.low) >2 :\n",
    "\n",
    "                            risk = 3\n",
    "\n",
    "                        if (row.high - row.open) /(row.open - row.low) >4 :\n",
    "\n",
    "                            risk = 4\n",
    "\n",
    "\n",
    "                        if (row.high - row.open) /(row.open - row.low) >8 :\n",
    "\n",
    "                            risk = 5\n",
    "\n",
    "                        if (row.high - row.open) /(row.open - row.low) >16 :\n",
    "\n",
    "                            risk = 6  \n",
    "\n",
    "                    #classifying reward level\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 0 :\n",
    "\n",
    "                        reward = 1\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector >200 :\n",
    "\n",
    "                        reward = 2\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 400 :\n",
    "\n",
    "                        reward = 3\n",
    "\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 800 :\n",
    "\n",
    "                        reward = 4\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 1600 :\n",
    "\n",
    "                        reward = 5\n",
    "\n",
    "\n",
    "                    if (row.close - row.open)*pips_corrector > 3200 :\n",
    "\n",
    "                        reward = 6  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # this is for the condition when the movement is a sell\n",
    "                else: \n",
    "\n",
    "                    trend = -1\n",
    "\n",
    "                    #classifying the risk level\n",
    "\n",
    "\n",
    "                    if (row.high - row.open) == 0 : # no risk because open is equal to high\n",
    "\n",
    "                        risk = 6\n",
    "\n",
    "                    else : \n",
    "\n",
    "                        if (row.high - row.open)> (row.open - row.low):\n",
    "\n",
    "                            risk = 1\n",
    "\n",
    "                        if  (row.open - row.low) > (row.high - row.open):\n",
    "\n",
    "                            risk = 2\n",
    "\n",
    "\n",
    "                        if (row.open - row.low) /(row.high - row.open) >2 :\n",
    "\n",
    "                            risk = 3\n",
    "\n",
    "                        if (row.open - row.low) /(row.high - row.open) >4 :\n",
    "\n",
    "                            risk = 4\n",
    "\n",
    "                        if (row.open - row.low) /(row.high - row.open) >8 :\n",
    "\n",
    "                            risk = 5\n",
    "\n",
    "                        if (row.open - row.low) /(row.high - row.open) >16 :\n",
    "\n",
    "                            risk = 6 \n",
    "\n",
    "\n",
    "                     #classifying reward level\n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 0 :\n",
    "\n",
    "                        reward = 1\n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 200 :\n",
    "\n",
    "                        reward = 2\n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 400 :\n",
    "\n",
    "                        reward = 3        \n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 800 :\n",
    "\n",
    "                        reward = 4    \n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 1600 :\n",
    "\n",
    "                        reward = 5 \n",
    "\n",
    "                    if (row.open - row.close)*pips_corrector > 3200 :\n",
    "\n",
    "                        reward = 6        \n",
    "            \n",
    "                #print(index)\n",
    "                break \n",
    "            \n",
    "        current_currency_class.append(trend*risk*reward)\n",
    "        current_currency_volume.append(row.volume)   \n",
    "        current_currency_day.append(datetime.date(int(row.date_start[0:4]), int(row.date_start[5:7]), int(row.date_start[8:10])).strftime('%w'))\n",
    "\n",
    "            #attach the classification score value to the dataframe and train a model with the data\n",
    "            #print(index)\n",
    "    #print(current_currency_class)\n",
    "\n",
    "            #combine_data_dataframe[x+'_class'] = current_currency_class\n",
    "    \n",
    "    \n",
    "            \n",
    "                        \n",
    "\n",
    "    # this function takes a list and returns with a list of 5 list that is the data for the previous row\n",
    "    \n",
    "    def add_5_columns(real_column) :\n",
    "        \n",
    "        current_currency_column_add_on = [real_column, [], [], [], [], []]\n",
    "        \n",
    "        g = 1 \n",
    "        \n",
    "        while g < 6:\n",
    "            \n",
    "            current_currency_column_add_on[g] = current_currency_column_add_on[g-1].copy()\n",
    "            current_currency_column_add_on[g].pop(0)\n",
    "            current_currency_column_add_on[g].append(0)    \n",
    "            g = g+1\n",
    "            \n",
    "        current_currency_column_add_on.pop(0)\n",
    "        return current_currency_column_add_on\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "    combine_data_dataframe[ x +'_volume'] = current_currency_volume\n",
    "    \n",
    "    #volume_columns = add_5_columns(current_currency_volume)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    combine_data_dataframe[ x +'_class'] = current_currency_class\n",
    "    \n",
    "    \n",
    "    combine_data_dataframe[ x +'_day'] = current_currency_day\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #low_columns = add_5_columns(current_currency_low)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    #combine_data_dataframe[ x +'_close'] = current_currency_close\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(x)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and add the timeframe column to the combine_data_data_frame to be able to identify each rows\n",
    "\n",
    "date_series = pd.Series(globally_available_time_frame)\n",
    "\n",
    "# the code below convert it to panda date time object\n",
    "date_series = pd.to_datetime(date_series)\n",
    "\n",
    "\n",
    "#turning date_series to a data frame so as to be able to add it as the first column \n",
    "date_series_dataframe =  pd.DataFrame(data={}, index = pd.Series(range(0, len(globally_available_time_frame))), )\n",
    "date_series_dataframe['date_start'] = date_series\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#the two dataframes are combined along the y axis to form one dataframe with all information and date\n",
    "combine_data_dataframe = pd.concat([ date_series_dataframe, combine_data_dataframe, ], axis=1)\n",
    "\n",
    "combine_data_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b977a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fundamental_data = fundamental_data[[\n",
    "                                #'eur_black', \n",
    "                                     #'eur_green',\n",
    "                                     #'eur_red',\n",
    "                                        #'gbp_green',\n",
    "                                        #'gbp_red',\n",
    "                                     #'usd_no_actual'\n",
    "                                    ]]\n",
    "\n",
    "#fundamental_data = fundamental_data.drop(columns=['original date frame', ])\n",
    "\n",
    "\n",
    "fundamental_data = fundamental_data[::-1].reset_index(drop=True)\n",
    "\n",
    "currency = ['usd','gbp','jpy','aud','chf','eur','cad','nzd',]\n",
    "\n",
    "\n",
    "\n",
    "#print(fundamental_data)\n",
    "\n",
    "combine_data_dataframe = pd.concat([ combine_data_dataframe, fundamental_data ], axis=1)\n",
    "print(combine_data_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies the data frame so as to isolate the first 10 rows for prediction\n",
    "combine_top_10_rows_dataframe = combine_data_dataframe.copy(deep=True)\n",
    "\n",
    "\n",
    "combine_top_10_rows_dataframe = combine_top_10_rows_dataframe.head(25)\n",
    "\n",
    "#saves the first 10 rows to excel\n",
    "\n",
    "combine_top_10_rows_dataframe.to_excel(\"files/combine_top_10_rows_dataframe.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "#combine_data_dataframe = combine_data_dataframe.head( len(globally_available_time_frame) - 5 )\n",
    "\n",
    "combine_data_dataframe.to_excel(\"files/combine_data_dataframe.xlsx\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776bed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
