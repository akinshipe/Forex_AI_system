{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fde693da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-16   6   6  16  30  -4  12   6  12  -3   4 -12   8  -3  15 -20  -3  20\n",
      "  -4   2  -3   6 -12   4   8   9  12 -12 -12  -6   4  -6  12 -12  24  -6\n",
      "  12 -25 -12  12  -4  24 -12   2  24  -6  24  -1 -12 -12  -6 -25  24 -12\n",
      " -20  24 -25  -4  12  20  20  -6  12 -12   6  -1  -9  16  -6  24  -3 -12\n",
      "  -4  12  12 -24 -12  -1 -12  30  -4 -12   9 -12  12 -12  -6  -1 -12  -4\n",
      " -12   6 -16  -4  24  16  12  -4  25  16   6 -12  30  -1 -12   6   2  24\n",
      "   4]\n",
      "Accuracy: 0.06422018348623854\n",
      "Unnamed: 3         0.041007\n",
      "eur_buy_percent    0.040717\n",
      "Unnamed: 5         0.040431\n",
      "usd_buy_percent    0.037765\n",
      "Unnamed: 4         0.037445\n",
      "Unnamed: 29        0.037402\n",
      "Unnamed: 24        0.037239\n",
      "Unnamed: 7         0.036562\n",
      "Unnamed: 9         0.035951\n",
      "Unnamed: 23        0.035949\n",
      "Unnamed: 8         0.035790\n",
      "jpy_buy_percent    0.034213\n",
      "Unnamed: 25        0.034177\n",
      "Unnamed: 11        0.033689\n",
      "Unnamed: 27        0.032982\n",
      "Unnamed: 12        0.032862\n",
      "Unnamed: 13        0.032317\n",
      "gbp_buy_percent    0.032270\n",
      "cad_buy_percent    0.030868\n",
      "Unnamed: 17        0.028220\n",
      "Unnamed: 28        0.028111\n",
      "Unnamed: 33        0.027986\n",
      "nzd_buy_percent    0.027979\n",
      "Unnamed: 16        0.026326\n",
      "aud_buy_percent    0.025724\n",
      "Unnamed: 15        0.025464\n",
      "Unnamed: 31        0.024893\n",
      "Unnamed: 21        0.022930\n",
      "chf_buy_percent    0.021981\n",
      "Unnamed: 32        0.021640\n",
      "Unnamed: 20        0.020511\n",
      "Unnamed: 19        0.018601\n",
      "dtype: float64\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "currency_list = ['USDCHF10080',\n",
    "                 #'GBPUSD10080', 'EURUSD10080', 'USDJPY10080', 'USDCAD10080', 'AUDUSD10080', 'NZDUSD10080',\n",
    "                 #'GBPCHF10080', 'EURCHF10080', 'CHFJPY10080', 'CADCHF10080', 'AUDCHF10080', 'NZDCHF10080', 'EURGBP10080',\n",
    "                 #'GBPJPY10080', 'GBPCAD10080', 'GBPAUD10080', 'EURJPY10080', 'EURCAD10080', 'EURAUD10080', 'EURNZD10080',\n",
    "                #'CADJPY10080', 'AUDJPY10080', 'NZDJPY10080', 'AUDCAD10080', 'NZDCAD10080', 'AUDNZD10080'\n",
    "                ]\n",
    "\n",
    "all_currency_prediction = []\n",
    "\n",
    "for q in currency_list:\n",
    "\n",
    "    currency = q.replace('10080','')\n",
    "    \n",
    "    data = pd.read_excel('files/currency_training_data/' + currency +'_combine_data_dataframe.xlsx', sheet_name=0)\n",
    "    \n",
    "    # classify each row and attach numeric score to it\n",
    "    classification_score = []\n",
    "\n",
    "    # Iterate over each row\n",
    "    for index, row in data.iterrows():\n",
    "\n",
    "        # condition when the curreny movement is a buy\n",
    "\n",
    "        pips_corrector = 100000\n",
    "\n",
    "        if currency.endswith('jpy'):# use this to correct multiplier of jpy pairs\n",
    "            pips_corrector = 1000\n",
    "\n",
    "        if row.nextweek_open < row.nextweek_close:\n",
    "\n",
    "            trend = 1\n",
    "\n",
    "\n",
    "            #classifying the risk level\n",
    "\n",
    "\n",
    "            if (row.nextweek_open - row.nextweek_low) == 0 : # no risk because open is equal to low\n",
    "\n",
    "                risk = 6\n",
    "\n",
    "            else : \n",
    "\n",
    "                if (row.nextweek_open - row.nextweek_low)> (row.nextweek_high - row.nextweek_open):\n",
    "\n",
    "                    risk = 1\n",
    "\n",
    "                if  (row.nextweek_high - row.nextweek_open) > (row.nextweek_open - row.nextweek_low):\n",
    "\n",
    "                    risk = 2\n",
    "\n",
    "\n",
    "                if (row.nextweek_high - row.nextweek_open) /(row.nextweek_open - row.nextweek_low) >2 :\n",
    "\n",
    "                    risk = 3\n",
    "\n",
    "                if (row.nextweek_high - row.nextweek_open) /(row.nextweek_open - row.nextweek_low) >4 :\n",
    "\n",
    "                    risk = 4\n",
    "\n",
    "\n",
    "                if (row.nextweek_high - row.nextweek_open) /(row.nextweek_open - row.nextweek_low) >8 :\n",
    "\n",
    "                    risk = 5\n",
    "\n",
    "                if (row.nextweek_high - row.nextweek_open) /(row.nextweek_open - row.nextweek_low) >16 :\n",
    "\n",
    "                    risk = 6  \n",
    "\n",
    "            #classifying reward level\n",
    "\n",
    "            if (row.nextweek_close - row.nextweek_open)*pips_corrector > 0 :\n",
    "\n",
    "                reward = 1\n",
    "\n",
    "            if (row.nextweek_close - row.nextweek_open)*pips_corrector >200 :\n",
    "\n",
    "                reward = 2\n",
    "\n",
    "            if (row.nextweek_close - row.nextweek_open)*pips_corrector > 400 :\n",
    "\n",
    "                reward = 3\n",
    "\n",
    "\n",
    "            if (row.nextweek_close - row.nextweek_open)*pips_corrector > 800 :\n",
    "\n",
    "                reward = 4\n",
    "\n",
    "            if (row.nextweek_close - row.nextweek_open)*pips_corrector > 1600 :\n",
    "\n",
    "                reward = 5\n",
    "\n",
    "\n",
    "            if (row.nextweek_close - row.nextweek_open)*pips_corrector > 3200 :\n",
    "\n",
    "                reward = 6  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # this is for the condition when the movement is a sell\n",
    "        else: \n",
    "\n",
    "            trend = -1\n",
    "\n",
    "            #classifying the risk level\n",
    "\n",
    "\n",
    "            if (row.nextweek_high - row.nextweek_open) == 0 : # no risk because open is equal to high\n",
    "\n",
    "                risk = 6\n",
    "\n",
    "            else : \n",
    "\n",
    "                if (row.nextweek_high - row.nextweek_open)> (row.nextweek_open - row.nextweek_low):\n",
    "\n",
    "                    risk = 1\n",
    "\n",
    "                if  (row.nextweek_open - row.nextweek_low) > (row.nextweek_high - row.nextweek_open):\n",
    "\n",
    "                    risk = 2\n",
    "\n",
    "\n",
    "                if (row.nextweek_open - row.nextweek_low) /(row.nextweek_high - row.nextweek_open) >2 :\n",
    "\n",
    "                    risk = 3\n",
    "\n",
    "                if (row.nextweek_open - row.nextweek_low) /(row.nextweek_high - row.nextweek_open) >4 :\n",
    "\n",
    "                    risk = 4\n",
    "\n",
    "                if (row.nextweek_open - row.nextweek_low) /(row.nextweek_high - row.nextweek_open) >8 :\n",
    "\n",
    "                    risk = 5\n",
    "\n",
    "                if (row.nextweek_open - row.nextweek_low) /(row.nextweek_high - row.nextweek_open) >16 :\n",
    "\n",
    "                    risk = 6 \n",
    "\n",
    "\n",
    "             #classifying reward level\n",
    "\n",
    "            if (row.nextweek_open - row.nextweek_close)*pips_corrector > 0 :\n",
    "\n",
    "                reward = 1\n",
    "\n",
    "            if (row.nextweek_open - row.nextweek_close)*pips_corrector > 200 :\n",
    "\n",
    "                reward = 2\n",
    "\n",
    "            if (row.nextweek_open - row.nextweek_close)*pips_corrector > 400 :\n",
    "\n",
    "                reward = 3        \n",
    "\n",
    "            if (row.nextweek_open - row.nextweek_close)*pips_corrector > 800 :\n",
    "\n",
    "                reward = 4    \n",
    "\n",
    "            if (row.nextweek_open - row.nextweek_close)*pips_corrector > 1600 :\n",
    "\n",
    "                reward = 5 \n",
    "\n",
    "            if (row.nextweek_open - row.nextweek_close)*pips_corrector > 3200 :\n",
    "\n",
    "                reward = 6        \n",
    "\n",
    "        classification_score.append(trend*risk*reward)\n",
    "\n",
    "\n",
    "\n",
    "    #attach the classification score value to the dataframe and train a model with the data\n",
    "\n",
    "\n",
    "    \n",
    "    data['classification_score'] = classification_score \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    X = data.drop(columns=['Unnamed: 0', \n",
    "                           'date_start',  'nextweek_open', 'nextweek_high','nextweek_low',                       \n",
    "                            'nextweek_close','classification_score',\n",
    "\n",
    "\n",
    "                          ])\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    y = data['classification_score']\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 80% training and 30% test\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "   \n",
    "  \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.00001 )\n",
    "\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(y_pred)\n",
    "    \n",
    "    \n",
    "\n",
    "    #temp_data = pd.read_excel('files/combine_top_10_rows_dataframe.xlsx', sheet_name=0)\n",
    "    \n",
    "    #temp_data = temp_data.head(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #currency1 =q[ 0 : 3 ].lower()\n",
    "    #currency2 = q[3:6].lower()\n",
    "    \n",
    "   \n",
    "    \n",
    "    #index1 = temp_data.columns.get_loc(currency1+'_buy_percent')\n",
    "    #index2 = temp_data.columns.get_loc(currency2+'_buy_percent')\n",
    "    \n",
    "    #temp_data = temp_data.iloc[:, [ 1, index1, index1+1, index1+2, index1+3, index2, index2+1, index2+2, index2+3]   ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #last_date = temp_data['date_start'][0].strftime('%Y-%m-%d')\n",
    "    #X = temp_data.drop(columns=[ 'date_start','Unnamed: 0' ])\n",
    "   \n",
    "    \n",
    " \n",
    "    #y_pred = model.predict(X)\n",
    "    #all_currency_prediction.append(y_pred[0])\n",
    "    \n",
    "    #print(q)\n",
    "    \n",
    "    \n",
    "  \n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
    "    print(feature_imp)\n",
    "    \n",
    "print(all_currency_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f56b9c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LAOLUH~1\\AppData\\Local\\Temp/ipykernel_10000/2771299636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m             }\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'files/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlast_date\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'scores.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    " data = {\n",
    "            'currency':currency_list,\n",
    "            'score':all_currency_prediction\n",
    "     \n",
    "             }\n",
    "                                     \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_excel('files/' + last_date + '_' + 'scores.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ea025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
