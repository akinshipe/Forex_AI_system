{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7576e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9caf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(\"../\", topdown=False):\n",
    "    pass\n",
    "\n",
    "print(len(dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "278419d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../0915. 12-april-2020 to predict 19-april-2020/files/maximaldraw_down_and_up.csv\n",
      "../0916. 19-april-2020 to predict 26-april-2020/files/maximaldraw_down_and_up.csv\n",
      "../0917. 26-april-2020 to predict 3-may-2020/files/maximaldraw_down_and_up.csv\n",
      "../0918. 3-may-2020 to predict 10-may-2020/files/maximaldraw_down_and_up.csv\n",
      "../0919. 10-may-2020 to predict 17-may-2020/files/maximaldraw_down_and_up.csv\n",
      "../0920. 17-may-2020 to predict 24-may/files/maximaldraw_down_and_up.csv\n",
      "../0921. 24-may-2020 to predict 31-may-2020/files/maximaldraw_down_and_up.csv\n",
      "../0922. 31-may-2020 to predict 7-june-2020/files/maximaldraw_down_and_up.csv\n",
      "../0923. 7-june-2020 to predict14-june-2020/files/maximaldraw_down_and_up.csv\n",
      "../0924. 14-june-2020 to predict 21-june-2020/files/maximaldraw_down_and_up.csv\n",
      "../0925. 21-june-2020 to predict 28-june-2020/files/maximaldraw_down_and_up.csv\n",
      "../0926. 28-june-2020 to predict 5-july-2020/files/maximaldraw_down_and_up.csv\n",
      "../0927. 5-july-2020 to predict 12-july-2020/files/maximaldraw_down_and_up.csv\n",
      "../0928. 12-july-2020 to predict 19-july-2020/files/maximaldraw_down_and_up.csv\n",
      "../0929. 19-july-2020 to predict 26-july-2020/files/maximaldraw_down_and_up.csv\n",
      "../0930. 26-july-2020 to predict 2-aug-2020/files/maximaldraw_down_and_up.csv\n",
      "../0931. 2-aug-2020 to predict 9-aug-2020/files/maximaldraw_down_and_up.csv\n",
      "../0932. 9-aug-2020 to predict 16-aug-2022/files/maximaldraw_down_and_up.csv\n",
      "../0933. 16-aug-2020 to predict 23-aug-2020/files/maximaldraw_down_and_up.csv\n",
      "../0934. 23-aug-2020 to predict 30-aug-2020/files/maximaldraw_down_and_up.csv\n",
      "../0935. 30-aug-2020 to predict 6-sept-2020/files/maximaldraw_down_and_up.csv\n",
      "../0936. 6-sept-2020 to predict 13-sept-2020/files/maximaldraw_down_and_up.csv\n",
      "../pips calculation/files/maximaldraw_down_and_up.csv\n",
      "../starterpack/files/maximaldraw_down_and_up.csv\n",
      "240 240\n"
     ]
    }
   ],
   "source": [
    "all_week_dataframes = []\n",
    "max_rows = 0\n",
    "max_timeframe_rows = None\n",
    "\n",
    "for a in dirs:\n",
    "    \n",
    "    path = '../'+ a + '/files/maximaldraw_down_and_up.csv'\n",
    "    \n",
    "    if os.path.exists(path) == False:\n",
    "        \n",
    "        print(path)\n",
    "    \n",
    "        continue\n",
    "    \n",
    "    \n",
    "    current_week_dataframe = pd.read_csv(path )\n",
    "    \n",
    "    current_dt_lenght = len(current_week_dataframe.index)\n",
    "    \n",
    "    if current_dt_lenght > 240:\n",
    "        print(path)\n",
    "        raise Exception('Rows are not supposed to me more than 240')\n",
    "    \n",
    "    if current_dt_lenght > max_rows :\n",
    "        \n",
    "        max_rows = current_dt_lenght\n",
    "        max_timeframe_rows = current_week_dataframe['timeframe']\n",
    "        \n",
    "        \n",
    "    \n",
    "    current_week_data = {'week_path' : path, 'dataframe' : current_week_dataframe,  }\n",
    "     \n",
    "    all_week_dataframes.append(current_week_data)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "print(max_rows, len(max_timeframe_rows))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e51aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_weeks_df = pd.DataFrame()\n",
    "combine_weeks_df['timeframe'] = max_timeframe_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41aec281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timeframe  week_0701  week_0702  week_0703  week_0704  week_0801  \\\n",
      "0    2018.01.19 23:30     1919.0    -8879.0    -8769.0   -11015.0      874.0   \n",
      "1    2018.01.19 23:00     2578.0    -9216.0    -8403.0   -11194.0     1196.0   \n",
      "2    2018.01.19 22:30     2415.0    -8795.0    -8597.0   -11695.0     1382.0   \n",
      "3    2018.01.19 22:00     2363.0    -8275.0    -8689.0   -12747.0     1684.0   \n",
      "4    2018.01.19 21:30     2429.0    -7869.0    -8111.0   -12853.0     1473.0   \n",
      "..                ...        ...        ...        ...        ...        ...   \n",
      "235  2018.01.15 02:00    -1298.0      767.0      827.0     -987.0     -178.0   \n",
      "236  2018.01.15 01:30       29.0      880.0     1023.0     -936.0     -497.0   \n",
      "237  2018.01.15 01:00     -474.0     1072.0     1194.0     -438.0     -145.0   \n",
      "238  2018.01.15 00:30      572.0      602.0     1071.0      514.0     -258.0   \n",
      "239  2018.01.15 00:00      337.0      612.0      613.0      936.0     -247.0   \n",
      "\n",
      "     week_0802  week_0803  week_0804  week_0901  ...  week_1045  week_1046  \\\n",
      "0       6264.0      363.0    10024.0    -3232.0  ...    11154.0     3726.0   \n",
      "1       6430.0      943.0     9800.0    -3242.0  ...    10849.0     3831.0   \n",
      "2       7033.0     1482.0     9687.0    -3138.0  ...    10468.0     4200.0   \n",
      "3       6977.0     1352.0    10078.0    -3146.0  ...    10413.0     4011.0   \n",
      "4       7190.0     1444.0     9755.0    -3212.0  ...    10190.0     3688.0   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "235      233.0      882.0       75.0     -429.0  ...     -878.0     1527.0   \n",
      "236      285.0      284.0      422.0       13.0  ...     -608.0     1053.0   \n",
      "237      515.0      -64.0      798.0     -160.0  ...      -63.0     1652.0   \n",
      "238       35.0     -252.0      185.0     -431.0  ...     -452.0     1015.0   \n",
      "239       47.0      233.0      293.0     -187.0  ...     -222.0      324.0   \n",
      "\n",
      "     week_1047  week_1048  week_1049  week_1050  week_1051  week_1052  empty1  \\\n",
      "0       1841.0    -8730.0     5094.0    -3826.0    14511.0   -15772.0           \n",
      "1       1835.0    -9121.0     5090.0    -3851.0    14472.0   -15579.0           \n",
      "2       1465.0    -9141.0     4772.0    -3940.0    14090.0   -15094.0           \n",
      "3       1586.0    -9255.0     4970.0    -4041.0    14333.0   -15126.0           \n",
      "4       1563.0    -9237.0     4814.0    -4587.0    14151.0   -16042.0           \n",
      "..         ...        ...        ...        ...        ...        ...     ...   \n",
      "235      378.0    -1101.0     -210.0     -241.0      668.0     1712.0           \n",
      "236      558.0      -82.0     -217.0     -279.0      560.0     2454.0           \n",
      "237      548.0      242.0     -198.0     -354.0      340.0     1890.0           \n",
      "238      371.0      242.0     -234.0     -347.0      479.0    -1739.0           \n",
      "239      252.0      242.0     -186.0     -333.0      358.0    -2188.0           \n",
      "\n",
      "         sum  \n",
      "0    16941.0  \n",
      "1    23010.0  \n",
      "2    28245.0  \n",
      "3    26870.0  \n",
      "4    25299.0  \n",
      "..       ...  \n",
      "235  47404.0  \n",
      "236  40648.0  \n",
      "237  31765.0  \n",
      "238  22470.0  \n",
      "239  22412.0  \n",
      "\n",
      "[240 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for b in all_week_dataframes:\n",
    "    \n",
    "    current_week_dataframe = b['dataframe'].iloc[: , :2]\n",
    "    week_name = 'week_' + b['week_path'][3:7]\n",
    "    \n",
    "    #print(current_week_dataframe)\n",
    "    # this is to removes weeks that have holiday or missing data in them\n",
    "    if len(current_week_dataframe.index) <230:\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    while len(current_week_dataframe.index) < max_rows:\n",
    "\n",
    "        \n",
    "        new_row = current_week_dataframe.tail(1).values[0]  \n",
    "        #print(new_row)\n",
    "       \n",
    "        current_week_dataframe.loc[len(current_week_dataframe.index)] = new_row\n",
    "       \n",
    "        \n",
    "    \n",
    "    \n",
    "    combine_weeks_df[week_name] = current_week_dataframe['profit']\n",
    "    \n",
    "\n",
    "column_list = list(combine_weeks_df)   \n",
    "column_list.remove('timeframe')\n",
    "\n",
    "combine_weeks_df[\"empty1\"] = [\"\" for x in max_timeframe_rows]\n",
    "combine_weeks_df[\"sum\"] = combine_weeks_df[column_list].sum(axis=1)\n",
    "print(combine_weeks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd895c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c44525b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'combine_weeks_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\AKINSH~1\\AppData\\Local\\Temp/ipykernel_24884/808514447.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombine_weeks_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'combine_weeks_df.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\akinshipe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3461\u001b[0m         )\n\u001b[0;32m   3462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3464\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\akinshipe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\akinshipe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\akinshipe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'combine_weeks_df.csv'"
     ]
    }
   ],
   "source": [
    "combine_weeks_df.to_csv('combine_weeks_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da7721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de929a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
